{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from osgeo import ogr, osr\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from scipy.ndimage import median_filter\n",
    "%run ../../src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"../../models/april-27-ft/126-75-3/\"\n",
    "new_saver = tf.train.import_meta_graph(model + \"model.meta\")\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    try:\n",
    "        fm = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "    except Exception:\n",
    "        pass\n",
    "#logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_11/Sigmoid:0\")\n",
    "inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "labels = tf.get_default_graph().get_tensor_by_name(\"Placeholder_2:0\")\n",
    "rmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "rmin = tf.get_default_graph().get_tensor_by_name(\"Placeholder_5:0\")\n",
    "length = tf.get_default_graph().get_tensor_by_name(\"Placeholder_1:0\")\n",
    "dmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_6:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_all = [0.20792677521705638,\n",
    " 0.2990041905641556,\n",
    " 0.4360648360848427,\n",
    " 0.5161105132102968,\n",
    " 0.4825860628485681,\n",
    " 0.4943232241272928,\n",
    " 0.5178957056999209,\n",
    " 0.5291672283411026,\n",
    " 0.6659183305501939,\n",
    " 0.6092100739479065,\n",
    " 0.37346625328063965,\n",
    " 0.7162704998254776,\n",
    " 0.40363759160041823,\n",
    " 0.6478493613004686,\n",
    " 0.8438000082969666,\n",
    " 0.15365000069141388]\n",
    "\n",
    "min_all = [0.01872335869818926,\n",
    " 0.03467957343906164,\n",
    " 0.021185510214418172,\n",
    " 0.08898216009140014,\n",
    " 0.052402322441339494,\n",
    " 0.07628638863563539,\n",
    " 0.083824477866292,\n",
    " 0.08768215030431747,\n",
    " 0.05718051139265299,\n",
    " 0.0372315139323473,\n",
    " 0.0,\n",
    " 0.007564654648303981,\n",
    " -0.019136652257293465,\n",
    " 0.0064204379683360435,\n",
    " 0.006225000135600567,\n",
    " 4.999999873689376e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "test_x = np.load(\"../../tile_data/processed/test_x_l2a_processed.npy\")\n",
    "print(test_x.shape)\n",
    "test_y = np.load(\"../../tile_data/processed/test_y_l2a_processed.npy\")\n",
    "test_lengths = np.load(\"../../tile_data/processed/test_length_l2a_processed.npy\")\n",
    "\n",
    "test_x = np.delete(test_x, 14, -1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.5]\n",
    "above_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.5]\n",
    "min_vals = [np.min(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "print(\"There are {} outliers: {}\".format(len(outliers), outliers))\n",
    "print(\"\\n\")\n",
    "print(min_vals, max_vals)\n",
    "        \n",
    "test_x = test_x[[x for x in range(0, len(test_x)) if x not in outliers]]\n",
    "test_y = test_y[[x for x in range(0, len(test_y)) if x not in outliers]]\n",
    "test_lengths = test_lengths[[x for x in range(0, len(test_lengths)) if x not in outliers]]\n",
    "\n",
    "for sample in tnrange(0, len(test_x)):\n",
    "    filtered = median_filter(test_x[sample, 0, :, :, 10], size = 5)\n",
    "    filtered = np.reshape(filtered, (8, 2, 8, 2))\n",
    "    filtered = np.mean(filtered, axis = (1, 3))\n",
    "    filtered = resize(filtered, (16, 16), 0)\n",
    "    test_x[sample, :, :, :, 10] = np.stack([filtered] * 24)\n",
    "    \n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[:, :, :, :, band] = np.clip(test_x[:, :, :, :, band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    test_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipping_params = {\n",
    "    'rmax': rmax,\n",
    "    'rmin': rmin,\n",
    "    'dmax': dmax\n",
    "}\n",
    "\n",
    "\n",
    "def run_predictions(x, y, lengths, debug = False):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    diffs = None\n",
    "    for sample in tnrange(x.shape[0]):\n",
    "        if sample not in [558, 563, 596, 599, 602, 615, 634]:\n",
    "            pred = sess.run([fm], feed_dict={inp: x[sample].reshape(1, 24, 16, 16, 16),\n",
    "                                      length: lengths[sample].reshape(1, 1),\n",
    "                                      clipping_params['rmax']: 5,\n",
    "                                      clipping_params['rmin']: 0,\n",
    "                                      clipping_params['dmax']: 3,\n",
    "                                      })\n",
    "            preds.append(np.array(pred))\n",
    "            trues.append(y[sample])\n",
    "    if debug:\n",
    "        thresh = 0.58\n",
    "        preds_i = np.copy(preds)\n",
    "        for i in range(len(preds_i)):\n",
    "            preds_i[i] = np.array(preds_i[i])\n",
    "            preds_i[i][np.where(preds_i[i] >= thresh)] = 1.\n",
    "            preds_i[i][np.where(preds_i[i] < thresh)] = 0.\n",
    "        diffs = [abs(np.sum(np.array(a)) - np.sum(np.array(b))) for a, b in zip(preds_i, trues)]\n",
    "    #preds = np.concatenate(preds)\n",
    "    #trues = np.concatenate(trues)\n",
    "    return preds, trues, diffs\n",
    "\n",
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calc_thresh_relaxed(trues, preds):\n",
    "    means = []\n",
    "    for thresh in tnrange(10, 90, 2):\n",
    "        tp = 0\n",
    "        fp = 0 \n",
    "        fn = 0\n",
    "        errors = []\n",
    "        for i in range(len(trues)):\n",
    "            pred_c = np.copy(preds[i])\n",
    "            pred_c = np.array(pred_c.reshape((14, 14)))\n",
    "            pred_c[np.where(pred_c >= thresh / 100)] = 1.\n",
    "            pred_c[np.where(pred_c < thresh / 100)] = 0.\n",
    "            errors.append(np.sum(trues[i] - np.sum(pred_c)))\n",
    "           \n",
    "            \n",
    "            tpi, fpi, fni = compute_f1_score_at_tolerance(np.array(trues[i].reshape((14, 14))),\n",
    "                                                 pred_c)\n",
    "            tp += tpi\n",
    "            fp += fpi\n",
    "            fn += fni\n",
    "        ua = (tp) / (tp + fn)\n",
    "        pa = (tp) / (tp + fp)\n",
    "        errors = np.mean(errors)\n",
    "        print(thresh, ua, pa, means)\n",
    "        m#eans.append(abs[np.sum(trues[i]) - np.sum(pred_c)])\n",
    "        means.append((ua + pa) / 2)\n",
    "    \n",
    "    best_acc = np.max(means)\n",
    "    best_thresh = [x for x in range(10, 90, 2)][np.argmax(np.array(means))] / 100\n",
    "    return best_thresh\n",
    "\n",
    "def calc_thresh(trues, preds, threshold = None):\n",
    "    trues = np.array(trues).flatten()\n",
    "    preds = np.array(preds).flatten()\n",
    "    f1s = []\n",
    "    if not threshold:\n",
    "        for thresh in range(10, 90, 2):\n",
    "            pred_i = np.copy(preds)\n",
    "            pred_i[np.where(pred_i >= thresh / 100)] = 1.\n",
    "            pred_i[np.where(pred_i < thresh / 100)] = 0.\n",
    "            f1 = f1_score(trues, pred_i)\n",
    "            f1s.append(f1)\n",
    "        best_f1 = np.max(f1s)\n",
    "        best_thresh = [x for x in range(10, 90, 2)][np.argmax(np.array(f1s))] / 100\n",
    "    else:\n",
    "        pred_i = np.copy(preds)\n",
    "        pred_i[np.where(pred_i >= threshold)] = 1.\n",
    "        pred_i[np.where(pred_i < threshold)] = 0.\n",
    "        f1 = f1_score(trues, pred_i)\n",
    "        best_f1 = f1\n",
    "        best_thresh = threshold\n",
    "        \n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, trues, diffs = run_predictions(test_x, test_y, test_lengths, debug = False)\n",
    "thresh = calc_thresh_relaxed(trues, preds)\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_canopy = []\n",
    "error_canopy = []\n",
    "pred_canopy = []\n",
    "tp_softs = []\n",
    "fp_softs = []\n",
    "fn_softs = []\n",
    "for i in range(len(trues)):\n",
    "    preds[i][np.where(preds[i] >= thresh)] = 1.\n",
    "    preds[i][np.where(preds[i] < thresh)] = 0.\n",
    "    \n",
    "    true_canopy.append(np.sum(trues[i]) / 1.96)\n",
    "    error_canopy.append(abs(np.sum(preds[i]) - np.sum(trues[i])) / 1.96)\n",
    "    pred_canopy.append(np.sum(preds[i]) / 1.96)\n",
    "    tp_soft, fp_soft, fn_soft = compute_f1_score_at_tolerance(np.array(trues[i].reshape((14, 14))),\n",
    "                                                 np.array(preds[i].reshape((14, 14))))\n",
    "    tp_softs.append(tp_soft)\n",
    "    fp_softs.append(fp_soft)\n",
    "    fn_softs.append(fn_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6f87be376879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_canopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.mean(error_canopy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9760131210278138 0.9874853073359607 11.280612244897961 73.79081632653062 83.21428571428571\n"
     ]
    }
   ],
   "source": [
    "precision = np.sum(tp_softs) / (np.sum(tp_softs) + np.sum(fp_softs))\n",
    "recall = np.sum(tp_softs) / (np.sum(tp_softs) + np.sum(fn_softs))\n",
    "print(precision, recall, np.mean(error_canopy), np.mean(true_canopy), np.mean(pred_canopy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wall to wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
