{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from osgeo import ogr, osr\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"../../models/unet-resnet/34-65-9/\"\n",
    "new_saver = tf.train.import_meta_graph(model + \"model.meta\")\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fspecial_gauss(size, sigma):\n",
    "\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g\n",
    "\n",
    "arr = fspecial_gauss(14, 3.5)\n",
    "arr = arr[:7, :7]\n",
    "\n",
    "\n",
    "SIZE = 9\n",
    "SIZE_N = SIZE*SIZE\n",
    "SIZE_UR = (SIZE - 1) * (SIZE - 1)\n",
    "SIZE_R = (SIZE - 1) * SIZE\n",
    "SIZE_U = SIZE_R\n",
    "TOTAL = SIZE_N + SIZE_UR + SIZE_R + SIZE_U\n",
    "print(SIZE_N, SIZE_UR, SIZE_R, SIZE_U, TOTAL)\n",
    "\n",
    "\n",
    "arr = np.concatenate([arr, np.flip(arr, 0)], 0)\n",
    "base_filter = np.concatenate([arr, np.flip(arr, 1)], 1)\n",
    "normal = np.tile(base_filter, (SIZE, SIZE))\n",
    "normal[:, 0:7] = 1.\n",
    "normal[:, -7:] = 1.\n",
    "normal[0:7, :] = 1.\n",
    "normal[-7:, :] = 1.\n",
    "upright = np.tile(base_filter, (SIZE - 1, SIZE - 1))\n",
    "upright = np.pad(upright, (7, 7), 'constant', constant_values = 0)\n",
    "right_filter = np.tile(base_filter, (SIZE, SIZE - 1))\n",
    "right_filter = np.pad(right_filter, ((0, 0), (7, 7)), 'constant', constant_values = 0)\n",
    "up_filter = np.tile(base_filter, (SIZE - 1, SIZE))\n",
    "up_filter = np.pad(up_filter, ((7, 7), (0, 0)), 'constant', constant_values = 0)\n",
    "\n",
    "sums = (up_filter + right_filter + upright + normal)\n",
    "up_filter /= sums\n",
    "right_filter /= sums\n",
    "upright /= sums\n",
    "normal /= sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# December 10-11 model, validated-size, filled in by train-l2a-dec\n",
    "\n",
    "min_all = [0.01872335869818926,\n",
    " 0.03467957343906164,\n",
    " 0.021185510214418172,\n",
    " 0.08898216009140014,\n",
    " 0.052402322441339494,\n",
    " 0.07628638863563539,\n",
    " 0.083824477866292,\n",
    " 0.08768215030431747,\n",
    " 0.05718051139265299,\n",
    " 0.0372315139323473,\n",
    " 0.0,\n",
    " 0.007564654648303981,\n",
    " -0.019136652257293465,\n",
    " 0.0064204379683360435,\n",
    " 0.006225000135600567,\n",
    " 4.999999873689376e-05]\n",
    "\n",
    "max_all = [0.20792677521705638,\n",
    " 0.2990041905641556,\n",
    " 0.4360648360848427,\n",
    " 0.5161105132102968,\n",
    " 0.4825860628485681,\n",
    " 0.4943232241272928,\n",
    " 0.5178957056999209,\n",
    " 0.5291672283411026,\n",
    " 0.6659183305501939,\n",
    " 0.6092100739479065,\n",
    " 0.37346625328063965,\n",
    " 0.7162704998254776,\n",
    " 0.40363759160041823,\n",
    " 0.6478493613004686,\n",
    " 0.8438000082969666,\n",
    " 0.15365000069141388]\n",
    "\n",
    "def tile_images(arr, output_folder):\n",
    "    i = 0\n",
    "    # Normal\n",
    "    images = []\n",
    "    for x_offset, cval in enumerate([x for x in range(0, 126, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 126, 14)]):\n",
    "            base_id = 0\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            images.append(subs)\n",
    "            \n",
    "    # Upright        \n",
    "    for x_offset, cval in enumerate([x for x in range(7,  119, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(7, 119, 14)]):\n",
    "            base_id = 9*9\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            images.append(subs)\n",
    "            \n",
    "    # Right\n",
    "    for x_offset, cval in enumerate([x for x in range(7, 119, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 126, 14)]):\n",
    "            base_id = (9*9)+(8*8)\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            images.append(subs)\n",
    "            \n",
    "    # Up\n",
    "    for x_offset, cval in enumerate([x for x in range(0, 119, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(7, 119, 14)]):\n",
    "            base_id = (9*9)+(8*8)+(9*8)\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            images.append(subs)\n",
    "    return images\n",
    "\n",
    "def load_and_predict_folder(y_col, folder, location, overlap_filter = upright, normal_filter = normal):\n",
    "    pred_files = [\"../../tile_data/\" + location + \"/processed/\" + str(y_col) + \"/\" + str(folder) + \".npy\"]\n",
    "    pred_x = []\n",
    "    \n",
    "    clipping_params = {\n",
    "        'rmax': rmax,\n",
    "        'rmin': rmin,\n",
    "        'dmax': dmax\n",
    "    }\n",
    "\n",
    "    for i in range(len(pred_files)):\n",
    "        x = np.load(pred_files[0])\n",
    "        \n",
    "        filtered = median_filter(x[0, :, :, 10], size = 5)\n",
    "        filtered = np.reshape(filtered, (64, 2, 64, 2))\n",
    "        filtered = np.mean(filtered, axis = (1, 3))\n",
    "        filtered = resize(filtered, (128, 128), 0)\n",
    "        x[:, :, :, 10] = np.stack([filtered] * 24)\n",
    "        x = np.delete(x, 14, -1)\n",
    "        x = tile_images(x, None)\n",
    "  \n",
    "    pred_x = np.stack(x)     \n",
    "    \n",
    "    for x in range(0, pred_x.shape[-1]):\n",
    "        mins = min_all[x]\n",
    "        maxs = max_all[x]\n",
    "        pred_x[:, :, :, :, x] = np.clip(pred_x[:, :, :, :, x], mins, maxs)\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = (pred_x[:, :, :, :, x] - midrange) / (rng / 2)\n",
    "        pred_x[:, :, :, :, x] = standardized\n",
    "        \n",
    "    pred_x = np.mean(pred_x, axis = 1)\n",
    "\n",
    "    preds = []\n",
    "    batches = [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260, 280, 289]\n",
    "    for i in range(len(batches)-1):\n",
    "        batch_x = pred_x[batches[i]:batches[i+1]]\n",
    "        batch_pred = sess.run(logits, feed_dict={inp:batch_x, \n",
    "                                                 clipping_params['rmax']: 5,\n",
    "                                                 clipping_params['rmin']: 0,\n",
    "                                                 clipping_params['dmax']: 3}).reshape(batch_x.shape[0], 14, 14)\n",
    "        for sample in range(batch_pred.shape[0]):\n",
    "            preds.append(batch_pred[sample, :, :])\n",
    "            \n",
    "    preds_stacked = []\n",
    "    for i in range(0, SIZE_N, SIZE):\n",
    "        preds_stacked.append(np.concatenate(preds[i:i + SIZE], axis = 1))\n",
    "    stacked = np.concatenate(preds_stacked, axis = 0)\n",
    "    stacked = stacked * normal\n",
    "    preds_overlap = []\n",
    "    for scene in range(SIZE_N, SIZE_N+SIZE_UR, SIZE - 1):\n",
    "        to_concat = np.concatenate(preds[scene:scene+ (SIZE - 1)], axis = 1)\n",
    "        preds_overlap.append(to_concat)    \n",
    "    overlapped = np.concatenate(preds_overlap, axis = 0)\n",
    "    overlapped = np.pad(overlapped, (7, 7), 'constant', constant_values = 0)\n",
    "    overlapped = overlapped * upright\n",
    "\n",
    "    preds_up = []\n",
    "    for scene in range(SIZE_N+SIZE_UR, SIZE_N+SIZE_UR+SIZE_R, SIZE):\n",
    "        to_concat = np.concatenate(preds[scene:scene+SIZE], axis = 1)\n",
    "        preds_up.append(to_concat)   \n",
    "    up = np.concatenate(preds_up, axis = 0)\n",
    "    up = np.pad(up, ((7,7), (0,0)), 'constant', constant_values = 0)\n",
    "    up = up * up_filter\n",
    "        \n",
    "    preds_right = []\n",
    "    for scene in range(SIZE_N+SIZE_UR+SIZE_R, TOTAL, SIZE - 1):\n",
    "        to_concat = np.concatenate(preds[scene:scene+SIZE-1], axis = 1)\n",
    "        preds_right.append(to_concat)   \n",
    "    right = np.concatenate(preds_right, axis = 0)\n",
    "    right = np.pad(right, ((0, 0), (7, 7)), 'constant', constant_values = 0)\n",
    "    right = right * right_filter\n",
    "    \n",
    "    stacked = stacked + overlapped + right + up\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    try:\n",
    "        logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_11/Sigmoid:0\")\n",
    "inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "rmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "rmin = tf.get_default_graph().get_tensor_by_name(\"Placeholder_5:0\")\n",
    "dmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_6:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanzania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "all_preds = []\n",
    "for row in tnrange(0, 5):\n",
    "    pred_i = [load_and_predict_folder(row, col, \"tanzania\") for col in range(0, 5)]\n",
    "    pred_i = np.concatenate(pred_i, axis = 1)\n",
    "    all_preds.append(pred_i)\n",
    "    sleep(3)\n",
    "all_preds.reverse()\n",
    "stacked = np.concatenate(all_preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.concatenate(all_preds, axis = 0)\n",
    "stacked[np.isnan(stacked)] = 0.\n",
    "stacked[np.where(stacked >= 0.47)] = 1.\n",
    "stacked[np.where(stacked < 0.47)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 15))\n",
    "sns.heatmap(stacked[398:-31, 400:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ghana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "all_preds = []\n",
    "for row in tnrange(0, 5):\n",
    "    pred_i = [load_and_predict_folder(row, col, \"ghana_cocoa\") for col in range(0, 5)]\n",
    "    pred_i = np.concatenate(pred_i, axis = 1)\n",
    "    all_preds.append(pred_i)\n",
    "    sleep(3)\n",
    "all_preds.reverse()\n",
    "stacked = np.concatenate(all_preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.concatenate(all_preds, axis = 0)\n",
    "stacked[np.where(stacked >= 0.4)] = 1.\n",
    "stacked[np.where(stacked < 0.4)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 15))\n",
    "# HONDURAS IS 200:400, 540:640 in (5, 10 row), (10, 20 coly)\n",
    "sns.heatmap(stacked[250:450, 350:450])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Honduras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "all_preds = []\n",
    "for row in tnrange(5, 10):\n",
    "    pred_i = [load_and_predict_folder(row, col, \"honduras\") for col in range(10, 20)]\n",
    "    pred_i = np.concatenate(pred_i, axis = 1)\n",
    "    all_preds.append(pred_i)\n",
    "    sleep(3)\n",
    "all_preds.reverse()\n",
    "stacked = np.concatenate(all_preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.concatenate(all_preds, axis = 0)\n",
    "stacked[np.where(stacked >= 0.71)] = 1.\n",
    "stacked[np.where(stacked < 0.71)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 15))\n",
    "# HONDURAS IS 200:400, 540:640 in (5, 10 row), (10, 20 coly)\n",
    "sns.heatmap(stacked[200:400, 540:640])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senegal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(19, 16)) # : ,96:155\n",
    "sns.heatmap(stacked[340:405, 98:163], cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
