{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate best model on testing dataset\n",
    "\n",
    "During model training, the per-epoch performance is validated against a single-threshold F1-score of the non-tiled test data with no post-processing.\n",
    "\n",
    "This notebook reports the test time performance of the model with regards to the following post-processing steps:\n",
    "\n",
    "- No postprocessing\n",
    "- Threshold selection by biome\n",
    "- Threshold selection by region\n",
    "- Smooth interpolation of test imagery data\n",
    "- Single pixel restoration by thresholding by biome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from osgeo import ogr, osr\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_saver = tf.train.import_meta_graph('../models/april-27-ft/master/model.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint('../models/april-27-ft/master/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_all = [0.01872335869818926,\n",
    " 0.03467957343906164,\n",
    " 0.021185510214418172,\n",
    " 0.08898216009140014,\n",
    " 0.052402322441339494,\n",
    " 0.07628638863563539,\n",
    " 0.083824477866292,\n",
    " 0.08768215030431747,\n",
    " 0.05718051139265299,\n",
    " 0.0372315139323473,\n",
    " 0.0,\n",
    " 0.007564654648303981,\n",
    " -0.019136652257293465,\n",
    " 0.0064204379683360435,\n",
    " 0.006225000135600567,\n",
    " 4.999999873689376e-05]\n",
    "\n",
    "max_all = [0.20792677521705638,\n",
    " 0.2990041905641556,\n",
    " 0.4360648360848427,\n",
    " 0.5161105132102968,\n",
    " 0.4825860628485681,\n",
    " 0.4943232241272928,\n",
    " 0.5178957056999209,\n",
    " 0.5291672283411026,\n",
    " 0.6659183305501939,\n",
    " 0.6092100739479065,\n",
    " 0.37346625328063965,\n",
    " 0.7162704998254776,\n",
    " 0.40363759160041823,\n",
    " 0.6478493613004686,\n",
    " 0.8438000082969666,\n",
    " 0.15365000069141388]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "test_x = np.load(\"../tile_data/processed/test_x_l2a_processed.npy\")\n",
    "test_y = np.load(\"../tile_data/processed/test_y_l2a_processed.npy\")\n",
    "test_lengths = np.load(\"../tile_data/processed/test_length_l2a_processed.npy\")\n",
    "\n",
    "test_x = np.delete(test_x, 14, -1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.66]\n",
    "above_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.66]\n",
    "min_vals = [np.min(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "\n",
    "print(\"There are {} outliers: {}\".format(len(outliers), outliers))\n",
    "print(\"\\n\")\n",
    "print(min_vals, max_vals)\n",
    "        \n",
    "test_x = test_x[[x for x in range(0, len(test_x)) if x not in outliers]]\n",
    "test_y = test_y[[x for x in range(0, len(test_y)) if x not in outliers]]\n",
    "test_lengths = test_lengths[[x for x in range(0, len(test_lengths)) if x not in outliers]]\n",
    "\n",
    "for sample in tnrange(0, len(test_x)):\n",
    "    filtered = median_filter(test_x[sample, 0, :, :, 10], size = 5)\n",
    "    filtered = np.reshape(filtered, (8, 2, 8, 2))\n",
    "    filtered = np.mean(filtered, axis = (1, 3))\n",
    "    filtered = resize(filtered, (16, 16), 0)\n",
    "    test_x[sample, :, :, :, 10] = np.stack([filtered] * 24)\n",
    "    \n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[:, :, :, :, band] = np.clip(test_x[:, :, :, :, band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    test_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    try:\n",
    "        fm = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "    except Exception:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_11/Sigmoid:0\")\n",
    "inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "length = tf.get_default_graph().get_tensor_by_name(\"Placeholder_1:0\")\n",
    "labels = tf.get_default_graph().get_tensor_by_name(\"Placeholder_2:0\")\n",
    "rmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "rmin = tf.get_default_graph().get_tensor_by_name(\"Placeholder_5:0\")\n",
    "dmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_6:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipping_params = {\n",
    "    'rmax': rmax,\n",
    "    'rmin': rmin,\n",
    "    'dmax': dmax\n",
    "}\n",
    "\n",
    "\n",
    "def run_predictions(x, y, lengths, debug = False):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    diffs = None\n",
    "    for sample in tnrange(x.shape[0]):\n",
    "        if sample not in [558, 563, 596, 599, 602, 615, 634]:\n",
    "            pred = sess.run([fm], feed_dict={inp: x[sample].reshape(1, 24, 16, 16, 16),\n",
    "                                      length: lengths[sample].reshape(1, 1),\n",
    "                                      clipping_params['rmax']: 5,\n",
    "                                      clipping_params['rmin']: 0,\n",
    "                                      clipping_params['dmax']: 3,\n",
    "                                      })\n",
    "            preds.append(np.array(pred).flatten())\n",
    "            trues.append(y[sample].flatten())\n",
    "    if debug:\n",
    "        thresh = 0.58\n",
    "        preds_i = np.copy(preds)\n",
    "        for i in range(len(preds_i)):\n",
    "            preds_i[i] = np.array(preds_i[i])\n",
    "            preds_i[i][np.where(preds_i[i] >= thresh)] = 1.\n",
    "            preds_i[i][np.where(preds_i[i] < thresh)] = 0.\n",
    "        diffs = [abs(np.sum(np.array(a)) - np.sum(np.array(b))) for a, b in zip(preds_i, trues)]\n",
    "    preds = np.concatenate(preds)\n",
    "    trues = np.concatenate(trues)\n",
    "    return preds, trues, diffs\n",
    "\n",
    "def calc_f1(trues, preds, threshold = None):\n",
    "    f1s = []\n",
    "    if not threshold:\n",
    "        for thresh in range(10, 90, 2):\n",
    "            pred_i = np.copy(preds)\n",
    "            pred_i[np.where(pred_i >= thresh / 100)] = 1.\n",
    "            pred_i[np.where(pred_i < thresh / 100)] = 0.\n",
    "            f1 = f1_score(trues, pred_i)\n",
    "            f1s.append(f1)\n",
    "        best_f1 = np.max(f1s)\n",
    "        best_thresh = [x for x in range(10, 90, 2)][np.argmax(np.array(f1s))] / 100\n",
    "    else:\n",
    "        pred_i = np.copy(preds)\n",
    "        pred_i[np.where(pred_i >= threshold)] = 1.\n",
    "        pred_i[np.where(pred_i < threshold)] = 0.\n",
    "        f1 = f1_score(trues, pred_i)\n",
    "        best_f1 = f1\n",
    "        best_thresh = threshold\n",
    "        \n",
    "    return best_f1, best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "\n",
    "test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list):\n",
    "          nrows (int):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(20, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No test augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(start/len(test_ids))\n",
    "test_ids = sorted(test_ids)\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "preds = []\n",
    "trues = []\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    y = sess.run([fm], feed_dict={inp: test_x[idx].reshape(1, 24, 16, 16, 16),\n",
    "                                  length: test_lengths[idx].reshape(1, 1),\n",
    "                                  clipping_params['rmax']: 5,\n",
    "                                  clipping_params['rmin']: 0,\n",
    "                                  clipping_params['dmax']: 3,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    true = test_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "    \n",
    "    \n",
    "\"\"\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "start = start + 8 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, trues, diffs = run_predictions(test_x, test_y, test_lengths, debug = True)\n",
    "best_f1, best_thresh = calc_f1(trues, preds)\n",
    "print(\"F1 score: {}, thresh: {}\".format(best_f1, best_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biome threshold selection\n",
    "\n",
    "- Rainforest\n",
    "- Hyperarid\n",
    "- Temperate\n",
    "- Arid\n",
    "- Grassland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region threshold selection\n",
    "- Latin america\n",
    "- Global\n",
    "- East africa\n",
    "- West africa\n",
    "- India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {'ethiopia-test': [0, 112],\n",
    " 'kenya-test': [113, 201],\n",
    " 'ghana-test': [201, 235],\n",
    " 'ghana-test-large': [235, 271],\n",
    " 'africaeast-test': [271, 306],\n",
    " 'india-test': [306, 357],\n",
    " 'lac-north-test': [357, 398],\n",
    " 'africawest-test': [398, 460],\n",
    " 'cameroon-test': [460, 499],\n",
    " 'lac-south-test': [499, 540],\n",
    " 'global-test': [540, 682]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethiopia\n",
    "f1_diffs = []\n",
    "for i in countries.keys():\n",
    "    start = countries[i][0]\n",
    "    end = countries[i][1]\n",
    "    preds, trues, _ = run_predictions(test_x[start:end], \n",
    "                               test_y[start:end],\n",
    "                               test_lengths[start:end])\n",
    "    \n",
    "    best_f1, best_thresh = calc_f1(trues, preds)\n",
    "    orig_f1, _ = calc_f1(trues, preds, threshold = 0.56)\n",
    "    f1_diffs.append(best_f1 - orig_f1)\n",
    "    print(\"{}: original F1: {}\".format(i, orig_f1))\n",
    "    print(\"{}: F1 score: {}, thresh: {}\".format(i, best_f1, best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.846 + np.mean(f1_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.array(diffs) / 1.96, bins = 50, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(np.array(diffs) / 1.96, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small pixel recovering\n",
    "\n",
    "# To do: grid search over a range of thresholds and options to ID best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_pixels(stacked, thresh, thresh_p):\n",
    "    \n",
    "    for window_x in range(2, stacked.shape[0]-2, 1):\n",
    "        for window_y in range(2, stacked.shape[1]-2, 1):\n",
    "            l, r, u, d =  False, False, False, False\n",
    "            cur_window = stacked[window_x-2:window_x+3, window_y-2:window_y+3]\n",
    "            hor_vert_neighbors = False\n",
    "            if (cur_window[2, 2] > thresh and\n",
    "                cur_window[2, 2] < thresh_p):\n",
    "                if cur_window[3, 2] > thresh * 2 and cur_window[4, 2] < thresh * 2 :\n",
    "                    hor_vert_neighbors = True\n",
    "                    r = True\n",
    "                if cur_window[1, 2] > thresh * 2 and cur_window[2, 0] < thresh * 2:\n",
    "                    hor_vert_neighbors = True\n",
    "                    l = True\n",
    "                if cur_window[2, 3] > thresh * 2 and cur_window[2, 4] < thresh * 2:\n",
    "                    hor_vert_neighbors = True\n",
    "                    d = True\n",
    "                if cur_window[2, 1] > thresh * 2 and cur_window[2, 0] < thresh * 2:\n",
    "                    hor_vert_neighbors = True\n",
    "                    u = True\n",
    "            passes = False\n",
    "            if r and not l:\n",
    "                passes = True\n",
    "            if l and not r:\n",
    "                passes = True\n",
    "            if d and not u:\n",
    "                passes = True\n",
    "            if u and not d:\n",
    "                passes = True\n",
    "\n",
    "            if passes:\n",
    "                if r:\n",
    "                    if cur_window[1, 1] < thresh * 2 and cur_window[1, 3] < thresh * 2:\n",
    "                        #print(\"Adding a tree with: {}\".format(cur_window[2, 2]))\n",
    "                        stacked[window_x, window_y] = (thresh_p + 0.01)\n",
    "\n",
    "                if l:\n",
    "                    if cur_window[3, 1] < thresh * 2 and cur_window[3, 3] < thresh * 2:\n",
    "                        #print(\"Adding a tree with: {}\".format(cur_window[2, 2]))\n",
    "                        stacked[window_x, window_y] = (thresh_p + 0.01)\n",
    "\n",
    "                if u:\n",
    "                    if cur_window[1, 3] < thresh * 2 and cur_window[3, 3] < thresh * 2:\n",
    "                        #print(\"Adding a tree with: {}\".format(cur_window[2, 2]))\n",
    "                        stacked[window_x, window_y] = (thresh_p + 0.01)\n",
    "\n",
    "                if d:\n",
    "                    if cur_window[1, 1] < thresh * 2 and cur_window[3, 1] < thresh * 2:\n",
    "                        #print(\"Adding a tree with: {}\".format(cur_window[2, 2]))\n",
    "                        stacked[window_x, window_y] = (thresh_p + 0.01)\n",
    "                        \n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(start/len(test_ids))\n",
    "test_ids = sorted(test_ids)\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "preds = []\n",
    "trues = []\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    y = sess.run([fm], feed_dict={inp: test_x[idx].reshape(1, 24, 16, 16, 16),\n",
    "                                  length: test_lengths[idx].reshape(1, 1),\n",
    "                                  clipping_params['rmax']: 5,\n",
    "                                  clipping_params['rmin']: 0,\n",
    "                                  clipping_params['dmax']: 3,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    y2 = np.copy(y)\n",
    "    y[np.where(y >= 0.5)] = 1.\n",
    "    y[np.where(y < 0.5)] = 0.\n",
    "    \n",
    "    initial_f1 = f1_score(test_y[idx].flatten(), y.flatten())\n",
    "    y2 = recover_pixels(y2, 0.4, 0.58)\n",
    "    y2[np.where(y2 >= 0.5)] = 1.\n",
    "    y2[np.where(y2 < 0.5)] = 0.\n",
    "    after_f1 = f1_score(test_y[idx].flatten(), y2.flatten())\n",
    "    #print(after_f1 - initial_f1)\n",
    "    print(idx, abs(np.sum(y) - np.sum(test_y[idx])))\n",
    "    \n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    true = test_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "    \n",
    "    \n",
    "\"\"\n",
    "\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "start = start + 8 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth windowed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fspecial_gauss(size, sigma):\n",
    "\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g\n",
    "\n",
    "arr = fspecial_gauss(14, 3)\n",
    "arr = arr[:7, :7]\n",
    "sns.heatmap(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filter = np.concatenate([arr, np.flip(arr, 0)], 0)\n",
    "base_filter = np.concatenate([base_filter, np.flip(base_filter, 1)], 1) \n",
    "sns.heatmap(base_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_filter = base_filter[:, 7:]\n",
    "right_filter = np.pad(right_filter, ((0, 0), (0, 7)), mode = 'constant', constant_values = 0)\n",
    "sns.heatmap(right_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_filter = base_filter[:, :7]\n",
    "left_filter = np.pad(left_filter, ((0, 0), (7, 0)), mode = 'constant', constant_values = 0)\n",
    "sns.heatmap(left_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_filter = base_filter[:7, :]\n",
    "up_filter = np.pad(up_filter, ((7, 0), (0, 0)), mode = 'constant', constant_values = 0)\n",
    "sns.heatmap(up_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_filter = base_filter[7:, :]\n",
    "down_filter = np.pad(down_filter, ((0, 7), (0, 0)), mode = 'constant', constant_values = 0)\n",
    "sns.heatmap(down_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums =  base_filter + down_filter + up_filter + left_filter + right_filter \n",
    "left_filter /= sums\n",
    "right_filter /= sums\n",
    "base_filter /= sums\n",
    "down_filter /= sums\n",
    "up_filter /= sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(base_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(left_filter[:, 7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "test_x = np.load(\"../tile_data/processed/test_x_tile.npy\")\n",
    "test_y = np.load(\"../tile_data/processed/test_y_tile.npy\")\n",
    "test_lengths = np.array([24] * len(test_x))\n",
    "\n",
    "test_x = np.delete(test_x, 14, -1)\n",
    "\n",
    "outliers = [594, 547, 572]\n",
    "        \n",
    "test_x = test_x[[x for x in range(0, len(test_x)) if x not in outliers]]\n",
    "test_y = test_y[[x for x in range(0, len(test_y)) if x not in outliers]]\n",
    "test_lengths = test_lengths[[x for x in range(0, len(test_lengths)) if x not in outliers]]\n",
    "\n",
    "for sample in tnrange(0, len(test_x)):\n",
    "    filtered = median_filter(test_x[sample, 0, :, :, 10], size = 5)\n",
    "    filtered = np.reshape(filtered, (16, 2, 16, 2))\n",
    "    filtered = np.mean(filtered, axis = (1, 3))\n",
    "    filtered = resize(filtered, (32, 32), 0)\n",
    "    test_x[sample, :, :, :, 10] = np.stack([filtered] * 24)\n",
    "    \n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[:, :, :, :, band] = np.clip(test_x[:, :, :, :, band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    test_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x[:, :, 8:-8, 8:-8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, trues, diffs = run_predictions(test_x, test_y, test_lengths, debug = False)\n",
    "best_f1, best_thresh = calc_f1(trues, preds)\n",
    "print(\"F1 score: {}, thresh: {}\".format(best_f1, best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_lookups = { #'x_start, y_start'\n",
    "    'center': [8, 8],\n",
    "    'down': [1, 8],\n",
    "    'up': [15, 8],\n",
    "    'right': [8, 15],\n",
    "    'left': [8, 1],\n",
    "    'ul': [16, 0],\n",
    "    'ur': [16, 16],\n",
    "    'dl': [0, 0],\n",
    "    'dr': [0, 16],\n",
    "}\n",
    "\n",
    "def make_5d_array(arr, tile_lookups):\n",
    "    arr_5d = np.empty((9, 24, 16, 16, 16))\n",
    "    print(arr.shape)\n",
    "    for i in range(len(tile_lookups.keys())):\n",
    "        key = list(tile_lookups.keys())[i]\n",
    "        start_x = tile_lookups[key][0]\n",
    "        start_y = tile_lookups[key][1]\n",
    "        arr_5d[i] = arr[:24, start_x:start_x+16, start_y:start_y+16, :]\n",
    "    return arr_5d\n",
    "\n",
    "def reconstruct_array(arr):\n",
    "    \n",
    "    out = np.copy(arr[0])\n",
    "    \n",
    "    center = arr[0] * base_filter\n",
    "    down = arr[1][7:, :]\n",
    "    down = np.pad(down, ((0, 7), (0, 0)), mode = 'constant', constant_values = 0)\n",
    "    down *= down_filter\n",
    "    \n",
    "    up = arr[2][:7, :]\n",
    "    up = np.pad(up, ((7, 0), (0, 0)), mode = 'constant', constant_values = 0)\n",
    "    up *= up_filter\n",
    "    \n",
    "    left = arr[4][:, 7:]\n",
    "    left = np.pad(left, ((0, 0), (0, 7)), mode = 'constant', constant_values = 0)\n",
    "    left *= right_filter\n",
    "    \n",
    "    right = arr[3][:, :7]\n",
    "    right = np.pad(right, ((0, 0), (7, 0)), mode = 'constant', constant_values = 0)\n",
    "    right *= left_filter\n",
    "    \n",
    "    \n",
    "    \n",
    "    #down = (arr[1] * up_filter)[7:, :]\n",
    "    #up = (arr[2] * down_filter)[:7, :]\n",
    "    #right = (arr[3] * right_filter)[:, :7]\n",
    "    #left = (arr[4] * left_filter)[:, 7:]\n",
    "\n",
    "    #out[:, 7:] = center[:, 7:] + right\n",
    "    #out[:, :7] = center[:, :7] + left\n",
    "    #out[:7, :] = center[:7, :] + down\n",
    "    #out[7:, :] = center[7:, :] + up\n",
    "\n",
    "    return (center + down + up + right + left)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 65\n",
    "\n",
    "def run_5d_array(idx):\n",
    "    five_d = make_5d_array(test_x[idx], tile_lookups)\n",
    "\n",
    "    y = sess.run([fm], feed_dict={inp: five_d[0].reshape(1, 24, 16, 16, 16),\n",
    "                                  length: test_lengths[0].reshape(1, 1),\n",
    "                                  clipping_params['rmax']: 5,\n",
    "                                  clipping_params['rmin']: 0,\n",
    "                                  clipping_params['dmax']: 3,\n",
    "                                  })\n",
    "    ys = []\n",
    "    for i in range(0, 9):\n",
    "        y = sess.run([fm], feed_dict={inp: five_d[i].reshape(1, 24, 16, 16, 16),\n",
    "                                      length: test_lengths[0].reshape(1, 1),\n",
    "                                      clipping_params['rmax']: 5,\n",
    "                                      clipping_params['rmin']: 0,\n",
    "                                      clipping_params['dmax']: 3,\n",
    "                                      })\n",
    "        ys.append(np.array(y).reshape((14, 14)))\n",
    "    ys = np.stack(ys)\n",
    "    pr = reconstruct_array(ys)\n",
    "    return pr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = run_5d_array(14)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed = [run_5d_array(x) for x in range(0, len(test_x))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigma = 3.5\n",
    "preds = np.stack(windowed).flatten()\n",
    "best_f1, best_thresh = calc_f1(np.stack(test_y).flatten(), preds)\n",
    "print(\"F1 score: {}, thresh: {}\".format(best_f1, best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigma = 2.0\n",
    "preds = np.stack(windowed).flatten()\n",
    "best_f1, best_thresh = calc_f1(np.stack(test_y).flatten(), preds)\n",
    "print(\"F1 score: {}, thresh: {}\".format(best_f1, best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_y[idx].reshape((14, 14)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
