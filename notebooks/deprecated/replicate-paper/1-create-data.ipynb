{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aridity calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aridity = pd.read_csv(\"../../data/latlongs/test_plots_aridity.csv\")\n",
    "aridity['aiet0'] /= 10000\n",
    "aridity['aridity'] = pd.cut(aridity['aiet0'],\n",
    "                            [0, 0.03, 0.2, 0.5, 0.65, np.max(aridity['aiet0'])],\n",
    "                            labels = ['Hyper Arid', 'Arid', 'Semi-Arid',\n",
    "                            'Dry Subhumid', 'Humid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = pd.read_csv(\"../../data/metrics/metadata/metadata.csv\")\n",
    "continents.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = pd.read_csv(\"../../data/latlongs/test_continents.csv\")\n",
    "continents.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = []\n",
    "slopes = []\n",
    "ids = continents['id']\n",
    "for i in ids:\n",
    "    cloud = np.load(\"../../data/raw/test-clouds/{}.npy\".format(str(i)))\n",
    "    data = np.load(\"../../data/test-s2/{}.npy\".format(str(i)))\n",
    "    slopes.append(np.mean(data[0, :, :, 10]))\n",
    "    cloud_percents = [len(np.argwhere(cloud[i].flatten() > 0.3)) for i in range(cloud.shape[0])]\n",
    "    cloud_percents = np.array(cloud_percents) / cloud.shape[1]*cloud.shape[2]\n",
    "    cloud_percents = len(np.argwhere(cloud_percents > 0.2)) / len(cloud_percents)\n",
    "    clouds.append(cloud_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents['clouds'] = clouds\n",
    "continents['slopes'] = slopes\n",
    "continents.to_csv(\"../../data/metrics/metadata/metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load proposed model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"../../data/metrics/proposed-sample.csv\")\n",
    "proposed = proposed.join(continents, how = 'inner')\n",
    "proposed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_l = []\n",
    "means = []\n",
    "means_u = []\n",
    "proposed['ccgroup'] = 0\n",
    "proposed['ccgroup'][(proposed['group'] >= 30) & (proposed['group'] <= 70)] = 1\n",
    "for i in range(0, 100, 10):\n",
    "    group = proposed[proposed['group'] == i]\n",
    "    ci = mean_confidence_interval(group['error'], 0.95)\n",
    "    if i >= 30 and i <= 70:\n",
    "        means_l.append(ci[0])\n",
    "        means_u.append(ci[2])\n",
    "        means.append(ci[1])\n",
    "        print(i, ci)\n",
    "print(np.mean(means_l), np.mean(means), np.mean(means_u))\n",
    "\n",
    "print(mean_confidence_interval(proposed[proposed['ccgroup'] == 1]['error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confidence_interval(proposed['error'], 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed.sum()['tp_soft']\n",
    "fp = proposed.sum()['fp_soft']\n",
    "fn = proposed.sum()['fn_soft']\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(proposed['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aridity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = proposed.join(aridity)\n",
    "proposed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = proposed.groupby(\"aridity\").sum()\n",
    "for i in proposed['aridity'].unique():\n",
    "    tp = sums[sums.index == i]['tp_soft']\n",
    "    fp = sums[sums.index == i]['fp_soft']\n",
    "    fn = sums[sums.index == i]['fn_soft']\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(i, float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = proposed.groupby(\"CONTINENT\").sum()\n",
    "for i in ['Africa', 'Asia', \"Australia\", \"Europe\", \"North America\", \"South America\"]:\n",
    "    tp = sums[sums.index == i]['tp_soft']\n",
    "    fp = sums[sums.index == i]['fp_soft']\n",
    "    fn = sums[sums.index == i]['fn_soft']\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(i, float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['clouds'] < 0.75].sum()['tp_soft']\n",
    "fp = proposed[proposed['clouds'] < 0.75].sum()['fp_soft']\n",
    "fn = proposed[proposed['clouds'] < 0.75].sum()['fn_soft']\n",
    "error = proposed[proposed['clouds'] < 0.75].mean()['error']\n",
    "count = proposed[proposed['clouds'] < 0.75].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 0.75 cloud: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['clouds'] >= 0.75].sum()['tp_soft']\n",
    "fp = proposed[proposed['clouds'] >= 0.75].sum()['fp_soft']\n",
    "fn = proposed[proposed['clouds'] >= 0.75].sum()['fn_soft']\n",
    "error = proposed[proposed['clouds'] >= 0.75].mean()['error']\n",
    "count = proposed[proposed['clouds'] >= 0.75].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Above 0.75 cloud: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slope metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['slopes'] < 0.1].sum()['tp_soft']\n",
    "fp = proposed[proposed['slopes'] < 0.1].sum()['fp_soft']\n",
    "fn = proposed[proposed['slopes'] < 0.1].sum()['fn_soft']\n",
    "error = proposed[proposed['slopes'] < 0.1].mean()['error']\n",
    "count = proposed[proposed['slopes'] < 0.1].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 0.1 slope: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['slopes'] >= 0.1].sum()['tp_soft']\n",
    "fp = proposed[proposed['slopes'] >= 0.1].sum()['fp_soft']\n",
    "fn = proposed[proposed['slopes'] >= 0.1].sum()['fn_soft']\n",
    "error = proposed[proposed['slopes'] >= 0.1].mean()['error']\n",
    "count = proposed[proposed['slopes'] >= 0.1].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Above 0.1 slope: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canopy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'] < 20].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'] < 20].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'] < 20].sum()['fn_soft']\n",
    "error = proposed[proposed['true'] < 20].mean()['error']\n",
    "count = proposed[proposed['true'] < 20].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 20%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(20, 40)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(20, 40)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(20, 40)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(20, 40)].mean()['error']\n",
    "count = proposed[proposed['true'].between(20, 40)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Between 20 and 40%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(0, 40)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(0, 40)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(0, 40)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(0, 40)].mean()['error']\n",
    "count = proposed[proposed['true'].between(0, 40)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Between 0 and 40%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(40, 60)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(40, 60)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(40, 60)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(40, 60)].mean()['error']\n",
    "count = proposed[proposed['true'].between(40, 60)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Between 40 and 60%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(60, 101)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(60, 101)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(60, 101)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(60, 101)].mean()['error']\n",
    "count = proposed[proposed['true'].between(60, 101)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Between 60 and 100%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"../../data/metrics/proposed.csv\")\n",
    "print(proposed.mean()['soft_prec'], proposed.mean()['soft_rec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Random forest predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"../../data/metrics/rf.csv\")\n",
    "print(proposed.mean()['soft_prec'], proposed.mean()['soft_rec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"../../data/metrics/rf-sample.csv\")\n",
    "proposed = proposed.drop(['Unnamed: 0'], axis = 1)\n",
    "proposed = proposed.drop(['lats'], axis = 1)\n",
    "proposed = proposed.drop(['longs'], axis = 1)\n",
    "\n",
    "\n",
    "proposed = proposed.join(continents, how = 'inner')\n",
    "proposed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = proposed.join(aridity)\n",
    "sums = proposed.groupby(\"aridity\").sum()\n",
    "for i in proposed['aridity'].unique():\n",
    "    tp = sums[sums.index == i]['tp_soft']\n",
    "    fp = sums[sums.index == i]['fp_soft']\n",
    "    fn = sums[sums.index == i]['fn_soft']\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(i, float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_l = []\n",
    "means = []\n",
    "means_u = []\n",
    "proposed['ccgroup'] = 0\n",
    "proposed['ccgroup'][(proposed['group'] >= 30) & (proposed['group'] <= 70)] = 1\n",
    "for i in range(0, 100, 10):\n",
    "    group = proposed[proposed['group'] == i]\n",
    "    ci = mean_confidence_interval(group['error'], 0.95)\n",
    "    if i >= 30 and i <= 70:\n",
    "        means_l.append(ci[0])\n",
    "        means_u.append(ci[2])\n",
    "        means.append(ci[1])\n",
    "        print(i, ci)\n",
    "print(np.mean(means_l), np.mean(means), np.mean(means_u))\n",
    "\n",
    "print(mean_confidence_interval(proposed[proposed['ccgroup'] == 1]['error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confidence_interval(proposed['error'], 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = proposed.groupby(\"CONTINENT\").sum()\n",
    "for i in ['Africa', 'Asia', \"Australia\", \"Europe\", \"North America\", \"South America\"]:\n",
    "    tp = sums[sums.index == i]['tp_soft']\n",
    "    fp = sums[sums.index == i]['fp_soft']\n",
    "    fn = sums[sums.index == i]['fn_soft']\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(i, float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'] < 20].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'] < 20].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'] < 20].sum()['fn_soft']\n",
    "error = proposed[proposed['true'] < 20].mean()['error']\n",
    "count = proposed[proposed['true'] < 20].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 20%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(20, 40)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(20, 40)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(20, 40)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(20, 40)].mean()['error']\n",
    "count = proposed[proposed['true'].between(20, 40)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 40%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(40, 60)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(40, 60)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(40, 60)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(40, 60)].mean()['error']\n",
    "count = proposed[proposed['true'].between(40, 60)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"40 - 60 %: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'] >= 60].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'] >= 60].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'] >= 60].sum()['fn_soft']\n",
    "error = proposed[proposed['true'] >= 60].mean()['error']\n",
    "count = proposed[proposed['true'] >= 60].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Greater than 60%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['clouds'] < 0.75].sum()['tp_soft']\n",
    "fp = proposed[proposed['clouds'] < 0.75].sum()['fp_soft']\n",
    "fn = proposed[proposed['clouds'] < 0.75].sum()['fn_soft']\n",
    "error = proposed[proposed['clouds'] < 0.75].mean()['error']\n",
    "count = proposed[proposed['clouds'] < 0.75].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 0.75 cloud: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['clouds'] >= 0.75].sum()['tp_soft']\n",
    "fp = proposed[proposed['clouds'] >= 0.75].sum()['fp_soft']\n",
    "fn = proposed[proposed['clouds'] >= 0.75].sum()['fn_soft']\n",
    "error = proposed[proposed['clouds'] >= 0.75].mean()['error']\n",
    "count = proposed[proposed['clouds'] >= 0.75].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Above 0.75 cloud: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['slopes'] < 0.1].sum()['tp_soft']\n",
    "fp = proposed[proposed['slopes'] < 0.1].sum()['fp_soft']\n",
    "fn = proposed[proposed['slopes'] < 0.1].sum()['fn_soft']\n",
    "error = proposed[proposed['slopes'] < 0.1].mean()['error']\n",
    "count = proposed[proposed['slopes'] < 0.1].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 0.1 slope: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['slopes'] >= 0.1].sum()['tp_soft']\n",
    "fp = proposed[proposed['slopes'] >= 0.1].sum()['fp_soft']\n",
    "fn = proposed[proposed['slopes'] >= 0.1].sum()['fn_soft']\n",
    "error = proposed[proposed['slopes'] >= 0.1].mean()['error']\n",
    "count = proposed[proposed['slopes'] >= 0.1].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Above 0.1 slope: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"../../data/metrics/rf.csv\")\n",
    "print(proposed.mean()['soft_prec'], proposed.mean()['soft_rec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load U-Net forest predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"../../data/metrics/unet-sample.csv\")\n",
    "proposed = proposed.drop(['Unnamed: 0'], axis = 1)\n",
    "proposed = proposed.join(continents, how = 'inner')\n",
    "proposed = proposed.drop(['lats'], axis = 1)\n",
    "proposed = proposed.drop(['longs'], axis = 1)\n",
    "proposed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed.groupby(\"aridity\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = proposed.merge(aridity, on = 'id')\n",
    "sums = proposed.groupby(\"aridity\").sum()\n",
    "for i in proposed['aridity'].unique():\n",
    "    tp = sums[sums.index == i]['tp_soft']\n",
    "    fp = sums[sums.index == i]['fp_soft']\n",
    "    fn = sums[sums.index == i]['fn_soft']\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(i, float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_l = []\n",
    "means = []\n",
    "means_u = []\n",
    "proposed['ccgroup'] = 0\n",
    "proposed['ccgroup'][(proposed['group'] >= 30) & (proposed['group'] <= 70)] = 1\n",
    "for i in range(0, 100, 10):\n",
    "    group = proposed[proposed['group'] == i]\n",
    "    ci = mean_confidence_interval(group['error'], 0.95)\n",
    "    if i >= 30 and i <= 70:\n",
    "        means_l.append(ci[0])\n",
    "        means_u.append(ci[2])\n",
    "        means.append(ci[1])\n",
    "        print(i, ci)\n",
    "print(np.mean(means_l), np.mean(means), np.mean(means_u))\n",
    "\n",
    "print(mean_confidence_interval(proposed[proposed['ccgroup'] == 1]['error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confidence_interval(proposed['error'], 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = proposed.groupby(\"CONTINENT\").sum()\n",
    "for i in ['Africa', 'Asia', \"Australia\", \"Europe\", \"North America\", \"South America\"]:\n",
    "    tp = sums[sums.index == i]['tp_soft']\n",
    "    fp = sums[sums.index == i]['fp_soft']\n",
    "    fn = sums[sums.index == i]['fn_soft']\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(i, float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'] < 20].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'] < 20].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'] < 20].sum()['fn_soft']\n",
    "error = proposed[proposed['true'] < 20].mean()['error']\n",
    "count = proposed[proposed['true'] < 20].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 20%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(20, 40)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(20, 40)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(20, 40)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(20, 40)].mean()['error']\n",
    "count = proposed[proposed['true'].between(20, 40)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Between 20 and 40%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(40, 60)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(40, 60)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(40, 60)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(40, 60)].mean()['error']\n",
    "count = proposed[proposed['true'].between(40, 60)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"40 - 60 %: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'] >= 60].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'] >= 60].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'] >= 60].sum()['fn_soft']\n",
    "error = proposed[proposed['true'] >= 60].mean()['error']\n",
    "count = proposed[proposed['true'] >= 60].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Greater than 60%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['clouds'] >= 0.75].sum()['tp_soft']\n",
    "fp = proposed[proposed['clouds'] >= 0.75].sum()['fp_soft']\n",
    "fn = proposed[proposed['clouds'] >= 0.75].sum()['fn_soft']\n",
    "error = proposed[proposed['clouds'] >= 0.75].mean()['error']\n",
    "count = proposed[proposed['clouds'] >= 0.75].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Above 0.75 cloud: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['slopes'] >= 0.1].sum()['tp_soft']\n",
    "fp = proposed[proposed['slopes'] >= 0.1].sum()['fp_soft']\n",
    "fn = proposed[proposed['slopes'] >= 0.1].sum()['fn_soft']\n",
    "error = proposed[proposed['slopes'] >= 0.1].mean()['error']\n",
    "count = proposed[proposed['slopes'] >= 0.1].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Above 0.1 slope: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['slopes'] < 0.1].sum()['tp_soft']\n",
    "fp = proposed[proposed['slopes'] < 0.1].sum()['fp_soft']\n",
    "fn = proposed[proposed['slopes'] < 0.1].sum()['fn_soft']\n",
    "error = proposed[proposed['slopes'] < 0.1].mean()['error']\n",
    "count = proposed[proposed['slopes'] < 0.1].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 0.1 slope: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['clouds'] < 0.75].sum()['tp_soft']\n",
    "fp = proposed[proposed['clouds'] < 0.75].sum()['fp_soft']\n",
    "fn = proposed[proposed['clouds'] < 0.75].sum()['fn_soft']\n",
    "error = proposed[proposed['clouds'] < 0.75].mean()['error']\n",
    "count = proposed[proposed['clouds'] < 0.75].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 0.75 cloud: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"../../data/metrics/unet.csv\")\n",
    "print(proposed.mean()['soft_prec'], proposed.mean()['soft_rec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SVM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = pd.read_csv(\"../../data/metrics/SVM-sample.csv\")\n",
    "proposed = proposed.drop(['Unnamed: 0'], axis = 1)\n",
    "proposed = proposed.drop(['lats'], axis = 1)\n",
    "proposed = proposed.join(continents, how = 'inner')\n",
    "proposed.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed = proposed.join(aridity)\n",
    "sums = proposed.groupby(\"aridity\").sum()\n",
    "for i in proposed['aridity'].unique():\n",
    "    tp = sums[sums.index == i]['tp_soft']\n",
    "    fp = sums[sums.index == i]['fp_soft']\n",
    "    fn = sums[sums.index == i]['fn_soft']\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(i, float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = proposed.groupby(\"CONTINENT\").sum()\n",
    "for i in ['Africa', 'Asia', \"Australia\", \"Europe\", \"North America\", \"South America\"]:\n",
    "    tp = sums[sums.index == i]['tp_soft']\n",
    "    fp = sums[sums.index == i]['fp_soft']\n",
    "    fn = sums[sums.index == i]['fn_soft']\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(i, float(precision), float(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['clouds'] < 0.75].sum()['tp_soft']\n",
    "fp = proposed[proposed['clouds'] < 0.75].sum()['fp_soft']\n",
    "fn = proposed[proposed['clouds'] < 0.75].sum()['fn_soft']\n",
    "error = proposed[proposed['clouds'] < 0.75].mean()['error']\n",
    "count = proposed[proposed['clouds'] < 0.75].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 0.75 cloud: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['clouds'] >= 0.75].sum()['tp_soft']\n",
    "fp = proposed[proposed['clouds'] >= 0.75].sum()['fp_soft']\n",
    "fn = proposed[proposed['clouds'] >= 0.75].sum()['fn_soft']\n",
    "error = proposed[proposed['clouds'] >= 0.75].mean()['error']\n",
    "count = proposed[proposed['clouds'] >= 0.75].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Above 0.75 cloud: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'] < 20].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'] < 20].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'] < 20].sum()['fn_soft']\n",
    "error = proposed[proposed['true'] < 20].mean()['error']\n",
    "count = proposed[proposed['true'] < 20].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 20%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(20, 40)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(20, 40)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(20, 40)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(20, 40)].mean()['error']\n",
    "count = proposed[proposed['true'].between(20, 40)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Between 20 and 40%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'].between(40, 60)].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'].between(40, 60)].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'].between(40, 60)].sum()['fn_soft']\n",
    "\n",
    "error = proposed[proposed['true'].between(40, 60)].mean()['error']\n",
    "count = proposed[proposed['true'].between(40, 60)].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Between 20 and 40%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['true'] >= 60].sum()['tp_soft']\n",
    "fp = proposed[proposed['true'] >= 60].sum()['fp_soft']\n",
    "fn = proposed[proposed['true'] >= 60].sum()['fn_soft']\n",
    "error = proposed[proposed['true'] >= 60].mean()['error']\n",
    "count = proposed[proposed['true'] >= 60].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Greater than 60%: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['slopes'] < 0.1].sum()['tp_soft']\n",
    "fp = proposed[proposed['slopes'] < 0.1].sum()['fp_soft']\n",
    "fn = proposed[proposed['slopes'] < 0.1].sum()['fn_soft']\n",
    "error = proposed[proposed['slopes'] < 0.1].mean()['error']\n",
    "count = proposed[proposed['slopes'] < 0.1].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Below 0.1 slope: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = proposed[proposed['slopes'] >= 0.1].sum()['tp_soft']\n",
    "fp = proposed[proposed['slopes'] >= 0.1].sum()['fp_soft']\n",
    "fn = proposed[proposed['slopes'] >= 0.1].sum()['fn_soft']\n",
    "error = proposed[proposed['slopes'] >= 0.1].mean()['error']\n",
    "count = proposed[proposed['slopes'] >= 0.1].count()['error'] * 196\n",
    "\n",
    "\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Above 0.1 slope: \", precision, recall, error, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
