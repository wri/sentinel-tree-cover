{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process Sentinel 1 data\n",
    "\n",
    "This notebook downloads and processes one year of Sentinel 1 data for training and testing plots labelled in Collect Earth Online.\n",
    "\n",
    "## John Brandt\n",
    "## July 12, 2021\n",
    "\n",
    "## Package imports, API import, source scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import scipy.sparse as sparse\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from scipy.sparse.linalg import splu\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType\n",
    "from sentinelhub import CRS, BBox, constants, DataSource, CustomUrlParam\n",
    "from skimage.transform import resize\n",
    "from sentinelhub.config import SHConfig\n",
    "\n",
    "import reverse_geocoder as rg\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "import hickle as hkl\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY = key['key']\n",
    "    SHUB_SECRET = key['shub_secret']\n",
    "    SHUB_KEY = key['shub_id']\n",
    "    AWSKEY = key['awskey']\n",
    "    AWSSECRET = key['awssecret']\n",
    "            \n",
    "shconfig = SHConfig()\n",
    "shconfig.instance_id = API_KEY\n",
    "shconfig.sh_client_id = SHUB_KEY\n",
    "shconfig.sh_client_secret = SHUB_SECRET\n",
    "        \n",
    "%matplotlib inline\n",
    "%run ../src/downloading/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('2020-12-15', '2022-01-15')\n",
    "YEAR = 2021\n",
    "IMSIZE = 32\n",
    "\n",
    "starting_days = np.cumsum([0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_s1_layer(coords: list) -> str:\n",
    "    coords = (coords[1], coords[0])\n",
    "    results = rg.search(coords)\n",
    "    admin1 = (results[-1]['admin1'])\n",
    "    admin2 = results[-1]['admin2']\n",
    "    country = results[-1]['cc']\n",
    "    continent_name = pc.country_alpha2_to_continent_code(country)\n",
    "    print(admin1, admin2, country, continent_name)\n",
    "    if continent_name in ['AF', 'OC', 'EU']:\n",
    "        layer = \"SENT\"\n",
    "    if continent_name in ['SA']:\n",
    "        if coords[0] > -7.11:\n",
    "            layer = \"SENT\"\n",
    "        else:\n",
    "            layer = \"SENT_DESC\"\n",
    "    if continent_name in ['AS']:\n",
    "        if coords[0] > 23.3:\n",
    "            layer = \"SENT\"\n",
    "        else:\n",
    "            layer = \"SENT_DESC\"\n",
    "    if continent_name in ['NA']:\n",
    "        layer = \"SENT_DESC\"\n",
    "    return layer\n",
    "\n",
    "\n",
    "def calc_bbox(plot_id: int, df: pd.DataFrame) -> list:\n",
    "    \"\"\" Calculates the corners of a bounding box from an input\n",
    "        pandas dataframe as output by Collect Earth Online\n",
    "\n",
    "        Parameters:\n",
    "         plot_id (int): plot_id of associated plot\n",
    "         df (pandas.DataFrame): dataframe of associated CEO survey\n",
    "    \n",
    "        Returns:\n",
    "         bounding_box (list): [(min(x), min(y)),\n",
    "                              (max(x), max_y))]\n",
    "    \"\"\"\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "\n",
    "def bounding_box(points: list, expansion: int = 160) -> (tuple, 'CRS'):\n",
    "    \"\"\" Calculates the corners of a bounding box with an\n",
    "        input expansion in meters from a given bounding_box\n",
    "        \n",
    "        Subcalls:\n",
    "         calculate_epsg, convertCoords\n",
    "\n",
    "        Parameters:\n",
    "         points (list): output of calc_bbox\n",
    "         expansion (float): number of meters to expand or shrink the\n",
    "                            points edges to be\n",
    "    \n",
    "        Returns:\n",
    "         bl (tuple): x, y of bottom left corner with edges of expansion meters\n",
    "         tr (tuple): x, y of top right corner with edges of expansion meters\n",
    "    \"\"\"\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    inproj = Proj('epsg:4326')\n",
    "    outproj_code = calculate_epsg(bl)\n",
    "    outproj = Proj('epsg:' + str(outproj_code))\n",
    "    \n",
    "    bl_utm =  transform(inproj, outproj, bl[1], bl[0])\n",
    "    tr_utm =  transform(inproj, outproj, tr[1], tr[0])\n",
    "\n",
    "    distance1 = tr_utm[0] - bl_utm[0]\n",
    "    distance2 = tr_utm[1] - bl_utm[1]\n",
    "    expansion1 = (expansion - distance1)/2\n",
    "    expansion2 = (expansion - distance2)/2\n",
    "    \n",
    "    bl_utm = [bl_utm[0] - expansion1, bl_utm[1] - expansion2]\n",
    "    tr_utm = [tr_utm[0] + expansion1, tr_utm[1] + expansion2]\n",
    "    \n",
    "    zone = str(outproj_code)[3:]\n",
    "    zone = zone[1:] if zone[0] == \"0\" else zone\n",
    "    direction = 'N' if tr[1] >= 0 else 'S'\n",
    "    utm_epsg = \"UTM_\" + zone + direction\n",
    "    return (bl_utm, tr_utm), CRS[utm_epsg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dates(date_dict: dict, year: int) -> List:\n",
    "    \"\"\" Transforms a SentinelHub date dictionary to a\n",
    "         list of integer calendar dates\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "    starting_days = np.cumsum(days_per_month)\n",
    "    for date in date_dict:\n",
    "        if date.year == year - 1:\n",
    "            dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year:\n",
    "            dates.append(starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year + 1:\n",
    "            dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "    return dates\n",
    "\n",
    "\n",
    "def identify_dates_to_download(dates: list) -> list:\n",
    "    \"\"\" Identify the S1 dates to download\"\"\"\n",
    "    days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "    days_per_month = np.array(days_per_month)\n",
    "    #days_per_month = np.reshape(days_per_month, (4, 3))\n",
    "    #days_per_month = np.sum(days_per_month, axis = 1)\n",
    "\n",
    "    starting_days = np.cumsum(days_per_month)\n",
    "\n",
    "    dates = np.array(dates)\n",
    "    dates_to_download = []\n",
    "    for i in starting_days:\n",
    "        s1_month = dates[dates > i]\n",
    "        s1_month = s1_month[s1_month < (i + 30)]\n",
    "        if len(s1_month) > 0:\n",
    "            dates_to_download.append(s1_month[0])\n",
    "    return dates_to_download\n",
    "\n",
    "\n",
    "def download_sentinel_1(bbox, epsg, time = time, \n",
    "                        layer = \"SENT\", year = YEAR, \n",
    "                        image_format = MimeType.TIFF, \n",
    "                        data = DataSource.SENTINEL1_IW_ASC):\n",
    "    \"\"\" Downloads all 10 and 20 meter L2A bands from sentinel-hub\n",
    "        for input bbox and epsg, within time range\n",
    "        \n",
    "        Parameters:\n",
    "         bbox (list): output of calc_bbox\n",
    "         epsg (float): UTM EPSG associated with bbox \n",
    "         time (tuple): YY-MM-DD - YY-MM-DD bounds for downloading \n",
    "    \n",
    "        Returns:\n",
    "         s1 (arr): (Time, X, Y, 2) array of sentinel 1 data\n",
    "         image_dates (list): number of days since time[0] for each\n",
    "                              image in s1.shape[0]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"The data is {data}\")\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer=layer,\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = image_format,\n",
    "                data_source= data,\n",
    "                maxcc=1.0,\n",
    "                resx='20m', resy='20m',\n",
    "                config=shconfig,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=72),\n",
    "            )\n",
    "        \n",
    "        \n",
    "        s1_dates_dict = [x for x in image_request.get_dates()]\n",
    "        s1_dates = extract_dates(s1_dates_dict, year)\n",
    "        dates_to_download = identify_dates_to_download(s1_dates)\n",
    "        \n",
    "        steps_to_download = [i for i, val in enumerate(s1_dates) if val in dates_to_download]\n",
    "        print(f\"The following steps will be downloaded: {steps_to_download}, for {dates_to_download}\")\n",
    "        \n",
    "        \n",
    "        data_filter = steps_to_download\n",
    "        if len(image_request.download_list) <= 3 or len(steps_to_download) <= 3:\n",
    "            return np.empty((0,)), np.empty((0,))\n",
    "        s1 = image_request.get_data(data_filter = data_filter)\n",
    "        s1 = np.stack(s1)\n",
    "        s1 = to_float32(s1)\n",
    "        \n",
    "        assert np.max(s1) <= 1.\n",
    "        assert s1.shape[1] == 16.\n",
    "        assert s1.shape[2] == 16.\n",
    "        \n",
    "        print(f\"Sentinel 1 used {(2/3)*s1.shape[0] * (s1.shape[1]*s1.shape[2])/(512*512)} PU for\"\n",
    "              f\" {s1.shape[0]} out of {len(image_request.download_list)} images\")\n",
    "        \n",
    "        original = s1.shape\n",
    "        #s1 = s1.repeat(3, axis = 0)\n",
    "        # Store it with nearest upsample, but this will be converted to bilinear at train time\n",
    "        s1 = resize(s1, (s1.shape[0], 32, 32, 2), 0)\n",
    "        new = s1.shape\n",
    "        print(f\"{original} -> {new}\")\n",
    "        \n",
    "        image_dates = []\n",
    "        for date in image_request.get_dates():\n",
    "            if date.year == year - 1:\n",
    "                image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year:\n",
    "                image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year + 1:\n",
    "                image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "        image_dates = [val for idx, val in enumerate(image_dates) if idx in data_filter]\n",
    "        image_dates = np.array(image_dates)\n",
    "        \n",
    "        s1c = np.copy(s1)\n",
    "        s1c[np.where(s1c < 1.)] = 0\n",
    "        n_pix_oob = np.sum(s1c, axis = (1, 2, 3))\n",
    "        to_remove = np.argwhere(n_pix_oob > (32*32*2)/10)\n",
    "        if len(to_remove) > 0:\n",
    "            print(f'A total of {len(to_remove)} steps of {s1.shape[0]} were removed.')\n",
    "            s1 = np.delete(s1, to_remove, 0)\n",
    "            image_dates = np.delete(image_dates, to_remove)\n",
    "\n",
    "        return s1, image_dates\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_plots(data_location: str, output_folder: str, image_format = MimeType.TIFF) -> None:\n",
    "    \"\"\" Downloads sentinel-1 data for the plot IDs associated\n",
    "        with an input CSV from a collect earth online survey\n",
    "        \n",
    "        Parameters:\n",
    "         data_location (os.path)\n",
    "         output_folder (os.path)\n",
    "        \n",
    "        Subcalls:\n",
    "         calc_bbox, bounding_box\n",
    "         download_sentinel_1,\n",
    "         calculate_and_save_best_images\n",
    "         \n",
    "        Creates:\n",
    "         output_folder/{plot_id}.npy\n",
    "    \n",
    "        Returns:\n",
    "         None\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_location, encoding = \"ISO-8859-1\")\n",
    "    df.columns = [x.upper() for x in df.columns]\n",
    "    for column in ['IMAGERY_TITLE', 'STACKINGPROFILEDG', 'PL_PLOTID', 'IMAGERYYEARDG',\n",
    "                  'IMAGERYMONTHPLANET', 'IMAGERYYEARPLANET', 'IMAGERYDATESECUREWATCH',\n",
    "                  'IMAGERYENDDATESECUREWATCH', 'IMAGERYFEATUREPROFILESECUREWATCH',\n",
    "                  'IMAGERYSTARTDATESECUREWATCH',\n",
    "                  'IMAGERY_ATTRIBUTIONS',\n",
    "                  'SAMPLE_GEOM']:\n",
    "        if column in df.columns:\n",
    "            df = df.drop(column, axis = 1)\n",
    "    df = df.rename(columns={df.columns[0]: 'PLOT_ID'})\n",
    "    print(df.columns)\n",
    "    df = df.dropna(axis = 0)\n",
    "    df = df[df['LAT'] > -24]\n",
    "    df = df[df['LAT'] < 24]\n",
    "    plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "    existing = [int(x[:-4]) for x in os.listdir(output_folder) if \".DS\" not in x]\n",
    "\n",
    "    to_download = [x for x in plot_ids if x not in existing]\n",
    "    print(f\"Starting download of {len(to_download)}\"\n",
    "          f\" plots from {data_location} to {output_folder}\")\n",
    "    errors = []\n",
    "    for i, val in enumerate(to_download):\n",
    "        print(f\"Downloading {i+1}/{len(to_download)}, {val}\")\n",
    "        location_wgs = calc_bbox(val, df = df)\n",
    "        print(location_wgs)\n",
    "        location, epsg = bounding_box(location_wgs, expansion = IMSIZE*10)\n",
    "        try:\n",
    "            # Identify cloud steps, download DEM, and download L2A series\n",
    "            s1_layer = identify_s1_layer(location_wgs[0])\n",
    "            data_source = DataSource.SENTINEL1_IW_DES if s1_layer == \"SENT_DESC\" else DataSource.SENTINEL1_IW_ASC\n",
    "            s1, s1_dates = download_sentinel_1(location, \n",
    "                                               layer = s1_layer, \n",
    "                                               epsg = epsg,\n",
    "                                               data = data_source)\n",
    "            if s1.shape[0] < 2:\n",
    "                s1_layer = \"SENT_DESC\" if s1_layer == \"SENT\" else \"SENT\"\n",
    "                data_source = DataSource.SENTINEL1_IW_DES if s1_layer == \"SENT_DESC\" else DataSource.SENTINEL1_IW_ASC\n",
    "                print(f'Switching to {s1_layer}')\n",
    "                s1, s1_dates = download_sentinel_1(location, \n",
    "                                                   layer = s1_layer,\n",
    "                                                   epsg = epsg,\n",
    "                                                   data = data_source)\n",
    "            \n",
    "            s1_a = np.copy(s1)\n",
    "            print(s1.shape, len(s1_dates))\n",
    "            s1, max_distance = calculate_and_save_best_images(s1, s1_dates)\n",
    "            print(s1.shape)\n",
    "\n",
    "            s1_b = np.copy(s1)\n",
    "            # Retain only iamgery every month\n",
    "            monthly = np.empty((12, IMSIZE, IMSIZE, 2))\n",
    "            index = 0\n",
    "            for start, end in zip(range(0, 24 + 2, 24 // 12), #0, 72, 6\n",
    "                                  range(24 // 12, 24 + 2, 24 // 12)): # 6, 72, 6\n",
    "                monthly[index] = np.median(s1[start:end], axis = 0)\n",
    "                index += 1\n",
    "\n",
    "            s1 = monthly\n",
    "            s1_c = np.copy(s1)\n",
    "            print(s1.shape)\n",
    "            \n",
    "            assert s1.shape[1] == IMSIZE\n",
    "            assert s1.shape[2] == IMSIZE\n",
    "            if max_distance < 200:\n",
    "                hkl.dump(s1, output_folder + str(val) + \".hkl\", mode='w', compression='gzip')\n",
    "                print('\\n')\n",
    "            else:\n",
    "                print(f\"Skipping {val} because max distance is {max_distance}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.fatal(e, exc_info=True)\n",
    "            errors.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pineapple-2021.csv\n",
      "Index(['PLOT_ID', 'SAMPLEID', 'LON', 'LAT', 'EMAIL', 'FLAGGED',\n",
      "       'COLLECTION_TIME', 'ANALYSIS_DURATION', 'TREE'],\n",
      "      dtype='object')\n",
      "Starting download of 34 plots from ../data/train-csv/pineapple-2021.csv to ../data/train-s1/\n",
      "Downloading 1/34, 999801\n",
      "[(-88.9761525, 13.44492467), (-88.9749847, 13.44606047)]\n",
      "Loading formatted geocoded file...\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 55961\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 2/34, 999802\n",
      "[(-88.9730616, 13.44667772), (-88.9718938, 13.44781352)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 3/34, 999803\n",
      "[(-88.97495305, 13.44875371), (-88.97378525, 13.44988949)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 4/34, 999804\n",
      "[(-88.97144695, 13.45078355), (-88.97027915, 13.45191933)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 5/34, 999805\n",
      "[(-88.97476852, 13.45221368), (-88.97360072, 13.45334944)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 6/34, 999806\n",
      "[(-88.97140082, 13.45424353), (-88.97023302, 13.45537929)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 7/34, 999807\n",
      "[(-88.97495305, 13.45064515), (-88.97378525, 13.45178093)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 42919\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 8/34, 999808\n",
      "[(-88.9925758, 13.45221368), (-88.991408, 13.45334944)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 45496\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 9/34, 999809\n",
      "[(-88.99248354, 13.45442806), (-88.99131574, 13.45556382)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 45118\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 10/34, 999810\n",
      "[(-88.99091502, 13.45599658), (-88.98974722, 13.45713233)]\n",
      "La Paz  SV NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 7, 9, 12, 13, 15, 16, 19, 21, 24, 26], for [10, 34, 70, 94, 130, 154, 190, 214, 250, 274, 310, 346]\n",
      "The original max value is 48898\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 29 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 11/34, 999811\n",
      "[(-85.18329222, 10.34145907), (-85.18212442, 10.34260791)]\n",
      "Guanacaste Canton de Canas CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 6, 9, 12, 14, 17, 19, 22, 24, 27, 29], for [12, 36, 60, 96, 132, 156, 192, 216, 252, 276, 312, 336]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 33 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "A total of 1 steps of 12 were removed.\n",
      "(11, 32, 32, 2) 11\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 12/34, 999812\n",
      "[(-85.18213057, 10.3409728), (-85.18096277, 10.34212164)]\n",
      "Guanacaste Canton de Canas CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 6, 9, 12, 14, 17, 19, 22, 24, 27, 29], for [12, 36, 60, 96, 132, 156, 192, 216, 252, 276, 312, 336]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 33 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "A total of 1 steps of 12 were removed.\n",
      "(11, 32, 32, 2) 11\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 13/34, 999813\n",
      "[(-85.18829001, 10.34164818), (-85.18712221, 10.34279702)]\n",
      "Guanacaste Canton de Canas CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 6, 9, 12, 14, 17, 19, 22, 24, 27, 29], for [12, 36, 60, 96, 132, 156, 192, 216, 252, 276, 312, 336]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 33 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "A total of 1 steps of 12 were removed.\n",
      "(11, 32, 32, 2) 11\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 14/34, 999814\n",
      "[(-85.18823598, 10.33962205), (-85.18706818, 10.34077089)]\n",
      "Guanacaste Canton de Canas CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 6, 9, 12, 14, 17, 19, 22, 24, 27, 29], for [12, 36, 60, 96, 132, 156, 192, 216, 252, 276, 312, 336]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 33 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "A total of 1 steps of 12 were removed.\n",
      "(11, 32, 32, 2) 11\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 15/34, 999815\n",
      "[(-85.18572327, 10.31413116), (-85.18455547, 10.3152801)]\n",
      "Guanacaste Canton de Canas CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [2, 4, 6, 9, 12, 14, 17, 19, 22, 24, 27, 29], for [12, 36, 60, 96, 132, 156, 192, 216, 252, 276, 312, 336]\n",
      "The original max value is 50745\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 33 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 16/34, 999816\n",
      "[(-83.11416328, 9.02087721), (-83.11299548, 9.022030573)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 17/34, 999817\n",
      "[(-83.11175237, 9.022613071), (-83.11058457, 9.02376643)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 18/34, 999818\n",
      "[(-83.10871461, 9.024686463), (-83.10754681, 9.025839814)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 19/34, 999819\n",
      "[(-83.11018527, 9.027892987), (-83.10901747, 9.029046328)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 20/34, 999820\n",
      "[(-83.10702697, 9.028905574), (-83.10585917, 9.030058912)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 21/34, 999821\n",
      "[(-83.11187291, 9.026325889), (-83.11070511, 9.027479236)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 22/34, 999822\n",
      "[(-83.10649657, 9.018418071), (-83.10532877, 9.019571442)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 56837\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 23/34, 999823\n",
      "[(-83.10357936, 9.021865686), (-83.10241156, 9.023019047)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 24/34, 999824\n",
      "[(-83.1034106, 9.025723158), (-83.1022428, 9.026876507)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 25/34, 999825\n",
      "[(-83.09844411, 9.032955919), (-83.09727631, 9.034109244)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 26/34, 999826\n",
      "[(-83.11104864, 9.038702324), (-83.10988084, 9.039855631)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 27/34, 999827\n",
      "[(-83.11616747, 9.041032281), (-83.11499967, 9.04218558)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 28/34, 999828\n",
      "[(-83.09565683, 9.037043113), (-83.09448903, 9.038196425)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 29/34, 999829\n",
      "[(-83.08506613, 9.046892474), (-83.08389833, 9.048045755)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 30/34, 999830\n",
      "[(-83.10086425, 9.05572706), (-83.09969645, 9.056880313)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 31/34, 999831\n",
      "[(-83.10331738, 9.057300147), (-83.10214958, 9.058453394)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 32/34, 999832\n",
      "[(-83.11693583, 9.035258343), (-83.11576803, 9.03641166)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 65535\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 33/34, 999833\n",
      "[(-83.555912, 8.935079874), (-83.5547442, 8.936233511)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 40449\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n",
      "Downloading 34/34, 999834\n",
      "[(-83.56560805, 8.930892709), (-83.56444025, 8.932046358)]\n",
      "Puntarenas  CR NA\n",
      "The data is DataCollection.SENTINEL1_IW_DES\n",
      "The following steps will be downloaded: [1, 4, 6, 8, 11, 13, 15, 18, 20, 23, 25, 28], for [7, 43, 67, 91, 139, 163, 187, 223, 247, 283, 307, 343]\n",
      "The original max value is 25821\n",
      "Sentinel 1 used 0.0078125 PU for 12 out of 32 images\n",
      "(12, 16, 16, 2) -> (12, 32, 32, 2)\n",
      "(12, 32, 32, 2) 12\n",
      "(24, 32, 32, 2)\n",
      "(12, 32, 32, 2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "def to_float32(array: np.array) -> np.array:\n",
    "    \"\"\"Converts an int_x array to float32\"\"\"\n",
    "    print(f'The original max value is {np.max(array)}')\n",
    "    if not isinstance(array.flat[0], np.floating):\n",
    "        assert np.max(array) > 1\n",
    "        array = np.float32(array) / 65535.\n",
    "    assert np.max(array) <= 1\n",
    "    return array\n",
    "\n",
    "for i in (os.listdir(\"../data/train-csv/\")):\n",
    "    if \"pineapple-2021.csv\" in i:\n",
    "        print(i)\n",
    "        download_plots(\"../data/train-csv/\" + i, \n",
    "                       \"../data/train-s1/\",\n",
    "                       image_format = MimeType.TIFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
