{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "from sentinelhub import DataSource\n",
    "import scipy.sparse as sparse\n",
    "import scipy\n",
    "from scipy.sparse.linalg import splu\n",
    "from skimage.transform import resize\n",
    "from sentinelhub import CustomUrlParam\n",
    "from time import time as timer\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/slope.py\n",
    "%run ../src/utils-bilinear.py\n",
    "%run ../src/dsen2/utils/DSen2Net.py\n",
    "#!source ~/.bash_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ('2018-12-15', '2020-01-15')\n",
    "SIZE = 9\n",
    "IMSIZE = (SIZE * 14)+2\n",
    "\n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions (to be moved to a utils file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSG = CRS.WGS84\n",
    "GRID_SIZE_X = 1\n",
    "GRID_SIZE_Y = 1\n",
    "\n",
    "IMAGE_X = 14*GRID_SIZE_X\n",
    "IMAGE_Y = 14*GRID_SIZE_Y\n",
    "\n",
    "TEST_X = 5\n",
    "TEST_Y = 5\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY = key['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_arr = np.array([[1, 1, 1, 1, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 2, 3, 2, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 1, 1, 1, 1,],])\n",
    "                  \n",
    "c_arr = c_arr / 3\n",
    "o_arr = 1 - c_arr\n",
    "c_arr = np.tile(c_arr[:, :, np.newaxis], (1, 1, 11))\n",
    "o_arr = np.tile(o_arr[:, :, np.newaxis], (1, 1, 11))\n",
    "\n",
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def bounding_box(point, x_offset_max = 140, y_offset_max = 140, expansion = 10):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    #@valid\n",
    "    tl = point\n",
    "    \n",
    "    if 102 <= tl[0] <= 109:\n",
    "        epsg = 32648 if tl[1] > 0 else 32748\n",
    "    if 96 <= tl[0] <= 102:\n",
    "        epsg = 32647 if tl[1] > 0 else 32747\n",
    "    if 90 <= tl[0] <= 96:\n",
    "        epsg = 32646 if tl[1] > 0 else 32746\n",
    "    if 84 <= tl[0] <= 90:\n",
    "        epsg = 32645 if tl[1] > 0 else 32745\n",
    "    if 78 <= tl[0] <= 84:\n",
    "        epsg = 32644 if tl[1] > 0 else 32744\n",
    "    if 72 <= tl[0] <= 78:\n",
    "        epsg = 32643 if tl[1] > 0 else 32743\n",
    "    if 66 <= tl[0] <= 72:\n",
    "        epsg = 32642 if tl[1] > 0 else 32742\n",
    "    if 60 <= tl[0] <= 66:\n",
    "        epsg = 32641 if tl[1] > 0 else 32741\n",
    "    if 54 <= tl[0] <= 60:\n",
    "        epsg = 32640 if tl[1] > 0 else 32740\n",
    "    if 48 <= tl[0] <= 54:\n",
    "        epsg = 32639 if tl[1] > 0 else 32739\n",
    "    if 42 <= tl[0] <= 48:\n",
    "        epsg = 32638 if tl[1] > 0 else 32738\n",
    "    if 36 <= tl[0] <= 42:\n",
    "        epsg = 32637 if tl[1] > 0 else 32737\n",
    "    if 30 <= tl[0] <= 36:\n",
    "        epsg = 32636 if tl[1] > 0 else 32736\n",
    "    if 24 <= tl[0] <= 30:\n",
    "        epsg = 32635 if tl[1] > 0 else 32735\n",
    "    if 18 <= tl[0] <= 24:\n",
    "        epsg = 32634 if tl[1] > 0 else 32734\n",
    "    if 12 <= tl[0] <= 18:\n",
    "        epsg = 32633 if tl[1] > 0 else 32733\n",
    "    if 6 <= tl[0] <= 12:\n",
    "        epsg = 32632 if tl[1] > 0 else 32732\n",
    "    if 0 <= tl[0] <= 6:\n",
    "        epsg = 32631 if tl[1] > 0 else 32731\n",
    "    if -6 <= tl[0] <= 0:\n",
    "        epsg = 32630 if tl[1] > 0 else 32730\n",
    "    if -12 <= tl[0] <= -6:\n",
    "        epsg = 32629 if tl[1] > 0 else 32729\n",
    "    if -18 <= tl[0] <= -12:\n",
    "        epsg = 32628 if tl[1] > 0 else 32728\n",
    "    if -24 <= tl[0] <= -18:\n",
    "        epsg = 32627 if tl[1] > 0 else 32727\n",
    "    if -30 <= tl[0] <= -24:\n",
    "        epsg = 32626 if tl[1] > 0 else 32726\n",
    "    if -36 <= tl[0] <= -30:\n",
    "        epsg = 32625 if tl[1] > 0 else 32725\n",
    "    if -42 <= tl[0] <= -36:\n",
    "        epsg = 32624 if tl[1] > 0 else 32724\n",
    "    if -48 <= tl[0] <= -42:\n",
    "        epsg = 32623 if tl[1] > 0 else 32723\n",
    "    if -54 <= tl[0] <= -48:\n",
    "        epsg = 32622 if tl[1] > 0 else 32722\n",
    "    if -60 <= tl[0] <= -54:\n",
    "        epsg = 32621 if tl[1] > 0 else 32721\n",
    "    if -66 <= tl[0] <= -60:\n",
    "        epsg = 32620 if tl[1] > 0 else 32720\n",
    "    if -72 <= tl[0] <= -66:\n",
    "        epsg = 32619 if tl[1] > 0 else 32719\n",
    "    if -78 <= tl[0] <= -72:\n",
    "        epsg = 32618 if tl[1] > 0 else 32718\n",
    "    if -84 <= tl[0] <= -78:\n",
    "        epsg = 32617 if tl[1] > 0 else 32717\n",
    "    if -90 <= tl[0] <= -84:\n",
    "        epsg = 32616 if tl[1] > 0 else 32716\n",
    "    if -96 <= tl[0] <= -90:\n",
    "        epsg = 32615 if tl[1] > 0 else 32715\n",
    "    if -102 <= tl[0] <= -96:\n",
    "        epsg = 32614 if tl[1] > 0 else 32714\n",
    "    if -108 <= tl[0] <= -102:\n",
    "        epsg = 32613 if tl[1] > 0 else 32713\n",
    "    if -114 <= tl[0] <= -108:\n",
    "        epsg = 32612 if tl[1] > 0 else 32712\n",
    "    if -120 <= tl[0] <= -114:\n",
    "        epsg = 32611 if tl[1] > 0 else 32711\n",
    "    if -126 <= tl[0] <= -120:\n",
    "        epsg = 32610 if tl[1] > 0 else 32710\n",
    "        \n",
    "    tl = convertCoords(tl, 4326, epsg)\n",
    "    \n",
    "    br = (tl[0], tl[1])\n",
    "    tl = ((tl[0] + (x_offset_max)), (tl[1] + (y_offset_max )))\n",
    "    distance1 = tl[0] - br[0]\n",
    "    distance2 = tl[1] - br[1]\n",
    "    \n",
    "    br = [a - expansion for a in br]\n",
    "    tl = [a + expansion for a in tl]\n",
    "    \n",
    "    after = [b - a for a,b in zip(br, tl)]\n",
    "    br = convertCoords(br, epsg, 4326)\n",
    "    tl = convertCoords(tl, epsg, 4326)\n",
    "    \n",
    "    min_x = tl[0] # original X offset - 10 meters\n",
    "    max_x = br[0] # original X offset + 10*GRID_SIZE meters\n",
    "    \n",
    "    min_y = tl[1] # original Y offset - 10 meters\n",
    "    max_y = br[1] # original Y offset + 10 meters + 140 meters\n",
    "    return [(min_x, min_y), (max_x, max_y)]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_clouds(bbox, epsg = EPSG, dates = dates):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=dates,\n",
    "            width=(SIZE*14)+2,\n",
    "            height=(SIZE*14)+2,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.75,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=48),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        clean_steps = [i for i, val in enumerate(means) if val < 0.20]\n",
    "        return clean_steps, means, cloud_probs\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(bbox, epsg = EPSG):\n",
    "    #@valid\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_s = (SIZE*14)+4\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=dem_s,\n",
    "                         height=dem_s,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, dem_s, dem_s)),\n",
    "                  np.full((dem_s, dem_s), 10), np.full((dem_s, dem_s), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((dem_s,dem_s, 1))\n",
    "    dem_image = dem_image[1:dem_s-1, 1:dem_s-1, :]\n",
    "    return dem_image #/ np.max(dem_image)\n",
    "\n",
    "def download_layer(bbox, epsg = EPSG, dates = dates):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A20',\n",
    "                bbox=box,\n",
    "                time=dates,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=48),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        img_20 = np.stack(img_bands)\n",
    "        print(\"Original size: {}\".format(img_20.shape))\n",
    "        img_20 = resize(img_20, (img_20.shape[0], IMSIZE, IMSIZE, img_20.shape[-1]), order = 0)\n",
    "        \n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A10',\n",
    "                bbox=box,\n",
    "                time=dates,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'BICUBIC',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=48),\n",
    "        )\n",
    "        \n",
    "        img_bands = image_request.get_data()\n",
    "        img_10 = np.stack(img_bands)\n",
    "        print(\"Original 10 size: {}\".format(img_10.shape))\n",
    "        img_10 = resize(img_10, (img_10.shape[0], IMSIZE, IMSIZE, img_10.shape[-1]), order = 0)\n",
    "        shadows = img_10[:, :, :, -1]\n",
    "        img_10 = img_10[:, :, :, :-1]\n",
    "        \n",
    "        shadows[np.where(shadows != 3)] = 0\n",
    "        shadows[np.where(shadows == 3)] = 1\n",
    "        print(\"Data shape: {}\".format(shadows.shape))\n",
    "        shadow_sum = np.sum(shadows, axis = (1, 2))\n",
    "        shadow_steps = np.argwhere(shadow_sum > (IMSIZE*IMSIZE) / 4)\n",
    "        \n",
    "        img = np.concatenate([img_10, img_20], axis = -1)\n",
    "        return img, image_request, shadows, shadow_steps\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "def download_sentinel_1(bbox, epsg = EPSG, dates = dates, layer = \"SENT\", year = 2019):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer=layer,\n",
    "                bbox=box,\n",
    "                time=dates,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=1.0,\n",
    "                resx='5m', resy='5m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=48),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        s1 = np.stack(img_bands)\n",
    "        s1 = resize(s1, (s1.shape[0], IMSIZE*2, IMSIZE*2, s1.shape[-1]), order = 0)\n",
    "        s1 = np.reshape(s1, (s1.shape[0], s1.shape[1]//2, 2, s1.shape[2] // 2, 2, s1.shape[-1]))\n",
    "        s1 = np.mean(s1, (2, 4))\n",
    "        #s1 = s1[:, 8:24, 8:24, :]\n",
    "        \n",
    "        image_dates = []\n",
    "        for date in image_request.get_dates():\n",
    "            if date.year == year - 1:\n",
    "                image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year:\n",
    "                image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year + 1:\n",
    "                image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "        image_dates = np.array(image_dates)\n",
    "        to_remove = np.argwhere(np.max(s1, (1, 2, 3)) == 1.).flatten()\n",
    "        s1 = np.delete(s1, to_remove, 0)\n",
    "        #print(np.max(s1, (1, 2, 3)))\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        return s1, image_dates\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud and shadow removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cloud_and_shadows(tiles, c_probs, shadows, image_dates):\n",
    "    wsize = 5\n",
    "    c_probs = c_probs - np.min(c_probs, axis = 0)\n",
    "    c_probs[np.where(c_probs > 0.33)] = 1.\n",
    "    c_probs[np.where(c_probs < 0.33)] = 0.\n",
    "    c_probs = np.reshape(c_probs, (c_probs.shape[0], 16, 8, 16, 8))\n",
    "    c_probs = np.sum(c_probs, (2, 4))\n",
    "    c_probs = resize(c_probs, (c_probs.shape[0], IMSIZE, IMSIZE), 0)\n",
    "    c_probs[np.where(c_probs < 16)] = 0\n",
    "    c_probs[np.where(c_probs >= 16)] = 1\n",
    "    secondary_c_probs = np.copy(c_probs)\n",
    "    c_probs += shadows\n",
    "    c_probs[np.where(c_probs >= 1.)] = 1.\n",
    "    number_interpolated = 0\n",
    "    for cval in range(0, IMSIZE - 4, 1):\n",
    "        for rval in range(0, IMSIZE - 4, 1):\n",
    "            subs = c_probs[:, cval:cval + wsize, rval:rval+wsize]\n",
    "            sums = np.sum(subs, axis = (1, 2))\n",
    "            satisfactory = [x for x in range(c_probs.shape[0]) if sums[x] < 12]\n",
    "            satisfactory = np.array(satisfactory)\n",
    "            for date in range(0, tiles.shape[0]):\n",
    "                if np.sum(subs[date, :, :]) > 12:\n",
    "                    number_interpolated += 1\n",
    "                    before, after = calculate_proximal_steps(date, satisfactory)\n",
    "                    before = date + before\n",
    "                    after = date + after\n",
    "                    bef = tiles[before, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    aft = tiles[after, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    before = image_dates[before]\n",
    "                    after = image_dates[after]\n",
    "                    before_diff = abs(image_dates[date] - before)\n",
    "                    after_diff = abs(image_dates[date] - after)\n",
    "                    bef_wt = 1 - before_diff / (before_diff + after_diff)\n",
    "                    aft_wt = 1 - bef_wt\n",
    "                    candidate = bef_wt*bef + aft_wt*aft\n",
    "                    candidate = candidate*c_arr + tiles[date, cval:cval+wsize, rval:rval+wsize, : ]*o_arr\n",
    "                    tiles[date, cval:cval+wsize, rval:rval+wsize, : ] = candidate \n",
    "    print(\"A total of {} pixels were interpolated\".format(number_interpolated))\n",
    "    return tiles, c_probs, secondary_c_probs\n",
    "\n",
    "def remove_missed_clouds(img):\n",
    "    iqr = np.percentile(img[:, :, :, 3].flatten(), 75) - np.percentile(img[:, :, :, 3].flatten(), 25)\n",
    "    thresh_t = np.percentile(img[:, :, :, 3].flatten(), 75) + iqr*2\n",
    "    thresh_b = np.percentile(img[:, :, :, 3].flatten(), 25) - iqr*2\n",
    "    diffs_fw = np.diff(img, 1, axis = 0)\n",
    "    diffs_fw = np.mean(diffs_fw, axis = (1, 2, 3))\n",
    "    diffs_fw = np.array([0] + list(diffs_fw))\n",
    "    diffs_bw = np.diff(np.flip(img, 0), 1, axis = 0)\n",
    "    diffs_bw = np.flip(np.mean(diffs_bw, axis = (1, 2, 3)))\n",
    "    diffs_bw = np.array(list(diffs_bw) + [0])\n",
    "    diffs = abs(diffs_fw - diffs_bw) * 100 # 3, -3 -> 6, -3, 3 -> 6, -3, -3\n",
    "    #diffs = [int(x) for x in diffs]\n",
    "    outlier_percs = []\n",
    "    for step in range(img.shape[0]):\n",
    "        bottom = len(np.argwhere(img[step, :, :, 3].flatten() > thresh_t))\n",
    "        top = len(np.argwhere(img[step, :, :, 3].flatten() < thresh_b))\n",
    "        p = 100* ((bottom + top) / (IMSIZE*IMSIZE))\n",
    "        outlier_percs.append(p)\n",
    "    to_remove = np.argwhere(np.array(outlier_percs) > 20)\n",
    "    return to_remove\n",
    "\n",
    "def threshold_shadows(arr):\n",
    "    arr = np.copy(arr)\n",
    "    iqr = np.percentile(arr.flatten(), 75) - np.percentile(arr.flatten(), 25)\n",
    "    low = np.percentile(arr.flatten(), 25)\n",
    "    #high = np.percentile(arr.flatten(), 75)\n",
    "    thresh_low = low - 1.5*iqr\n",
    "    #thresh_high = high + 2*iqr\n",
    "    #arr[np.where(arr > thresh_high)] = 1.\n",
    "    arr[np.where(arr < thresh_low)] = 1.\n",
    "    arr[np.where(arr < 1)] = 0.\n",
    "    arr = np.reshape(arr, (arr.shape[0], 16, 8, 16, 8))\n",
    "    arr = np.sum(arr, axis = (2, 4))\n",
    "    arr = resize(arr, (arr.shape[0], 128, 128), 0)\n",
    "    fake_shadows = np.zeros((arr.shape[0], arr.shape[1], arr.shape[2]))\n",
    "    for step in range(arr.shape[0]):\n",
    "        if step > 0:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        before = arr[step - 1, x, y]\n",
    "                        if abs(before - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "                            \n",
    "    for step in range(arr.shape[0]):\n",
    "        if step < arr.shape[0] - 1:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        after = arr[step + 1, x, y]\n",
    "                        if abs(after - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "    before = np.sum(arr)\n",
    "    arr[np.where(fake_shadows == 1)] = 0.\n",
    "    after = np.sum(arr)\n",
    "    arr[np.where(arr > 9)] = 1.\n",
    "    arr[np.where(arr < 9)] = 0.\n",
    "    print(\"Removed {} fake shadows, leaving {}\".format(before - after, after))\n",
    "    print(\"The total percent shadow cover is: {}%\".format(after/(arr.shape[0]*arr.shape[1]*arr.shape[2])))\n",
    "    for step in range(arr.shape[0]):\n",
    "        for x in range(1, arr.shape[1] -1):\n",
    "            for y in range(1, arr.shape[2] - 1):\n",
    "                if np.sum(arr[step, x-1:x+2, y-1:y+2]) == 1:\n",
    "                    if arr[step, x, y] != 0:\n",
    "                        print(\"Removing: {} {} {} {}\".format(step, x, y, np.sum(arr[step, x-1:x+2, y-1:y+2])))\n",
    "                        arr[step, x, y] = 0\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonals = np.zeros(2*2+1)\n",
    "diagonals[2] = 1.\n",
    "for i in range(2):\n",
    "    diff = diagonals[:-1] - diagonals[1:]\n",
    "    diagonals = diff\n",
    "offsets = np.arange(2+1)\n",
    "shape = (70, 72)\n",
    "\n",
    "def smooth(y, lmbd = 800, diagonals = diagonals, offsets = offsets, shape = shape, d = 2):\n",
    "    E = sparse.eye(72, format = 'csc')\n",
    "    D = scipy.sparse.diags(diagonals, offsets, shape)\n",
    "    coefmat = E + lmbd * D.conj().T.dot(D)\n",
    "    z = splu(coefmat).solve(y)\n",
    "    return z\n",
    "\n",
    "def calculate_and_save_best_images(img_bands, image_dates):\n",
    "\n",
    "    biweekly_dates = [day for day in range(0, 360, 5)] # ideal imagery dates are every 15 days\n",
    "    \n",
    "    # Identify the dates where there is < 20% cloud cover\n",
    "    #satisfactory_ids = list(np.argwhere(np.array(means) < 4.).reshape(-1, )) \n",
    "    satisfactory_ids = [x for x in range(0, img_bands.shape[0])]\n",
    "    satisfactory_dates = [value for idx, value in enumerate(image_dates) if idx in satisfactory_ids]\n",
    "    \n",
    "    \n",
    "    selected_images = {}\n",
    "    for i in biweekly_dates:\n",
    "        distances = [abs(date - i) for date in satisfactory_dates]\n",
    "        closest = np.min(distances)\n",
    "        closest_id = np.argmin(distances)\n",
    "        # If there is imagery within 8 days, select it\n",
    "        if closest < 8:\n",
    "            date = satisfactory_dates[closest_id]\n",
    "            image_idx = int(np.argwhere(np.array(image_dates) == date)[0])\n",
    "            selected_images[i] = {'image_date': [date], 'image_ratio': [1], 'image_idx': [image_idx]}\n",
    "        # If there is not imagery within 8 days, look for the closest above and below imagery\n",
    "        else:\n",
    "            distances = np.array([(date - i) for date in satisfactory_dates])\n",
    "            # Number of days above and below the selected date of the nearest clean imagery\n",
    "            above = distances[np.where(distances < 0, distances, -np.inf).argmax()]\n",
    "            below = distances[np.where(distances > 0, distances, np.inf).argmin()]\n",
    "            if abs(above) > 240: # If date is the last date, occassionally argmax would set above to - number\n",
    "                above = below\n",
    "            if abs(below) > 240:\n",
    "                below = above\n",
    "            if above != below:\n",
    "                below_ratio = above / (above - below)\n",
    "                above_ratio = 1 - below_ratio\n",
    "            else:\n",
    "                above_ratio = below_ratio = 0.5\n",
    "                \n",
    "            # Extract the image date and imagery index for the above and below values\n",
    "            above_date = i + above\n",
    "            above_image_idx = int(np.argwhere(np.array(image_dates) == above_date)[0])\n",
    "            \n",
    "            below_date = i + below\n",
    "            below_image_idx = int(np.argwhere(np.array(image_dates) == below_date)[0])\n",
    "            \n",
    "            selected_images[i] = {'image_date': [above_date, below_date], 'image_ratio': [above_ratio, below_ratio],\n",
    "                                 'image_idx': [above_image_idx, below_image_idx]}\n",
    "                            \n",
    "    max_distance = 0\n",
    "    \n",
    "    for i in selected_images.keys():\n",
    "        #print(i, selected_images[i])\n",
    "        if len(selected_images[i]['image_date']) == 2:\n",
    "            dist = selected_images[i]['image_date'][1] - selected_images[i]['image_date'][0]\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "    \n",
    "    print(\"Maximum time distance: {}\".format(max_distance))\n",
    "        \n",
    "    keep_steps = []\n",
    "    for i in selected_images.keys():\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "        if len(info['image_idx']) == 2:\n",
    "            step1 = img_bands[info['image_idx'][0]] * 0.5#info['image_ratio'][0]\n",
    "            step2 = img_bands[info['image_idx'][1]] * 0.5 #info['image_ratio'][1]\n",
    "            step = step1 + step2\n",
    "        keep_steps.append(step)\n",
    "        \n",
    "    keep_steps = np.stack(keep_steps)\n",
    "    return keep_steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiling and coordinate selection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coords = (13.540810, 38.177220) # tigray\n",
    "#coords = (-1.817109, 37.477563) # makueni-2\n",
    "#coords = (-2.575694, 37.949516) # makueni-3\n",
    "#coords = (-2.561161, 38.096274) # makueni\n",
    "#coords = (9.259359, -0.833750) # ghana\n",
    "#coords = (-1.515869, 29.952997) # rwanda - useable\n",
    "#coords = (-1.455224, 30.323259) # rwanda2\n",
    "#coords = (13.316919, 2.581680) # niger\n",
    "#coords = (13.18158333, 2.47805556) # niger - koure salima\n",
    "#coords = (10.596, 14.2722) # cameroon\n",
    "#coords = (18.232495, -92.134215) # campeche\n",
    "#coords = (14.231732, -89.418679) # el salvador\n",
    "#coords = (-11.044091, 33.818034) # malawi\n",
    "#coords = (10.385811, -1.764760) # sisala east, ghana\n",
    "#coords = (10.390084, -0.846330) # weest mamprusi, ghana\n",
    "#coords = (7.702058, -0.709011) # brong ahafo, bono east\n",
    "#coords = (10.097017, -2.439068)# close to wa, has been done\n",
    "#coords = (24.070469, 81.606926) # sidhi, india\n",
    "#coords = (7.398111, -1.269223) # cocoa\n",
    "#coords = (44.865106, -123.093435) # salem, oregon\n",
    "#coords = (-20.147326, -40.837780) # Esperito santo, BR\n",
    "#coords = (-20.147320, -40.837770) BR 2\n",
    "#coords = (-22.559943, -44.186629) # Vale do Paraiba, Brazil\n",
    "#coords = (6.622101, -0.704616) # kwahu\n",
    "#coords = (6.518909, -0.826008) # kwahu large\n",
    "#coords = (-6.352580, 106.677072) # jakarta\n",
    "#coords = (6.167177, -75.693226) # medellin, colombia\n",
    "#coords = (4.179529, -74.889171) # colombia\n",
    "#coords = (6.518909, -0.826008) # kwahu large\n",
    "#coords = (5.765917, 14.791618) # baboua, CAF\n",
    "#coords = (-18.960152, 47.469587) # madagascar\n",
    "#coords = (9.909083, 76.253594) # Kochi, india\n",
    "#coords = (16.032170, -90.144511) # Guatemala\n",
    "#coords = (13.757749, -90.004949) # elsalvador imposible\n",
    "#coords = (13.727334, -90.015579) # elsalvador imposible2\n",
    "#coords = (-11.749636, 27.586622) # Kafubu, DRC\n",
    "#coords = (-6.272258, 36.679824) # Tanzania\n",
    "#coords = (-36.431237, -71.872030) # Chile\n",
    "#coords = (12.398014, -86.963042) # Nicaragua\n",
    "coords = (13.933745, -84.690842) # Bonanza, Nicaragua\n",
    "#coords = (14.096664, -88.720304) # Honduras\n",
    "coords = (coords[1], coords[0])\n",
    "OUTPUT_FOLDER = '../tile_data/bonanza/'\n",
    "#13.567962754335872\n",
    "\n",
    "borders = bounding_box(coords, 10*(SIZE*14), 10*(SIZE*14), expansion = 0)\n",
    "print(borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this needs the first coordinate to not be [coords] for different y steps\n",
    "def calculate_offset_coords(coords, x_step, y_step, number):\n",
    "    offset_coords = []\n",
    "    y_coord = bounding_box(coords, x_step, y_step, expansion = 0)\n",
    "    y_coord = y_coord[0][1]\n",
    "    for i in range(number):\n",
    "        bbx = bounding_box(coords, (i+1)*x_step, y_step, expansion = 0)\n",
    "        coord_x = bbx[0][0]\n",
    "        coord_y = y_coord\n",
    "        offset_coords.append((coord_x, coord_y))\n",
    "    coords = [(coords[0], y_coord)]\n",
    "    return coords + offset_coords\n",
    "\n",
    "SIZE = 9\n",
    "corner_coordinates = []\n",
    "for row in range(0, 25):\n",
    "    temp = calculate_offset_coords(coords, x_step = (SIZE*140), \n",
    "                                            y_step = row*(SIZE*140), \n",
    "                                            number = 40)\n",
    "    corner_coordinates.append([[x, [y, row]] for x, y in zip(temp, [col for col in range(0, 40)])])\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(20, 17))\n",
    "\n",
    "# So instead of corner coordinates, make the BBoxes to begin with and verify with a plot\n",
    "# color each box differently\n",
    "\n",
    "tiled_bbx = []\n",
    "xs = []\n",
    "ys =[]\n",
    "for x in corner_coordinates:\n",
    "    for y in x:\n",
    "        bbx = bounding_box(y[0], SIZE*140, SIZE*140, 10)\n",
    "        xs.append(bbx[0][0])\n",
    "        xs.append(bbx[1][0])\n",
    "        \n",
    "        xs.append(bbx[0][0])\n",
    "        xs.append(bbx[1][0])\n",
    "        \n",
    "        ys.append(bbx[0][1])\n",
    "        ys.append(bbx[1][1])   \n",
    "        ys.append(bbx[1][1])\n",
    "        ys.append(bbx[0][1])\n",
    "        \n",
    "sns.scatterplot(x = xs, y = ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDL_PATH = \"../src/dsen2/models/\"\n",
    "\n",
    "input_shape = ((4, None, None), (6, None, None))\n",
    "model = s2model(input_shape, num_layers=6, feature_size=128)\n",
    "predict_file = MDL_PATH+'s2_032_lr_1e-04.hdf5'\n",
    "print('Symbolic Model Created.')\n",
    "\n",
    "model.load_weights(predict_file)\n",
    "\n",
    "def DSen2(d10, d20):\n",
    "    test = [d10, d20]\n",
    "    input_shape = ((4, None, None), (6, None, None))\n",
    "    prediction = _predict(test, input_shape, deep=False)\n",
    "    #prediction *= 5\n",
    "    return prediction\n",
    "\n",
    "def _predict(test, input_shape, model = model, deep=False, run_60=False):\n",
    "    \n",
    "    print(\"Predicting using file: {}\".format(predict_file))\n",
    "    prediction = model.predict(test, verbose=1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "starting_days = np.cumsum(days_per_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(sample):\n",
    "    for date in range(24):\n",
    "        for band in range(10):\n",
    "            maxs = np.max(sample[date, :, :, band])\n",
    "            mins = np.min(sample[date, :, :, band])\n",
    "            if maxs == 1.0 or mins == 0.0:\n",
    "                print(\"Found null outlier\")\n",
    "                return True\n",
    "            if maxs == mins:\n",
    "                print(\"Found missing outlier\")\n",
    "                return True\n",
    "            if maxs >= 1.05 or mins <= -1.05:\n",
    "                print(\"Found range outlier\")\n",
    "                return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def tile_images(arr, output_folder):\n",
    "    # Normal\n",
    "    for x_offset, cval in enumerate([x for x in range(0, 126, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 126, 14)]):\n",
    "            base_id = 0\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            np.save(output_folder + str(base_id+x_offset*9+y_offset+1), subs)\n",
    "            \n",
    "    # Upright        \n",
    "    for x_offset, cval in enumerate([x for x in range(7, 126, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(7, 126, 14)]):\n",
    "            base_id = 9*9\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            np.save(output_folder + str(base_id+x_offset*8+y_offset+1), subs)\n",
    "            \n",
    "    # Right\n",
    "    for x_offset, cval in enumerate([x for x in range(7, 119, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 126, 14)]):\n",
    "            base_id = (9*9)+(8*8)\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            np.save(output_folder + str(base_id+x_offset*9+y_offset+1), subs)\n",
    "            \n",
    "    # Up\n",
    "    for x_offset, cval in enumerate([x for x in range(0, 119, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(7, 126, 14)]):\n",
    "            base_id = (9*9)+(8*8)+(9*8)\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            np.save(output_folder + str(base_id+x_offset*8+y_offset+1), subs)\n",
    "            \n",
    "            \n",
    "def calculate_proximal_steps(date, satisfactory):\n",
    "    arg_before = None\n",
    "    arg_after = None\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < np.max(satisfactory):\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after and not arg_before:\n",
    "        arg_after = date\n",
    "        arg_before = date\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    #print(arg_before, date, arg_after)\n",
    "    return arg_before, arg_after\n",
    "\n",
    "def worker_download(coord, folder = OUTPUT_FOLDER, year = 2019):\n",
    "    idx_x = coord[1][0]\n",
    "    idx_y = coord[1][1]\n",
    "    start = timer()\n",
    "    print(\"Starting: {} {}\".format(idx_x, idx_y))\n",
    "    coord = coord[0]\n",
    "    output_folder = OUTPUT_FOLDER + \"{}\".format(str(idx_y))\n",
    "    if not os.path.exists(os.path.realpath(output_folder)):\n",
    "        os.makedirs(os.path.realpath(output_folder))\n",
    "    existing = [x for x in os.listdir(os.path.realpath(output_folder))]\n",
    "    if str(idx_x) + \".npy\" not in existing:\n",
    "        tiled_bbx = bounding_box(coord, y_offset_max = (SIZE*140)-0, x_offset_max = (SIZE*140)+0, expansion = 10)\n",
    "        dem_bbx = bounding_box(coord, y_offset_max = SIZE*140, x_offset_max = SIZE*140, expansion = 20)\n",
    "        cloud_timer = timer()\n",
    "        clean_steps, means, cloud_probs = identify_clouds(tiled_bbx)\n",
    "        \n",
    "        ## SENTINEL 1 BLOCK HERE\n",
    "        s1, s1_dates = download_sentinel_1(tiled_bbx, layer = 'SENT')\n",
    "        print(\"ASCENDING: {}\".format(s1.shape))\n",
    "        if s1.shape[0] == 0:\n",
    "            s1, s1_dates = download_sentinel_1(tiled_bbx, layer = \"SENT_DESC\")\n",
    "            print(\"DESCENDING: {}\".format(s1.shape))\n",
    "        if s1_dates.shape[0] > 0:\n",
    "            s1 = calculate_and_save_best_images(s1, s1_dates)\n",
    "\n",
    "\n",
    "            # Retain only iamgery every 15 days\n",
    "            biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "            to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "            s1 = np.delete(s1, to_remove, 0)\n",
    "        \n",
    "        tiles, request, shadows, shadow_steps = download_layer(tiled_bbx)\n",
    "        print(\"Downloaded imagery\")\n",
    "        cloud_end = timer()\n",
    "        print(\"The imagery calcs and data take {}\".format(cloud_end - cloud_timer))\n",
    "        \n",
    "        image_dates = []\n",
    "        for date in request.get_dates():\n",
    "            if date.year == year - 1:\n",
    "                image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year:\n",
    "                image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year + 1:\n",
    "                image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "        image_dates = np.array(image_dates)\n",
    "\n",
    "        args = np.array([len(np.argwhere(cloud_probs[x, :, :].reshape((128)*(128)) > 0.3)) for x in range(cloud_probs.shape[0])])\n",
    "        dirty_steps = np.argwhere(args > (128)*(128) / 5)\n",
    "        missing_images = [np.argwhere(tiles[x, :, : :10].flatten() == 0.0) for x in range(tiles.shape[0])]\n",
    "        missing_images = np.array([len(x) for x in missing_images])\n",
    "        missing_images_p = [np.argwhere(tiles[x, :, : :10].flatten() >= 1) for x in range(tiles.shape[0])]\n",
    "        missing_images_p = np.array([len(x) for x in missing_images_p])\n",
    "        missing_images += missing_images_p\n",
    "        missing_images = list(np.argwhere(missing_images >= 100))\n",
    "        to_remove = np.unique(np.array(list(dirty_steps) + list(missing_images) + list(shadow_steps)))\n",
    "\n",
    "        # Remove null steps\n",
    "        print(\"There are {}/{} dirty steps: {} cloud, {} missing, {} shadows\".format(len(to_remove),\n",
    "                                                                                    len(tiles), len(dirty_steps),\n",
    "                                                                                    len(missing_images),\n",
    "                                                                                    len(shadow_steps)))\n",
    "\n",
    "        tiles = np.delete(tiles, to_remove, 0)\n",
    "        cloud_probs = np.delete(cloud_probs, to_remove, 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        shadows = np.delete(shadows, to_remove, 0)\n",
    "        #tiles = remove_blank_steps(tiles)\n",
    "        \n",
    "        to_remove = remove_missed_clouds(tiles)\n",
    "        tiles = np.delete(tiles, to_remove, 0)\n",
    "        cloud_probs = np.delete(cloud_probs, to_remove, 0)\n",
    "        shadows = np.delete(shadows, to_remove, 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        print(\"Removing {} steps based on ratio\".format(len(to_remove)))\n",
    "        \n",
    "        bef = timer()\n",
    "        dem = download_dem(dem_bbx)\n",
    "        dem = np.tile(dem[np.newaxis, :, :, :], (tiles.shape[0], 1, 1, 1))\n",
    "        tiles = np.concatenate([tiles, dem], axis = -1)\n",
    "        tiles[:, :, :, 10] /= 90\n",
    "        aft = timer()\n",
    "        print(\"The DEM calcs took {}\".format(aft - bef))\n",
    "        \n",
    "        new_shadows = threshold_shadows(tiles[:, :, :, 3])\n",
    "        x, new_probs, mid_probs = remove_cloud_and_shadows(tiles, cloud_probs, new_shadows, image_dates)\n",
    "        bef = timer()\n",
    "        print(\"Before super: {}\".format(x.shape))\n",
    "\n",
    "        d10 = x[:, :, :, 0:4]\n",
    "        d20 = x[:, :, :, 4:10]\n",
    "\n",
    "        d10 = np.swapaxes(d10, 1, -1)\n",
    "        d10 = np.swapaxes(d10, 2, 3)\n",
    "        d20 = np.swapaxes(d20, 1, -1)\n",
    "        d20 = np.swapaxes(d20, 2, 3)\n",
    "        superresolved = DSen2(d10, d20)\n",
    "        superresolved = np.swapaxes(superresolved, 1, -1)\n",
    "        superresolved = np.swapaxes(superresolved, 1, 2)\n",
    "\n",
    "        # returns band IDXs 3, 4, 5, 7, 8, 9\n",
    "        x[:, :, :, 4:10] = superresolved\n",
    "        aft = timer()\n",
    "        print(\"The superresolve took: {}\".format(aft - bef))\n",
    "        x, amin = evi(x, True)\n",
    "        x = bi(x, True)\n",
    "        x = msavi2(x, True)\n",
    "        x = si(x, True)\n",
    "        \n",
    "        # check for and remove null values\n",
    "        \n",
    "        missing_pixels = 0\n",
    "        for band in range(0, 15):\n",
    "            for time in range(0, x.shape[0]):\n",
    "                x_i = x[time, :, :, band]\n",
    "                missing_pixels += len(np.argwhere(np.isnan(x_i)))\n",
    "                x_i[np.argwhere(np.isnan(x_i))] = np.mean(x_i)\n",
    "                x[time, :, :, band] = x_i\n",
    "        print(\"There are {} missing pixels\".format(missing_pixels))\n",
    "        \n",
    "        \n",
    "        x = calculate_and_save_best_images(x, image_dates)\n",
    "        \n",
    "        bef = timer()\n",
    "        no_dem = np.delete(x, 10, -1)\n",
    "        no_dem = np.reshape(no_dem, (72, 128*128*14))\n",
    "        no_dem = np.swapaxes(no_dem, 0, 1)\n",
    "        \n",
    "        pool = multiprocessing.Pool(6)\n",
    "        no_dem = pool.map(smooth, no_dem)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        no_dem = np.swapaxes(no_dem, 0, 1)\n",
    "        no_dem = np.reshape(no_dem, (72, 128, 128, 14))\n",
    "        x[:, :, :, :10] = no_dem[:, :, :, :10]\n",
    "        x[:, :, :, 11:] = no_dem[:, :, :, 10:]\n",
    "        aft = timer()\n",
    "        print(\"The interpolation of pixels took {}\".format(aft - bef))\n",
    "        \n",
    "        #for row in range(0, (SIZE*14)+2):\n",
    "        #    for column in range(0, (SIZE*14)+2):\n",
    "        #        for band in [x for x in range(0, 15) if x != 10]:\n",
    "        #            x[:, row, column, band] = smooth(x[:, row, column, band], 800, d = 2)\n",
    "        \n",
    "        biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "        to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "        x = np.delete(x, to_remove, 0)\n",
    "        print(x.shape)\n",
    "        print(s1.shape)\n",
    "        \n",
    "        fused = np.concatenate([x, s1], axis = -1)\n",
    "        print(fused.shape)\n",
    "        np.save(output_folder + \"/\" + str(idx_x) + \".npy\", fused)\n",
    "        end = timer()\n",
    "        print(\"Finished in {}\".format(end - start))\n",
    "        return fused, cloud_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(0, 10):\n",
    "    for c in range(0, 10):\n",
    "        x2 = worker_download(corner_coordinates[r][c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### x2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 14))\n",
    "sns.heatmap(x2[1][38, :, :]) # 22, 27, 29, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "START_Y = 0\n",
    "START_X = 0\n",
    "\n",
    "import multiprocessing\n",
    "for i in corner_coordinates[:8]:\n",
    "    try:\n",
    "        threads = 3\n",
    "        pool = multiprocessing.Pool(threads)\n",
    "        zip(*pool.map(worker_download, i[:12]))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    except Exception as e:\n",
    "        print(\"error\")\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
