{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from osgeo import ogr, osr\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import rasterio\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'proposed'\n",
    "if model == \"proposed\":\n",
    "    model = \"../../models/april-10/88-69-5/\"\n",
    "    new_saver = tf.train.import_meta_graph(model + \"model.meta\")\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint(model))\n",
    "\n",
    "    for i in range(50):\n",
    "        try:\n",
    "            fm = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "        except Exception:\n",
    "            pass\n",
    "    #logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_11/Sigmoid:0\")\n",
    "    inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "    labels = tf.get_default_graph().get_tensor_by_name(\"Placeholder_2:0\")\n",
    "    rmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "    rmin = tf.get_default_graph().get_tensor_by_name(\"Placeholder_5:0\")\n",
    "    length = tf.get_default_graph().get_tensor_by_name(\"Placeholder_1:0\")\n",
    "    dmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_6:0\")\n",
    "if model == 'unet':\n",
    "    model = \"../../models/unet-resnet/new/34-65-9/\"\n",
    "    new_saver = tf.train.import_meta_graph(model + \"model.meta\")\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint(model))\n",
    "    for i in range(50):\n",
    "            try:\n",
    "                fm = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "    rmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "    rmin = tf.get_default_graph().get_tensor_by_name(\"Placeholder_5:0\")\n",
    "    dmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_6:0\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_all = [0.20792677521705638,\n",
    " 0.2990041905641556,\n",
    " 0.4360648360848427,\n",
    " 0.5161105132102968,\n",
    " 0.4825860628485681,\n",
    " 0.4943232241272928,\n",
    " 0.5178957056999209,\n",
    " 0.5291672283411026,\n",
    " 0.6659183305501939,\n",
    " 0.6092100739479065,\n",
    " 0.37346625328063965,\n",
    " 0.7162704998254776,\n",
    " 0.40363759160041823,\n",
    " 0.6478493613004686,\n",
    " 0.8438000082969666,\n",
    " 0.15365000069141388]\n",
    "\n",
    "min_all = [0.01872335869818926,\n",
    " 0.03467957343906164,\n",
    " 0.021185510214418172,\n",
    " 0.08898216009140014,\n",
    " 0.052402322441339494,\n",
    " 0.07628638863563539,\n",
    " 0.083824477866292,\n",
    " 0.08768215030431747,\n",
    " 0.05718051139265299,\n",
    " 0.0372315139323473,\n",
    " 0.0,\n",
    " 0.007564654648303981,\n",
    " -0.019136652257293465,\n",
    " 0.0064204379683360435,\n",
    " 0.006225000135600567,\n",
    " 4.999999873689376e-05]\n",
    "\n",
    "clipping_params = {\n",
    "    'rmax': rmax,\n",
    "    'rmin': rmin,\n",
    "    'dmax': dmax\n",
    "}\n",
    "\n",
    "def load_file(file):\n",
    "    plot_id = int(data['PL_PLOTID'][data['PLOT_ID'] == file].unique())\n",
    "    x = np.load(\"../../data/drylands/s2/\" + str(file) + \".npy\")\n",
    "\n",
    "    filtered = median_filter(x[0, :, :, 10], size = 5)\n",
    "    filtered = np.reshape(filtered, (8, 2, 8, 2))\n",
    "    filtered = np.mean(filtered, axis = (1, 3))\n",
    "    filtered = resize(filtered, (16, 16), 0)\n",
    "    x[:, :, :, 10] = np.stack([filtered] * 24)\n",
    "    \n",
    "    s1 = np.load(\"../../data/drylands/s1/\" + str(file) + \".npy\")\n",
    "    x = np.concatenate([x, s1], axis = -1)\n",
    "    x = np.delete(x, 14, -1)\n",
    "    \n",
    "    for band in range(0, x.shape[-1]):\n",
    "        mins = min_all[band]\n",
    "        maxs = max_all[band]\n",
    "        x[:, :, :, band] = np.clip(x[:, :, :, band], mins, maxs)\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = (x[:, :, :,band] - midrange) / (rng / 2)\n",
    "        x[:, :, :, band] = standardized\n",
    "        \n",
    "    return x, plot_id\n",
    "    \n",
    "def predict_array(x, plot_id):\n",
    "    lengths = np.tile(np.array(24), (1, 1))\n",
    "    batch_pred= sess.run([fm], feed_dict={inp: x[np.newaxis, :, :, :, :],\n",
    "                                      length: lengths,\n",
    "                                      clipping_params['rmax']: 5,\n",
    "                                      clipping_params['rmin']: 0,\n",
    "                                      clipping_params['dmax']: 3,\n",
    "                                      })\n",
    "    batch_pred = np.array(batch_pred).reshape((14, 14))\n",
    "\n",
    "    batch_pred[np.where(batch_pred >= 0.5)] = 1.\n",
    "    batch_pred[np.where(batch_pred < 0.5)] = 0.\n",
    "    sub = df[df['PLOT_ID'] == plot_id]\n",
    "    ys = np.array(sub['tree_cover'])\n",
    "    country = sub['Country']\n",
    "\n",
    "    op1 = np.sum(batch_pred[3:10, 4:11]) / 49\n",
    "    op2 = np.sum(batch_pred[3:10, 3:10]) / 49\n",
    "    op3 = np.sum(batch_pred[4:11, 3:10]) / 49\n",
    "    op4 = np.sum(batch_pred[4:11, 4:11]) / 49\n",
    "\n",
    "    ops = [op1, op2, op3, op4]\n",
    "    pred = np.mean(ops)\n",
    "    return pred, ys, country\n",
    "\n",
    "def predict_unet(x, plot_id):\n",
    "    x = np.mean(x, axis = 0)\n",
    "    batch_pred= sess.run([fm], feed_dict={inp: x[np.newaxis, :, :, :],\n",
    "                                      clipping_params['rmax']: 5,\n",
    "                                      clipping_params['rmin']: 0,\n",
    "                                      clipping_params['dmax']: 3,\n",
    "                                      })\n",
    "    batch_pred = np.array(batch_pred).reshape((14, 14))\n",
    "\n",
    "    batch_pred[np.where(batch_pred >= 0.45)] = 1.\n",
    "    batch_pred[np.where(batch_pred < 0.45)] = 0.\n",
    "    sub = df[df['PLOT_ID'] == plot_id]\n",
    "    ys = np.array(sub['tree_cover'])\n",
    "    country = sub['Country']\n",
    "\n",
    "    op1 = np.sum(batch_pred[3:10, 4:11]) / 49\n",
    "    op2 = np.sum(batch_pred[3:10, 3:10]) / 49\n",
    "    op3 = np.sum(batch_pred[4:11, 3:10]) / 49\n",
    "    op4 = np.sum(batch_pred[4:11, 4:11]) / 49\n",
    "\n",
    "    ops = [op1, op2, op3, op4]\n",
    "    pred = np.mean(ops)\n",
    "    return pred, ys, country\n",
    "\n",
    "def predict_rf(x, plot_id):\n",
    "    x = np.mean(x, axis = 0)\n",
    "    x = x[1:-1, 1:-1, :]\n",
    "    x = np.reshape(x, (x.shape[0]*x.shape[1], x.shape[-1]))\n",
    "\n",
    "\n",
    "    preds = clf.predict(x)\n",
    "\n",
    "    preds[np.where(preds >= 0.43)] = 1.\n",
    "    preds[np.where(preds < 0.43)] = 0.\n",
    "    preds = preds.reshape((14, 14))\n",
    "    sub = df[df['PLOT_ID'] == plot_id]\n",
    "    ys = np.array(sub['tree_cover'])\n",
    "    country = sub['Country']\n",
    "\n",
    "    op1 = np.sum(preds[3:10, 4:11]) / 49\n",
    "    #op2 = np.sum(preds[3:10, 3:10]) / 49\n",
    "    #op3 = np.sum(preds[4:11, 3:10]) / 49\n",
    "    #op4 = np.sum(preds[4:11, 4:11]) / 49\n",
    "\n",
    "    #ops = [op1, op2, op3, op4]\n",
    "    #ops_diff = np.array([abs(x - ys) for x in ops]).flatten()\n",
    "    #pred = np.array(ops[np.argmin(np.array(ops_diff))])\n",
    "    #pred = min(possible_values, key=lambda x:abs(x-pred))\n",
    "    #pred = np.mean(ops)\n",
    "    pred = op1\n",
    "    \n",
    "    return pred, ys, country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Bastin et al. stratified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/latlongs/stratified.csv\")\n",
    "df['PLOT_ID'] = range(0, len(df))\n",
    "df = df.reset_index()\n",
    "df = df.drop(\"Unnamed: 0\", axis = 1)\n",
    "df1 = pd.read_csv(\"../../data/latlongs/stratified_new.csv\")\n",
    "df1['PLOT_ID'] = range(3000, 3000+len(df1))\n",
    "df1 = df1.reset_index()\n",
    "df1 = df1.drop([\"LAT\", \"LON\"], axis = 1)\n",
    "cols = list(df1.columns)\n",
    "a, b = cols.index('group'), cols.index('PLOT_ID')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "df1 = df1[cols]\n",
    "df = pd.concat([df, df1], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] = 'Asia'\n",
    "df['Country'][df['dryland_assessment_region'].isin(['HornAfrica', 'Sahel', 'SouthernAfrica', 'NorthernAfrica'])] = 'Africa'\n",
    "df['Country'][df['dryland_assessment_region'].isin(['SouthWestAsia, CentralAsia', 'MiddleEast'])] = 'Asia'\n",
    "df['Country'][df['dryland_assessment_region'].isin(['Europe'])] = 'Europe'\n",
    "df['Country'][df['dryland_assessment_region'].isin(['Australia'])] = 'Australia'\n",
    "df['Country'][df['dryland_assessment_region'].isin(['NorthAmerica'])] = 'NorthAmerica'\n",
    "df['Country'][df['dryland_assessment_region'].isin(['EastSouthAmerica', 'WestSouthAmerica'])] = 'SouthAmerica'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Country').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dryland_assessment_region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict tree cover for each plot\n",
    "\n",
    "Run for each file in fao-ceo/fao-test-*.csv\n",
    "\n",
    "Load the associated S1 and S2 processed imagery, and get a $\\hat{Y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "file = '1'\n",
    "model = 'proposed' # ['proposed', 'randomforest', 'unet']\n",
    "data = pd.read_csv(\"../../data/drylands/csv/fao-test-{}.csv\".format(file))\n",
    "data = data.drop(\"IMAGERY_TITLE\", axis = 1)\n",
    "data = data.dropna(axis = 0)\n",
    "\n",
    "if model == 'randomforest':\n",
    "    clf = load('../../models/randomforest/model.joblib') \n",
    "    \n",
    "files = [x for x in os.listdir(\"../../data/drylands/s1/\") if \".npy\" in x]\n",
    "files = [x for x in files if x in os.listdir(\"../../data/drylands/s2/\")]\n",
    "files = sorted([int(x[:-4]) for x in files])\n",
    "files = [x for x in files if x in np.unique(data['PLOT_ID'])]\n",
    "#63-64, 70:71\n",
    "preds = []\n",
    "countries = []\n",
    "ys = []\n",
    "for i in files:\n",
    "    x, plot_id = load_file(i)\n",
    "    if model == \"proposed\":\n",
    "        p, y, country = predict_array(x, plot_id)\n",
    "    if model == \"randomforest\":\n",
    "        p, y, country = predict_rf(x, plot_id)\n",
    "    if model == 'unet':\n",
    "        p, y, country = predict_unet(x, plot_id)\n",
    "    #p, y, country = load_and_predict_folder(i)\n",
    "    preds.append(p)\n",
    "    ys.append(y)\n",
    "    countries.append(country)\n",
    "    \n",
    "def reconstruct_images(plot_id, df = data):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    rows = []\n",
    "    latitudes = list(reversed(sorted(subs['LAT'].unique())))\n",
    "    for i, val in enumerate(latitudes):\n",
    "        subs_lat = subs[subs['LAT'] == val]\n",
    "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
    "        rows.append(list(subs_lat['TREE']))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Y pred, Y relabel, Y label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = files.index(np.min(files))\n",
    "end = files.index(np.max(files))\n",
    "\n",
    "# og: [1:, 1:], 644\n",
    "# [1:, :-1] 642 (current RF)\n",
    "# [:-1, 1:] 642,\n",
    "# [:-1, :-1] 640\n",
    "def make_preds_and_trues(start, end, df = data):\n",
    "    plot_ids = np.unique(df['PLOT_ID'])\n",
    "    plot_ids_fao = np.unique(df['PL_PLOTID'])\n",
    "    true_ceo = []\n",
    "    preds_ceo = []\n",
    "    true_files = []\n",
    "    for i in files[start:end]:\n",
    "        if i in plot_ids:\n",
    "            arr = np.array(reconstruct_images(i))\n",
    "            total_1 = np.sum(arr[1:, 1:])\n",
    "            total_2 = np.sum(arr[1:, :-1])\n",
    "            total_3 = np.sum(arr[:-1, 1:])\n",
    "            total_4 = np.sum(arr[:-1, :-1])\n",
    "            #total = (total_1 + total_2 + total_3 + total_4) / 4\n",
    "            true_ceo.append(total_1)\n",
    "            true_files.append(plot_ids_fao[np.argwhere(plot_ids == i)])\n",
    "    preds_ceo = preds[start:end]\n",
    "    return true_ceo, preds_ceo, np.array(true_files).flatten()\n",
    "\n",
    "true_ceo, preds_ceo, fao_files = make_preds_and_trues(start, end)\n",
    "np.save(\"../../data/drylands/output/{}/{}-true.npy\".format(model, file), np.array(true_ceo))\n",
    "np.save(\"../../data/drylands/output/{}/{}-pred.npy\".format(model, file), np.array(preds_ceo))\n",
    "np.save(\"../../data/drylands/output/{}/{}-files.npy\".format(model, file), np.array(fao_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all plots in each .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'proposed'\n",
    "total_y = np.empty(shape = (0,))\n",
    "total_x = np.empty(shape = (0,))\n",
    "total_files = np.empty(shape = (0,))\n",
    "#for i in [1, 2, 6, 7, 9, 11]:\n",
    "for i in [1, 2, 6, 7, 9, 11, 12]:\n",
    "    y = np.load(\"../../data/drylands/output/{}/{}-true.npy\".format(model, str(i)))\n",
    "    x = np.load(\"../../data/drylands/output/{}/{}-pred.npy\".format(model, str(i)))\n",
    "    fao_files = np.load(\"../../data/drylands/output/{}/{}-files.npy\".format(model, str(i)))\n",
    "    total_y = np.concatenate([total_y, y])\n",
    "    total_x = np.concatenate([total_x, x])\n",
    "    total_files = np.concatenate([total_files, fao_files])\n",
    "    print(i, x.shape, y.shape, fao_files.shape)\n",
    "print(len(total_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Bastin et al. data where tree cover matches within 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fao_y = np.array(df[df['PLOT_ID'].isin(total_files)]['tree_cover'])\n",
    "use_original = np.argwhere(abs(total_y / 49 - fao_y) < 0.3)\n",
    "print(len(use_original))\n",
    "total_y[use_original] = (fao_y[use_original] * 49)\n",
    "p = [0., 0.02, 0.04, 0.06, 0.08, \n",
    "                       0.15, 0.25, 0.35, 0.45, 0.55, 0.65,\n",
    "                       0.75, 0.85, 0.95]\n",
    "\n",
    "#p = [0., 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.]\n",
    "new_x = []\n",
    "new_y = []\n",
    "for x, y, in zip(total_x, total_y):\n",
    "    \n",
    "    x_diff = p[np.argmin([abs(p - x)])]\n",
    "    y_diff = p[np.argmin([abs(p - y/49)])]\n",
    "    new_x.append(x_diff)\n",
    "    new_y.append(y_diff)\n",
    "\n",
    "\n",
    "countries = np.array(df[df['PLOT_ID'].isin(total_files)]['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "\n",
    "def r_to_z(r):\n",
    "    return math.log((1 + r) / (1 - r)) / 2.0\n",
    "\n",
    "def z_to_r(z):\n",
    "    e = math.exp(2 * z)\n",
    "    return((e - 1) / (e + 1))\n",
    "\n",
    "def r_confidence_interval(r, alpha, n):\n",
    "    z = r_to_z(r)\n",
    "    se = 1.0 / math.sqrt(n - 3)\n",
    "    z_crit = scipy.stats.norm.ppf(1 - alpha/2)  # 2-tailed z critical value\n",
    "\n",
    "    lo = z - z_crit * se\n",
    "    hi = z + z_crit * se\n",
    "\n",
    "    # Return a sequence\n",
    "    return (z_to_r(lo), z_to_r(hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposed\n",
    "corr = np.corrcoef(np.array(new_x), new_y)[0][1]\n",
    "ci = r_confidence_interval(corr, 0.05, len(total_files))\n",
    "print(corr, ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet\n",
    "corr = np.corrcoef(np.array(new_x), new_y)[0][1]\n",
    "ci = r_confidence_interval(corr, 0.05, len(total_files))\n",
    "print(corr, ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "corr = np.corrcoef(np.array(new_x), new_y)[0][1]\n",
    "ci = r_confidence_interval(corr, 0.05, len(total_files))\n",
    "print(corr, ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with original FAO plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Proposed\")\n",
    "new_y = np.array(new_y)\n",
    "new_x = np.array(new_x)\n",
    "fao_y = np.array(df[df['PLOT_ID'].isin(total_files)]['tree_cover'])\n",
    "countries = np.array(df[df['PLOT_ID'].isin(total_files)]['Country'])\n",
    "for i in np.unique(countries):\n",
    "    country_i_y = new_y[np.argwhere(countries == i)].flatten()\n",
    "    country_i_x = new_x[np.argwhere(countries == i)].flatten()\n",
    "    diffs = np.around(np.mean(abs(country_i_y - country_i_x)), 2)\n",
    "    cor = np.corrcoef(np.array(country_i_y), country_i_x)[0][1]\n",
    "    ci = r_confidence_interval(cor, 0.05, len(country_i_x) * 2)\n",
    "    cis = [np.around(ci[0], 3), np.around(ci[1], 3)]\n",
    "    print(i, \"\\t\\t\\t\",  np.around(cor, 3), \"Diffs: \", diffs, \"CI\", cis, len(country_i_x), cis[1] - cis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(new_x) - sum(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(new_x - new_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposed\n",
    "fao_y = np.array(df[df['PLOT_ID'].isin(total_files)]['tree_cover'])\n",
    "aridity = np.array(df[df['PLOT_ID'].isin(total_files)]['Aridity_zone'])\n",
    "for i in np.unique(aridity):\n",
    "    country_i_y = new_y[np.argwhere(aridity == i)].flatten()\n",
    "    country_i_x = new_x[np.argwhere(aridity == i)].flatten()\n",
    "    print(i, \"\\t\\t\\t\",  np.corrcoef(np.array(country_i_y), country_i_x)[0][1], len(country_i_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = np.zeros_like(new_x)\n",
    "forest_true = np.zeros_like(new_y)\n",
    "forest_pred[np.argwhere(new_x > 0.1)] = 1.\n",
    "forest_true[np.argwhere(new_y > 0.1)] = 1.\n",
    "tp = sum(forest_pred * forest_true)\n",
    "fp = sum(forest_pred * (1 - forest_true))\n",
    "fn = sum((1 - forest_pred) * forest_true)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y2 = np.zeros_like(new_y)\n",
    "new_x2 = np.zeros_like(new_x)\n",
    "for i, (value1, value2) in enumerate(zip(new_x, new_y)):\n",
    "    if value1 in [0, 0.02, 0.04, 0.06, 0.08]:\n",
    "        new_x2[i] = 1.\n",
    "    if value1 in [0.15, 0.25, 0.35, 0.45, 0.55, 0.65]:\n",
    "        new_x2[i] = 2.\n",
    "    if value1 in[0.75, 0.85, 0.95]:\n",
    "        new_x2[i] = 4.\n",
    "        \n",
    "    if value2 in [0, 0.02, 0.04, 0.06, 0.08]:\n",
    "        new_y2[i] = 1.\n",
    "    if value2 in [0.15, 0.25, 0.35, 0.45, 0.55, 0.65]:\n",
    "        new_y2[i] = 2.\n",
    "    if value2 in[0.75,  0.85, 0.95]:\n",
    "        new_y2[i] = 4.\n",
    "        \n",
    "        \n",
    "from sklearn import metrics\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(font_scale = 2)\n",
    "C = metrics.confusion_matrix(new_y2, new_x2)\n",
    "C = C / C.astype(np.float).sum(axis=0, keepdims=True) \n",
    "C = np.flipud(C)\n",
    "ax = sns.heatmap(C,\n",
    "           cmap=\"YlGnBu\", vmax = 0.6, annot=True, annot_kws={\"size\": 16},\n",
    "           yticklabels = [\"66+\", \"10-65\", \"0-9\"],\n",
    "           xticklabels = [\"0-9\", \"10-65\", \"66+\"]\n",
    "                )\n",
    "ax.set(xlabel='Predicted tree cover', ylabel='Actual tree cover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rounded = (np.around(np.array(new_y), 1) * 100).astype(int)\n",
    "x_rounded = (np.around(np.array(new_x), 1) * 100).astype(int)\n",
    "\n",
    "y_rounded[np.argwhere(y_rounded == 10)] = 20\n",
    "x_rounded[np.argwhere(x_rounded == 10)] = 20\n",
    "y_rounded[np.argwhere(y_rounded == 100)] = 80\n",
    "x_rounded[np.argwhere(x_rounded == 100)] = 80\n",
    "\n",
    "from sklearn import metrics\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_rounded, x_rounded)\n",
    "confusion = np.flipud(confusion)\n",
    "ax = sns.heatmap((confusion / ((np.sum(confusion, axis = 0)))),\n",
    "           cmap=\"YlGnBu\", vmax = 0.6, annot=True, annot_kws={\"size\": 16},\n",
    "                 yticklabels = ['80+', '60-80', '40-60', '10-40', '0-10'],\n",
    "                 xticklabels = ['0-10', '10-40', '40-60', '60-80',' 80+'],\n",
    "                )\n",
    "ax.set(xlabel='Predicted tree cover', ylabel='Actual tree cover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest\")\n",
    "new_y = np.array(new_y)\n",
    "new_x = np.array(new_x)\n",
    "fao_y = np.array(df[df['PLOT_ID'].isin(total_files)]['tree_cover'])\n",
    "countries = np.array(df[df['PLOT_ID'].isin(total_files)]['Country'])\n",
    "for i in np.unique(countries):\n",
    "    country_i_y = new_y[np.argwhere(countries == i)].flatten()\n",
    "    country_i_x = new_x[np.argwhere(countries == i)].flatten()\n",
    "    diffs = np.around(np.mean(abs(country_i_y - country_i_x)), 2)\n",
    "    cor = np.corrcoef(np.array(country_i_y), country_i_x)[0][1]\n",
    "    ci = r_confidence_interval(cor, 0.05, len(country_i_x))\n",
    "    cis = [np.around(ci[0], 3), np.around(ci[1], 3)]\n",
    "    print(i, \"\\t\\t\\t\",  np.around(cor, 3), \"Diffs: \", diffs, \"CI\", cis, len(country_i_x), cis[1] - cis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forestts\n",
    "fao_y = np.array(df[df['PLOT_ID'].isin(total_files)]['tree_cover'])\n",
    "aridity = np.array(df[df['PLOT_ID'].isin(total_files)]['Aridity_zone'])\n",
    "for i in np.unique(aridity):\n",
    "    country_i_y = new_y[np.argwhere(aridity == i)].flatten()\n",
    "    country_i_x = new_x[np.argwhere(aridity == i)].flatten()\n",
    "    print(i, \"\\t\\t\\t\",  np.corrcoef(np.array(country_i_y), country_i_x)[0][1], len(country_i_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(new_x - new_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = np.zeros_like(new_x)\n",
    "forest_true = np.zeros_like(new_y)\n",
    "forest_pred[np.argwhere(new_x > 0.1)] = 1.\n",
    "forest_true[np.argwhere(new_y > 0.1)] = 1.\n",
    "tp = sum(forest_pred * forest_true)\n",
    "fp = sum(forest_pred * (1 - forest_true))\n",
    "fn = sum((1 - forest_pred) * forest_true)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y2 = np.zeros_like(new_y)\n",
    "new_x2 = np.zeros_like(new_x)\n",
    "for i, (value1, value2) in enumerate(zip(new_x, new_y)):\n",
    "    if value1 in [0, 0.02, 0.04, 0.06, 0.08]:\n",
    "        new_x2[i] = 1.\n",
    "    if value1 in [0.15, 0.25, 0.35, 0.45, 0.55, 0.65]:\n",
    "        new_x2[i] = 2.\n",
    "    if value1 in[0.75, 0.85, 0.95]:\n",
    "        new_x2[i] = 4.\n",
    "        \n",
    "    if value2 in [0, 0.02, 0.04, 0.06, 0.08]:\n",
    "        new_y2[i] = 1.\n",
    "    if value2 in [0.15, 0.25, 0.35, 0.45, 0.55, 0.65]:\n",
    "        new_y2[i] = 2.\n",
    "    if value2 in[0.75,  0.85, 0.95]:\n",
    "        new_y2[i] = 4.\n",
    "        \n",
    "        \n",
    "from sklearn import metrics\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(font_scale = 2)\n",
    "C = metrics.confusion_matrix(new_y2, new_x2)\n",
    "C = C / C.astype(np.float).sum(axis=0, keepdims=True) \n",
    "C = np.flipud(C)\n",
    "ax = sns.heatmap(C,\n",
    "           cmap=\"YlGnBu\", vmax = 0.6, annot=True, annot_kws={\"size\": 16},\n",
    "           yticklabels = [\"66+\", \"10-65\", \"0-9\"],\n",
    "           xticklabels = [\"0-9\", \"10-65\", \"66+\"]\n",
    "                )\n",
    "ax.set(xlabel='Predicted tree cover', ylabel='Actual tree cover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rounded = (np.around(np.array(new_y), 1) * 100).astype(int)\n",
    "x_rounded = (np.around(np.array(new_x), 1) * 100).astype(int)\n",
    "\n",
    "y_rounded[np.argwhere(y_rounded == 10)] = 20\n",
    "x_rounded[np.argwhere(x_rounded == 10)] = 20\n",
    "y_rounded[np.argwhere(y_rounded == 100)] = 80\n",
    "x_rounded[np.argwhere(x_rounded == 100)] = 80\n",
    "\n",
    "from sklearn import metrics\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_rounded, x_rounded)\n",
    "confusion = np.flipud(confusion)\n",
    "ax = sns.heatmap((confusion / ((np.sum(confusion, axis = 0)))),\n",
    "           cmap=\"YlGnBu\", vmax = 0.6, annot=True, annot_kws={\"size\": 16},\n",
    "                 yticklabels = ['80+', '60-80', '40-60', '10-40', '0-10'],\n",
    "                 xticklabels = ['0-10', '10-40', '40-60', '60-80',' 80+'],\n",
    "                )\n",
    "ax.set(xlabel='Predicted tree cover', ylabel='Actual tree cover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UNET\")\n",
    "new_y = np.array(new_y)\n",
    "new_x = np.array(new_x)\n",
    "fao_y = np.array(df[df['PLOT_ID'].isin(total_files)]['tree_cover'])\n",
    "countries = np.array(df[df['PLOT_ID'].isin(total_files)]['Country'])\n",
    "for i in np.unique(countries):\n",
    "    country_i_y = new_y[np.argwhere(countries == i)].flatten()\n",
    "    country_i_x = new_x[np.argwhere(countries == i)].flatten()\n",
    "    diffs = np.around(np.mean(abs(country_i_y - country_i_x)), 2)\n",
    "    cor = np.corrcoef(np.array(country_i_y), country_i_x)[0][1]\n",
    "    ci = r_confidence_interval(cor, 0.05, len(country_i_x))\n",
    "    cis = [np.around(ci[0], 3), np.around(ci[1], 3)]\n",
    "    print(i, \"\\t\\t\\t\",  np.around(cor, 3), \"Diffs: \", diffs, \"CI\", cis, len(country_i_x), cis[1] - cis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(new_x - new_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = np.zeros_like(new_x)\n",
    "forest_true = np.zeros_like(new_y)\n",
    "forest_pred[np.argwhere(new_x > 0.1)] = 1.\n",
    "forest_true[np.argwhere(new_y > 0.1)] = 1.\n",
    "tp = sum(forest_pred * forest_true)\n",
    "fp = sum(forest_pred * (1 - forest_true))\n",
    "fn = sum((1 - forest_pred) * forest_true)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNET\n",
    "fao_y = np.array(df[df['PLOT_ID'].isin(total_files)]['tree_cover'])\n",
    "aridity = np.array(df[df['PLOT_ID'].isin(total_files)]['Aridity_zone'])\n",
    "for i in np.unique(aridity):\n",
    "    country_i_y = new_y[np.argwhere(aridity == i)].flatten()\n",
    "    country_i_x = new_x[np.argwhere(aridity == i)].flatten()\n",
    "    print(i, \"\\t\\t\\t\",  np.corrcoef(np.array(country_i_y), country_i_x)[0][1], len(country_i_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y2 = np.zeros_like(new_y)\n",
    "new_x2 = np.zeros_like(new_x)\n",
    "for i, (value1, value2) in enumerate(zip(new_x, new_y)):\n",
    "    if value1 in [0, 0.02, 0.04, 0.06, 0.08]:\n",
    "        new_x2[i] = 1.\n",
    "    if value1 in [0.15, 0.25, 0.35, 0.45, 0.55, 0.65]:\n",
    "        new_x2[i] = 2.\n",
    "    if value1 in[0.75, 0.85, 0.95]:\n",
    "        new_x2[i] = 4.\n",
    "        \n",
    "    if value2 in [0, 0.02, 0.04, 0.06, 0.08]:\n",
    "        new_y2[i] = 1.\n",
    "    if value2 in [0.15, 0.25, 0.35, 0.45, 0.55, 0.65]:\n",
    "        new_y2[i] = 2.\n",
    "    if value2 in[0.75,  0.85, 0.95]:\n",
    "        new_y2[i] = 4.\n",
    "        \n",
    "        \n",
    "from sklearn import metrics\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(font_scale = 2)\n",
    "C = metrics.confusion_matrix(new_y2, new_x2)\n",
    "C = C / C.astype(np.float).sum(axis=0, keepdims=True) \n",
    "C = np.flipud(C)\n",
    "ax = sns.heatmap(C,\n",
    "           cmap=\"YlGnBu\", vmax = 0.6, annot=True, annot_kws={\"size\": 16},\n",
    "           yticklabels = [\"66+\", \"10-65\", \"0-9\"],\n",
    "           xticklabels = [\"0-9\", \"10-65\", \"66+\"]\n",
    "                )\n",
    "ax.set(xlabel='Predicted tree cover', ylabel='Actual tree cover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rounded = (np.around(np.array(new_y), 1) * 100).astype(int)\n",
    "x_rounded = (np.around(np.array(new_x), 1) * 100).astype(int)\n",
    "\n",
    "y_rounded[np.argwhere(y_rounded == 10)] = 20\n",
    "x_rounded[np.argwhere(x_rounded == 10)] = 20\n",
    "y_rounded[np.argwhere(y_rounded == 100)] = 80\n",
    "x_rounded[np.argwhere(x_rounded == 100)] = 80\n",
    "\n",
    "from sklearn import metrics\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_rounded, x_rounded)\n",
    "confusion = np.flipud(confusion)\n",
    "ax = sns.heatmap((confusion / ((np.sum(confusion, axis = 0)))),\n",
    "           cmap=\"YlGnBu\", vmax = 0.6, annot=True, annot_kws={\"size\": 16},\n",
    "                 yticklabels = ['80+', '60-80', '40-60', '10-40', '0-10'],\n",
    "                 xticklabels = ['0-10', '10-40', '40-60', '60-80',' 80+'],\n",
    "                )\n",
    "ax.set(xlabel='Predicted tree cover', ylabel='Actual tree cover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the correlation between the labeled CEO plots and the labeled FAO plots\")\n",
    "np.corrcoef(np.array(new_y) / 49, fao_y)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the correlation between the plot predictions and the labeled FAO plots\")\n",
    "np.corrcoef(np.array(total_x), fao_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.argwhere((total_y / 49 - fao_y) < 0.3)) / len(total_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
