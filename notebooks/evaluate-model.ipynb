{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1cba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import hickle as hkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5160cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../src/preprocessing/indices.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbbd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model_path = \"../models/may-avg-small-onethird/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8956bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../models/may-avg-small-onethird/\n"
     ]
    }
   ],
   "source": [
    "predict_graph_def = tf.compat.v1.GraphDef()\n",
    "if os.path.exists(predict_model_path):\n",
    "    print(f\"Loading model from {predict_model_path}\")\n",
    "    predict_file = tf.io.gfile.GFile(predict_model_path + \"predict_graph.pb\", 'rb')\n",
    "    predict_graph_def.ParseFromString(predict_file.read())\n",
    "    predict_graph = tf.import_graph_def(predict_graph_def, name='predict')\n",
    "    predict_sess = tf.compat.v1.Session(graph=predict_graph)\n",
    "    predict_logits = predict_sess.graph.get_tensor_by_name(f\"predict/conv2d_13/Sigmoid:0\") \n",
    "    #feature_extraction = predict_sess.graph.get_tensor_by_name(f\"predict/csse_out_mul/mul:0\")  \n",
    "    #feature_extraction_initial = predict_sess.graph.get_tensor_by_name(\n",
    "    #    \"predict/conv_median_drop/drop_block2d_1/cond/Merge:0\")\n",
    "    predict_inp = predict_sess.graph.get_tensor_by_name(\"predict/Placeholder:0\")\n",
    "    predict_length = predict_sess.graph.get_tensor_by_name(\"predict/PlaceholderWithDefault:0\")\n",
    "else:\n",
    "    raise Exception(f\"The model path {predict_model_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6fa4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_all = [0.006576638437476157, 0.0162050812542916, 0.010040436408026246, 0.013351644159609368, \n",
    "           0.01965362020294499, 0.014229037918669413, 0.015289539940489814, 0.011993591210803388, \n",
    "           0.008239871824216068, 0.006546120393682765, 0.0, 0.0, 0.0, -0.1409399364817101,\n",
    "           -0.4973397113668104, -0.09731556326714398, -0.7193834232943873]\n",
    "\n",
    "max_all = [0.2691233691920348, 0.3740291447318227, 0.5171435111009385, 0.6027466239414053, \n",
    "           0.5650263218127718, 0.5747005416952773, 0.5933928435187305, 0.6034943160143434,\n",
    "           0.7472037842374304, 0.7000076295109483, 0.509269855802243, 0.948334642387533, \n",
    "           0.6729257769285485, 0.8177635298774327, 0.35768999002433816, 0.7545951919107605, 0.7602693339366691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d56681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_db(x: np.ndarray, min_db: int) -> np.ndarray:\n",
    "    \"\"\" Converts unitless backscatter coefficient\n",
    "        to db with a min_db lower threshold\n",
    "        \n",
    "        Parameters:\n",
    "         x (np.ndarray): unitless backscatter (T, X, Y, B) array\n",
    "         min_db (int): integer from -50 to 0\n",
    "    \n",
    "        Returns:\n",
    "         x (np.ndarray): db backscatter (T, X, Y, B) array\n",
    "    \"\"\"\n",
    "    \n",
    "    x = 10 * np.log10(x + 1/65535)\n",
    "    x[x < -min_db] = -min_db\n",
    "    x = (x + min_db) / min_db\n",
    "    return np.clip(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dbb3831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424, 12, 28, 28, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x = hkl.load(\"../data/test/test_x.hkl\")\n",
    "test_y = hkl.load(\"../data/test/test_y.hkl\")\n",
    "df = pd.read_csv(\"../data/test/test_plot_ids.csv\")\n",
    "x = np.delete(x, 11, -1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d330103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.float32(x) / 65535\n",
    "\n",
    "x[..., -1] = convert_to_db(x[..., -1], 22)\n",
    "x[..., -2] = convert_to_db(x[..., -2], 22)\n",
    "\n",
    "indices = np.empty((x.shape[0], 12, 28, 28, 4))\n",
    "indices[..., 0] = evi(x)\n",
    "indices[..., 1] = bi(x)\n",
    "indices[..., 2] = msavi2(x)\n",
    "indices[..., 3] = grndvi(x)\n",
    "\n",
    "x = np.concatenate([x, indices], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05733b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "def preprocess_sample(test, idx):\n",
    "\n",
    "    med = np.median(test[idx], axis = 0)\n",
    "    med = med[np.newaxis, :, :, :]\n",
    "    sample = np.concatenate([test[idx], med], axis = 0)\n",
    "    \n",
    "    for band in range(0, sample.shape[-1]):\n",
    "        mins = min_all[band]\n",
    "        maxs = max_all[band]\n",
    "        sample[..., band] = np.clip(sample[..., band], mins, maxs)\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = (sample[..., band] - midrange) / (rng / 2)\n",
    "        sample[..., band] = standardized\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5593f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(idx)\n",
    "for i in range(0, 50):\n",
    "    print(idx, df.iloc[idx])\n",
    "    sample = preprocess_sample(x, idx)\n",
    "    batch_x = sample[np.newaxis]\n",
    "    lengths = np.full((batch_x.shape[0]), 12)\n",
    "    preds = predict_sess.run(predict_logits,\n",
    "                          feed_dict={predict_inp:batch_x, \n",
    "                                     predict_length:lengths})\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (9, 4))\n",
    "\n",
    "    sns.heatmap(preds.squeeze(), vmin = 0.0, vmax = 1, ax=ax1, cbar = False)\n",
    "    sns.heatmap(test_y[idx], vmin = 0.0, vmax = 1, ax=ax2, cbar = False)\n",
    "    plt.show()\n",
    "    idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05dc28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "al = 0.33\n",
    "\n",
    "def make_evaluation_csv(data):\n",
    "    test_ids = [x for x in range(len(x))]\n",
    "    print(len(test_ids))\n",
    "    sums = []\n",
    "    sum_preds = []\n",
    "    trues = []\n",
    "    preds = []\n",
    "    preds_arr = np.zeros_like(test_y)\n",
    "    for test_sample in test_ids:\n",
    "        #x_input = x[test_sample]#.reshape(1, 13, 28, 28, 17)\n",
    "        x_input = preprocess_sample(x, test_sample)\n",
    "        batch_x = x_input[np.newaxis]\n",
    "        lengths = np.full((batch_x.shape[0]), 12)\n",
    "        y = predict_sess.run(predict_logits,\n",
    "                              feed_dict={predict_inp:batch_x, \n",
    "                                         predict_length:lengths})\n",
    "        preds.append(y.reshape((14, 14)))\n",
    "        trues.append(test_y[test_sample].reshape((14, 14)))\n",
    "        preds_arr[test_sample] = y.reshape((14, 14))\n",
    "    thresh = 0.4\n",
    "    tps_relaxed = np.empty((len(preds), ))\n",
    "    fps_relaxed = np.empty((len(preds), ))\n",
    "    fns_relaxed = np.empty((len(preds), ))\n",
    "    abs_error = np.empty((len(preds), ))\n",
    "    \n",
    "    tree_cover = []\n",
    "    for sample in range(len(preds)):\n",
    "        pred = np.copy(preds[sample])\n",
    "        true = trues[sample]\n",
    "        if thresh == 8:\n",
    "            if np.sum(true + pred) > 0:\n",
    "                dice_losses.append(0.5)\n",
    "               # dice_losses.append(dice_loss_tolerance(np.array(true), np.array(pred)))\n",
    "            else:\n",
    "                dice_losses.append(1.)\n",
    "        pred[np.where(pred >= thresh)] = 1\n",
    "        pred[np.where(pred < thresh)] = 0\n",
    "\n",
    "        true_s = np.sum(true)\n",
    "        pred_s = np.sum(pred)\n",
    "        \n",
    "        tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "        abs_error[sample] = int((true_s - pred_s) // 1.96)\n",
    "        print(abs_error[sample])\n",
    "        tps_relaxed[sample] = tp_relaxed\n",
    "        fps_relaxed[sample] = fp_relaxed\n",
    "        fns_relaxed[sample] = fn_relaxed       \n",
    "        tree_cover.append(int( (np.sum(true) * 100) // 196))\n",
    "\n",
    "    oa_error = np.mean(abs_error)\n",
    "    precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "    recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "    f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "    data['error'] = abs_error\n",
    "    data['tp'] = tps_relaxed\n",
    "    data['fp'] = fps_relaxed\n",
    "    data['fn'] = fns_relaxed\n",
    "    data['tree_cover'] = tree_cover\n",
    "    \n",
    "    return data, preds_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023d8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    \"\"\"Because of coregistration errors, we evaluate the model\n",
    "    where false positives/negatives must be >1px away from a true positive\n",
    "    \"\"\"\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calculate_metrics(al = 0.4, canopy_thresh = 100):\n",
    "    '''Calculates the following metrics\n",
    "       \n",
    "         - Loss\n",
    "         - F1\n",
    "         - Precision\n",
    "         - Recall\n",
    "         - Dice\n",
    "         - Mean surface distance\n",
    "         - Average error\n",
    "    \n",
    "         Parameters:\n",
    "          al (float):\n",
    "          canopy_thresh (int)\n",
    "          \n",
    "         Returns:\n",
    "          val_loss (float):\n",
    "          best_dice (float):\n",
    "          error (float):\n",
    "    '''\n",
    "    best_f1, best_thresh, relaxed_f1 = 0, 0, 0\n",
    "    preds, trues, vls = [], [], []\n",
    "\n",
    "    for test_sample in range(x.shape[0]):\n",
    "        sample = preprocess_sample(x, test_sample)\n",
    "        batch_x = sample[np.newaxis]\n",
    "        lengths = np.full((batch_x.shape[0]), 12)\n",
    "        y = predict_sess.run(predict_logits,\n",
    "                              feed_dict={predict_inp:batch_x, \n",
    "                                         predict_length:lengths})\n",
    "        preds.append(y.reshape((14, 14)))\n",
    "        trues.append(test_y[test_sample].reshape((14, 14)))\n",
    "\n",
    "    # These threshes are just for ROC\n",
    "    for thresh in range(7, 9):\n",
    "        tps_relaxed = np.empty((len(preds), ))\n",
    "        fps_relaxed = np.empty((len(preds), ))\n",
    "        fns_relaxed = np.empty((len(preds), ))\n",
    "        abs_error = np.empty((len(preds), ))\n",
    "        \n",
    "        for sample in range(len(preds)):\n",
    "            pred = np.copy(preds[sample])\n",
    "            true = trues[sample]\n",
    "        \n",
    "            pred[np.where(pred >= thresh*0.05)] = 1\n",
    "            pred[np.where(pred < thresh*0.05)] = 0\n",
    "            \n",
    "            true_s = np.sum(true[1:-1])\n",
    "            pred_s = np.sum(pred[1:-1])\n",
    "            abs_error[sample] = abs(true_s - pred_s)\n",
    "            tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "            tps_relaxed[sample] = tp_relaxed\n",
    "            fps_relaxed[sample] = fp_relaxed\n",
    "            fns_relaxed[sample] = fn_relaxed                   \n",
    "            \n",
    "        oa_error = np.mean(abs_error)\n",
    "        precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "        recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "        f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "        \n",
    "        if f1_r > best_f1:\n",
    "            best_f1 = f1_r\n",
    "            p = precision_r\n",
    "            r = recall_r\n",
    "            error = oa_error\n",
    "            best_thresh = thresh*0.05\n",
    "\n",
    "    print(f\" Thresh: {np.around(best_thresh, 2)}\"\n",
    "          f\" F1: {np.around(best_f1, 3)} R: {np.around(p, 3)} P: {np.around(r, 3)}\"\n",
    "          f\" Error: {np.around(error, 3)}\")\n",
    "    return np.mean(vls), best_f1, error, (fps_relaxed + fns_relaxed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b948a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['scale', 'error', 'Reference tree cover (%)', 'Threshold'])\n",
    "\n",
    "def check_treecover_accuracy_at_grain(y, pred, scale, mincc, maxcc, threshold):\n",
    "    y_scale = y[:, 2:2+scale, 2:2+scale]\n",
    "    pred_scale = pred[:, 2:2+scale, 2:2+scale]\n",
    "    pred_scale[pred_scale < 0.25] = 0.\n",
    "    y_scale_mean = np.mean(y_scale, axis = (1, 2))\n",
    "    if threshold == True:\n",
    "        pred_scale_mean = np.mean(pred_scale > 0.4, axis = (1, 2))\n",
    "    else:\n",
    "        pred_scale_mean = np.mean(pred_scale, axis = (1, 2))\n",
    "    return abs(y_scale_mean - pred_scale_mean)[np.logical_and(y_scale_mean >= mincc /100, y_scale_mean < maxcc / 100)]\n",
    "\n",
    "for scale in [3, 5, 7, 10]:\n",
    "    for mincc in [0, 10, 40]:\n",
    "        for threshold in [False]:\n",
    "            if mincc == 0:\n",
    "                maxcc = 10\n",
    "            if mincc == 10:\n",
    "                maxcc = 40\n",
    "            if mincc == 40:\n",
    "                maxcc = 100\n",
    "            error1ha = check_treecover_accuracy_at_grain(test_y, preds_arr, scale, mincc, maxcc, threshold)\n",
    "            cc_label = f'{str(mincc)}-{str(maxcc)}'\n",
    "            m = pd.DataFrame({\"scale\": [scale * 10] * len(error1ha),\n",
    "                              \"error\":  error1ha * 100, \n",
    "                              'Reference tree cover (%)': [cc_label] * len(error1ha),\n",
    "                              'Threshold': [threshold] * len(error1ha)})\n",
    "            print(scale, mincc, threshold, len(error1ha))\n",
    "            df = df.append(m, ignore_index = True)\n",
    "print(np.mean(df['error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale = 2.5)\n",
    "sns.set_style(\"ticks\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "facet = sns.FacetGrid(df, col='Reference tree cover (%)', sharey = False, height = 12, aspect = 0.9)\n",
    "facet.map(sns.violinplot, \"scale\", \"error\", 'Threshold', cut = 0, bw = 0.15, inner = 'quartile')\n",
    "facet.set(xlabel = \"Scale (meters)\", ylabel = \"Absolute error (%)\")\n",
    "#l.set(ylim = (0, 1.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
