{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-process statistics for previous processed countries\n",
    "# check that uploading new files will simply replace what is currently there\n",
    "# or rename the old file and upload new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from time import time, strftime\n",
    "import os\n",
    "import os.path\n",
    "import boto3\n",
    "import confuse\n",
    "import rasterio as rs\n",
    "from rasterio.mask import mask\n",
    "from rasterio.merge import merge\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "import numpy as np \n",
    "import numpy.ma as ma \n",
    "import geopandas as gpd \n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "import pandas as pd\n",
    "import pandas.api.types as ptypes\n",
    "import fiona\n",
    "from contextlib import contextmanager  \n",
    "from skimage.transform import resize\n",
    "import math\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import osgeo\n",
    "from osgeo import gdal\n",
    "from osgeo import gdalconst\n",
    "import glob\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73899e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    '''\n",
    "    Prints the runtime of the decorated function.\n",
    "    '''\n",
    "    \n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        start = datetime.now() \n",
    "        value = func(*args, **kwargs)\n",
    "        end = datetime.now() \n",
    "        run_time = end - start\n",
    "        print(f'Completed {func.__name__!r} in {run_time}.')\n",
    "        return value\n",
    "    return wrapper_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf69f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_inputs(country, bucket_name, s3_folder, local_dir=None):\n",
    "    \"\"\"\n",
    "    Download the contents of a folder directory\n",
    "    Args:\n",
    "        bucket_name: the name of the s3 bucket\n",
    "        s3_folder: the folder path in the s3 bucket\n",
    "        local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    if not os.path.exists(f'{country}/'):\n",
    "        os.makedirs(f'{country}/')\n",
    "    \n",
    "    if not os.path.exists(f'{country}/resampled_rasters/'):\n",
    "        os.makedirs(f'{country}/resampled_rasters/')\n",
    "        \n",
    "    config = confuse.Configuration('sentinel-tree-cover')\n",
    "    # CHANGE ONCE ON INSTANCE\n",
    "    config.set_file('/Users/jessica.ertel/sentinel-tree-cover/jessica-config.yaml')\n",
    "    aws_access_key = config['aws']['aws_access_key_id']\n",
    "    aws_secret_key = config['aws']['aws_secret_access_key']\n",
    "    s3 = boto3.resource('s3', aws_access_key_id=aws_access_key.as_str(), aws_secret_access_key=aws_secret_key.as_str())\n",
    "    \n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    \n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        bucket.download_file(obj.key, target)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_4d(raster):\n",
    "    \n",
    "    '''\n",
    "    Takes in a GTiff, identifies the dimensions and them down to the nearest 10th.\n",
    "    Then uses those dimensions and reshapes to a 4 dimensional, 10x10 grid.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    raster : str\n",
    "        GTiff that will be reshaped\n",
    "    '''\n",
    "    \n",
    "    def round_down(num, divisor):\n",
    "         return num - (num%divisor)\n",
    "   \n",
    "    # round down rows and cols to nearest 10th\n",
    "    rows, cols = round_down(raster.shape[0], 10), round_down(raster.shape[1], 10)\n",
    "    \n",
    "    # clip according to rounded numbers and reshape\n",
    "    rounded = raster[:rows, :cols]\n",
    "    reshaped = np.reshape(rounded, (rounded.shape[0] // 10, 10, rounded.shape[1] // 10, 10))\n",
    "        \n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8683e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def calculate_stats_tml(country, extent):\n",
    "    \n",
    "    '''\n",
    "    Takes in a country and extent (full or partial) and produces zonal stats on tree cover. \n",
    "    Returns a csv with statistics per administrative district, per land cover class and \n",
    "    per tree cover threshold. Only produces statistics for TML data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    country : str\n",
    "        a string indicating the country files to import\n",
    "    extent : str\n",
    "        a string indicating the processing extent of the geotiff\n",
    "\n",
    "    '''\n",
    "    \n",
    "    if not os.path.exists(f'{country}/stats'):\n",
    "        os.makedirs(f'{country}/stats')\n",
    "        \n",
    "    df = pd.DataFrame({'country': pd.Series(dtype='str'),\n",
    "                       'admin': pd.Series(dtype='str'),\n",
    "                       'esa_id': pd.Series(dtype='str'),\n",
    "                       'esa_class': pd.Series(dtype='str'),\n",
    "                       'esa_sampled_ha': pd.Series(dtype='float64'),\n",
    "                       'esa_total_ha': pd.Series(dtype='float64'),\n",
    "                       'tree_cover_class': pd.Series(dtype='str'),\n",
    "                       'tof_ha': pd.Series(dtype='int64'),\n",
    "                       'tof_mean': pd.Series(dtype='float64')})\n",
    "    counter = 0\n",
    "    \n",
    "    folder_contents = [f for f in os.listdir(f'{country}/resampled_rasters/tof') if f != '.ipynb_checkpoints']\n",
    "    folder_contents = ['Northern.tif']\n",
    "    \n",
    "    # iterate through the admins \n",
    "    for file in folder_contents:\n",
    "        print(file)\n",
    "        \n",
    "        counter += 1\n",
    "        tof = rs.open(f'{country}/resampled_rasters/tof/{file}').read(1)\n",
    "        esa = rs.open(f'{country}/resampled_rasters/esa/{file}').read(1)\n",
    "        \n",
    "        # reshape TML admin tif to 4d array and mask where equal to 255\n",
    "        tof = reshape_to_4d(tof)\n",
    "        tof = np.ma.masked_equal(tof, 255)\n",
    "        \n",
    "        # manually calculate the mean per hectare for memory purposes\n",
    "        tof_count_per_ha = np.sum(~tof.mask, axis = (1, 3), dtype=np.uint8) \n",
    "        tof_sum_per_ha = np.sum(tof, axis = (1, 3), dtype=np.uint16)\n",
    "        tof_mean_per_ha = np.divide(tof_sum_per_ha, tof_count_per_ha, dtype=np.float32)\n",
    "\n",
    "        # reshape esa admin tif to 4d array\n",
    "        esa = reshape_to_4d(esa)\n",
    "        \n",
    "        # Set each hectare to the mode (lcc that appears most often) to prevent doouble counting \n",
    "        # The fastest way is a zipped for loop \n",
    "        for i, l in zip(range(esa.shape[0]), range(esa.shape[2])):\n",
    "            \n",
    "            # if there is > 1 unique value in a hectare of the esa tif (5-10% of cases)\n",
    "            # calculate the mode, otherwise skip this step\n",
    "            if len(np.unique(esa[i, :, l, :])) > 1:\n",
    "                esa[i, :, l, :] = scipy.stats.mode(esa[i, :, l, :].flatten())[0]\n",
    "\n",
    "        # Now that the esa array is set to the mode per hectare,\n",
    "        # We need to make it a 2D array. np.max is a safe way to reshape quickly\n",
    "        esa = np.max(esa, axis = (1, 3))\n",
    "        \n",
    "        lower_rng = [x for x in range(0, 100, 10)]\n",
    "        upper_rng = [x for x in range(10, 110, 10)]\n",
    "        \n",
    "        # Set upper to 101, otherwise it isn't inclusive of 100% hectares.\n",
    "        upper_rng[-1] = 101\n",
    "        \n",
    "        esa_classes = np.unique(esa)\n",
    "        \n",
    "        for cover in esa_classes:\n",
    "            print(cover)\n",
    "            \n",
    "            tof_class_mean_per_ha = tof_mean_per_ha.copy()\n",
    "\n",
    "            # Expand the existing no-data mask so that we calculate mean per lcc\n",
    "            # tof class mean per ha is the mean TML\n",
    "            tof_class_mean_per_ha.mask[esa != cover] = 1\n",
    "            tof_class_mean = np.round(np.mean(tof_class_mean_per_ha), 2)\n",
    "\n",
    "            # calculate the total land cover \n",
    "            lc_total = np.sum(esa == cover)\n",
    "            \n",
    "            # calculate land cover sampled - the sum of values that have not been masked out by 1\n",
    "            lc_sampled = np.sum(~tof_class_mean_per_ha.mask)\n",
    "\n",
    "            # iterate through the thresholds (0-10, 10-20, 20-30)\n",
    "            for lower, upper in zip(lower_rng, upper_rng):\n",
    "\n",
    "                # calculate total ha for that threshold \n",
    "                # if the lc sampled is a mask, then 0 area has been sampled \n",
    "                # which means tof_bin is 0 and tof mean should be NaN for that row\n",
    "                if lc_sampled == 0:\n",
    "                    tof_bin = 0\n",
    "                    tof_class_mean = np.nan\n",
    "                else:\n",
    "                    tof_bin = np.sum((tof_class_mean_per_ha >= lower) & (tof_class_mean_per_ha < upper))\n",
    "                \n",
    "                bin_name = (f'{str(lower)}-{str(upper - 1)}')\n",
    "\n",
    "                # confirm masked array doesn't propogate\n",
    "                vars_to_check = [lc_sampled, lc_total, tof_bin, tof_class_mean]\n",
    "                \n",
    "                for index, var in enumerate(vars_to_check):\n",
    "                    if np.ma.isMaskedArray(var):\n",
    "                        print(f'Masked array at index {index} for {var}.')\n",
    "                \n",
    "                # check for erroneous values\n",
    "                assert lc_sampled <= lc_total, f'Sampled area is greater than total area for land cover {cover} in {file}.'\n",
    "\n",
    "                df = df.append({'country': country, \n",
    "                               'admin': file[:-4],\n",
    "                               'esa_id': cover,\n",
    "                               'esa_sampled_ha': lc_sampled,\n",
    "                               'esa_total_ha': lc_total,\n",
    "                               'tree_cover_class': bin_name,\n",
    "                               'tof_ha': tof_bin,\n",
    "                               'tof_mean': tof_class_mean},\n",
    "                                ignore_index=True)\n",
    "\n",
    "                # reinforce datatypes\n",
    "                convert_dict = {'esa_sampled_ha':'float64',\n",
    "                                'esa_total_ha':'float64',\n",
    "                                'tof_ha':'int64',\n",
    "                                'tof_mean': 'float64'}\n",
    "                df = df.astype(convert_dict)\n",
    "                print(f'{cover} done.')\n",
    "                \n",
    "                #assert df.esa_sampled_ha.any() <= df.esa_total_ha.any(), f'Sampled area is greater than total area for land cover {cover} in {file}.'\n",
    "\n",
    "        # map ESA id numbers to lcc labels\n",
    "        esa_legend = {0: 'ESA No Data',\n",
    "                10: 'Cropland, rainfed',\n",
    "                11: 'Cropland, rainfed',\n",
    "                12: 'Cropland, rainfed',\n",
    "                20: 'Cropland, irrigated or post-flooding',\n",
    "                30: 'Mosaic cropland / natural vegetation',\n",
    "                40: 'Mosaic natural vegetation / cropland',\n",
    "                50: 'Tree cover, broadleaved, evergreen',\n",
    "                60: 'Tree cover, broadleaved, deciduous',\n",
    "                61: 'Tree cover, broadleaved, deciduous',\n",
    "                62: 'Tree cover, broadleaved, deciduous',\n",
    "                70: 'Tree cover, needleleaved, evergreen',\n",
    "                71: 'Tree cover, needleleaved, evergreen',\n",
    "                72: 'Tree cover, needleleaved, evergreen',\n",
    "                80: 'Tree cover, needleleaved, deciduous',\n",
    "                81: 'Tree cover, needleleaved, deciduous',\n",
    "                82: 'Tree cover, needleleaved, deciduous',\n",
    "                90: 'Tree cover, mixed leaf type',\n",
    "                100: 'Mosaic tree and shrub / herbaceous cover',\n",
    "                110: 'Mosaic herbaceous cover / tree and shrub',\n",
    "                120: 'Shrubland',\n",
    "                121: 'Shrubland',\n",
    "                122: 'Shrubland',\n",
    "                130: 'Grassland',\n",
    "                140: 'Lichens and mosses',\n",
    "                150: 'Sparse vegetation',\n",
    "                151: 'Sparse vegetation',\n",
    "                152: 'Sparse vegetation',\n",
    "                153: 'Sparse vegetation',\n",
    "                160: 'Tree cover, flooded, fresh or brakish water',\n",
    "                170: 'Tree cover, flooded, saline water',\n",
    "                180: 'Shrub or herbaceous cover, flooded, fresh/saline/brakish water',\n",
    "                190: 'Urban areas',\n",
    "                200: 'Bare areas',\n",
    "                201: 'Bare areas',\n",
    "                202: 'Bare areas',\n",
    "                210: 'Water bodies',\n",
    "                220: 'Permanent snow and ice',\n",
    "                255: 'No Data (flag)'}\n",
    "        df['esa_class'] = df['esa_id'].map(esa_legend)\n",
    "        \n",
    "        tof = None\n",
    "        esa = None\n",
    "        \n",
    "        if counter % 3 == 0:\n",
    "            print(f'{counter}/{len(folder_contents)} admins processed...')\n",
    "    \n",
    "    cols_to_check = ['esa_sampled_ha', 'esa_total_ha', 'tof_ha', 'tof_mean']\n",
    "    assert all(ptypes.is_numeric_dtype(df[col]) for col in cols_to_check)\n",
    "    \n",
    "    df.to_csv(f'{country}/stats/{country}_statistics_{extent}_tmlonly_Northern.csv', index=False)\n",
    "    print('Analysis complete.')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def upload_dir(filename, bucket, object_name):\n",
    "    \"\"\"\n",
    "    Upload a file to an S3 bucket. \n",
    "\n",
    "    file_name: File to upload\n",
    "    bucket: Bucket to upload to\n",
    "    object_name: S3 object name. If not specified then file_name is used\n",
    "\n",
    "    \"\"\"\n",
    "    config = confuse.Configuration('sentinel-tree-cover')\n",
    "    # CHANGE ONCE ON INSTANCE\n",
    "    config.set_file('/Users/jessica.ertel/sentinel-tree-cover/jessica-config.yaml')\n",
    "    aws_access_key = config['aws']['aws_access_key_id']\n",
    "    aws_secret_key = config['aws']['aws_secret_access_key']\n",
    "    session = boto3.Session(aws_access_key_id=aws_access_key.as_str(), aws_secret_access_key=aws_secret_key.as_str())    \n",
    "    s3 = session.client('s3') \n",
    "  \n",
    "    with open(filename, 'rb') as data:\n",
    "        s3.upload_fileobj(data, bucket, object_name)\n",
    "\n",
    "    print('Upload complete.')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dafae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def execute_pipe(country, extent):\n",
    "#     print(f'Started at: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "#     print('Downloading input data...')\n",
    "#     download_inputs(country,\n",
    "#                    'tof-output',\n",
    "#                     f'2020/analysis/2020-full/{country}/resampled_rasters/',\n",
    "#                     f'/Users/jessica.ertel/sentinel-tree-cover/notebooks/analysis/{country}/resampled_rasters/')\n",
    "    print('Calculating statistics...')\n",
    "    calculate_stats_tml(country, extent)\n",
    "#     print('Uploading files to s3...')\n",
    "#     upload_dir(f'/Users/jessica.ertel/sentinel-tree-cover/notebooks/analysis/{country}/stats/{country}_statistics_full_tmlonly.csv', \n",
    "#                'tof-output', \n",
    "#                f'2020/analysis/2020-full/{country}/stats/{country}_statistics_full_tmlonly.csv')\n",
    "    print(f'Finished {extent} processing at: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_pipe('Fiji', 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif = rs.open('Fiji/resampled_rasters/tof/Northern.tif').read(1)\n",
    "tif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5208ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif = rs.open('Fiji/resampled_rasters/esa/Eastern2.tif').read(1)\n",
    "tif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965619be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tml-analysis",
   "language": "python",
   "name": "tml-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
