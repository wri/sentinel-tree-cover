{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, preprocess, and save train and test data\n",
    "# John Brandt\n",
    "# April 1, 2020\n",
    "\n",
    "- Fuse Sentinel 1/2 data\n",
    "- Reconstruct 2D-array from CEO output CSV by plot\n",
    "- Match sentinel data to CEO labels\n",
    "- Stack data_x, data_y, length\n",
    "- Save numpy arrays for data_x, data_y, length\n",
    "\n",
    "The notebook additionally contains some development code for:\n",
    "- Parameter selection in whittaker smoothing\n",
    "- Graphing plot locations on map\n",
    "\n",
    "# Package imports and source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from scipy.ndimage import median_filter\n",
    "import hickle as hkl\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "%run ../src/preprocessing/slope.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_images(plot_id):\n",
    "    '''Takes a plot ID and subsets the input pd.DataFrame to that plot ID\n",
    "       returns a (14, 14) array-like list with binary labels\n",
    "       \n",
    "        Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    rows = []\n",
    "    lats = reversed(sorted(subs['LAT'].unique()))\n",
    "    for i, val in enumerate(lats):\n",
    "        subs_lat = subs[subs['LAT'] == val]\n",
    "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
    "        rows.append(list(subs_lat['TREE']))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'train'\n",
    "sentinel_1 = True\n",
    "s2_path = \"../data/{}-s2-new/\".format(source)\n",
    "s1_path = \"../data/{}-s1-radiometric/\".format(source)\n",
    "csv_path = \"../data/{}-csv/\".format(source)\n",
    "output_path = \"../data/{}-processed/\".format(source)\n",
    "dem_path = \"../data/{}-dem/\".format(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2307\n"
     ]
    }
   ],
   "source": [
    "# Load and edit bad plot ids if needed\n",
    "verified_lu_change = np.load(\"bad_plot_ids.npy\")\n",
    "len(verified_lu_change)\n",
    "\n",
    "to_add = [136318379, 136318436, 136410758, 136434844, 138900789,\n",
    "               138900891, 138948277, 139027556, 139027610, 139048283,\n",
    "              136434420, 136446328,136446323, 139177883, 135724924,\n",
    "               139025378, 139179668, 138948292, 135224801, 135191144,\n",
    "               139070828, 136456502, 139070835, 139070836, 139178557]\n",
    "to_add = [x for x in to_add if x not in verified_lu_change]\n",
    "verified_lu_change = np.concatenate([verified_lu_change, \n",
    "                     np.array(to_add).flatten()])\n",
    "\n",
    "to_remove = [139189689, 139189690, 139320349]\n",
    "\n",
    "verified_lu_change = [x for x in verified_lu_change if x not in to_remove]\n",
    "np.save(\"bad_plot_ids.npy\", np.array(verified_lu_change))\n",
    "print(len(verified_lu_change))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For either train or test data, loop through each plot and determine whether there is\n",
    "# labelled Y data for it -- returning one dataframe for the entire data set\n",
    "\n",
    "cols_to_keep = ['PLOT_ID', 'SAMPLE_ID', 'LON', 'LAT', 'FLAGGED', 'ANALYSES', 'USER_ID',\n",
    "       'COLLECTION_TIME', 'ANALYSIS_DURATION', 'TREE']\n",
    "csvs = [x for x in sorted(os.listdir(csv_path)) if '.csv' in x]\n",
    "\n",
    "dfs = []\n",
    "for i in csvs:\n",
    "    print(i)\n",
    "    df = pd.read_csv(csv_path + i, encoding = \"ISO-8859-1\")\n",
    "    df.columns = [x.upper() for x in df.columns]\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column not in cols_to_keep:\n",
    "            df = df.drop(column, axis = 1)\n",
    "    df['country'] = i.split(\".\")[0]\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index = True, sort = True)\n",
    "df = df[~pd.isna(df['TREE'])]\n",
    "\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "plot_ids_loaded = plot_ids\n",
    "\n",
    "print(f\"There are {len(plot_ids)} plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int16(array: np.array) -> np.array:\n",
    "    '''Converts a float32 array to int16, reducing storage costs by three-fold'''\n",
    "    assert np.min(array) >= 0, np.min(array)\n",
    "    assert np.max(array) <= 1, np.max(array)\n",
    "    \n",
    "    array = np.clip(array, 0, 1)\n",
    "    array = np.trunc(array * 65535)\n",
    "    assert np.min(array >= 0)\n",
    "    assert np.max(array <= 65535)\n",
    "    \n",
    "    return array.astype(np.uint16)\n",
    "\n",
    "def process_dem(dem):\n",
    "    dem =  median_filter(dem, size = 5)\n",
    "    dem = calcSlope(dem.reshape((1, 32+2, 32+2)),\n",
    "                      np.full((32+2, 32+2), 10),\n",
    "                      np.full((32+2, 32+2), 10), \n",
    "                      zScale = 1, minSlope = 0.02)\n",
    "    dem = dem / 90\n",
    "    dem = dem.reshape((32+2, 32+2, 1))\n",
    "    dem = dem[1:-1, 1:-1]\n",
    "    dem = median_filter(dem, 5)[4:-4, 4:-4]\n",
    "    return dem\n",
    "\n",
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81aef8f88f3a4b57b791605213a0c246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15510), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 13369 plots\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2b770d885a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                               \u001b[0;36m139187043\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                              139187133, 139187134]]\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_ids_to_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_ids_to_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FOR THE TIME BEING!\n",
    "from skimage.transform import resize\n",
    "\n",
    "%run ../src/preprocessing/indices.py\n",
    "\n",
    "def to_float32(array: np.array) -> np.array:\n",
    "    \"\"\"Converts an int_x array to float32\"\"\"\n",
    "    if not isinstance(array.flat[0], np.floating):\n",
    "        assert np.max(array) > 1\n",
    "        array = np.float32(array) / 65535.\n",
    "    assert np.max(array) <= 1\n",
    "    assert array.dtype == np.float32\n",
    "    return array\n",
    "\n",
    "count = 0\n",
    "dataframe = pd.DataFrame({'plot_id': [''], 'lat': [0.325], 'long': [0.325],\n",
    "                          'y': [0]})\n",
    "\n",
    "# Identify shape of data to load\n",
    "plot_ids_to_load = []\n",
    "for i in tnrange(len(plot_ids)):\n",
    "    s1_i = f'{s1_path}{str(plot_ids[i])}.npy'\n",
    "    s2_i = f'{s2_path}{str(plot_ids[i])}.hkl'\n",
    "    dem_i = f'{dem_path}{str(plot_ids[i])}.npy'\n",
    "    s1_new_i = f'../data/{source}-s1/{str(plot_ids[i])}.npy'\n",
    "    s1_exists = (os.path.exists(s1_i) or os.path.exists(s1_new_i))    \n",
    "    \n",
    "    if os.path.isfile(s2_i) and s1_exists:\n",
    "        if plot_ids[i] not in verified_lu_change:\n",
    "            plot_ids_to_load.append(plot_ids[i])\n",
    "\n",
    "print(f\"There are {len(plot_ids_to_load)} plots\")\n",
    "plot_ids_to_load = [x for x in plot_ids_to_load if x not in  [139077414,\n",
    "                                                              139187051,\n",
    "                                                              139187043,\n",
    "                                                             139187133, 139187134]]\n",
    "data_x = np.zeros((len(plot_ids_to_load), 12, 24, 24, 14)).astype(np.uint16)\n",
    "data_y = np.zeros((len(plot_ids_to_load), 14, 14))\n",
    "            \n",
    "    \n",
    "\n",
    "# Iterate over each plot\n",
    "to_remove = []\n",
    "#139187043\n",
    "for i in tnrange(len(plot_ids_to_load)):\n",
    "    s1_i = f'{s1_path}{str(plot_ids_to_load[i])}.npy'\n",
    "    s2_i = f'{s2_path}{str(plot_ids_to_load[i])}.hkl'\n",
    "    dem_i = f'{dem_path}{str(plot_ids_to_load[i])}.npy'\n",
    "\n",
    "    x = to_float32(hkl.load(s2_i))\n",
    "    if os.path.exists(s1_i):\n",
    "        s1 = np.load(s1_i)\n",
    "    else:\n",
    "        s1 = np.load(f'../data/{source}-s1/{str(plot_ids_to_load[i])}.npy')\n",
    "    s1 = np.reshape(s1, (12, 12, 2, 12, 2, 2))\n",
    "    s1 = np.mean(s1, axis = (2, 4))\n",
    "    s1 = resize(s1, (12, 24, 24, 2), order = 0)\n",
    "    \n",
    "    dem = np.load(dem_i)\n",
    "    dem = process_dem(dem)\n",
    "    dem = np.tile(dem.reshape((1, 24, 24)), (x.shape[0], 1, 1))\n",
    "    x[..., 10] = dem\n",
    "    x = np.concatenate([x, s1], axis = -1)\n",
    "    #median = np.median(x, axis = 0)\n",
    "    #x = np.concatenate([x, median[np.newaxis]], axis = 0)\n",
    "    count += 1\n",
    "    y = reconstruct_images(plot_ids_to_load[i])\n",
    "    long = np.mean(df[df['PLOT_ID'] == plot_ids_to_load[i]]['LON'])\n",
    "    lat = np.mean(df[df['PLOT_ID'] == plot_ids_to_load[i]]['LAT'])\n",
    "    dataframe = dataframe.append({'plot_id': str(plot_ids_to_load[i]),\n",
    "                                  'lat': lat, 'long': long,\n",
    "                                 'y': np.sum(np.array(y))}, \n",
    "                                 ignore_index = True)\n",
    "    dataframe.append([plot_ids_to_load[i], lat, long])\n",
    "    # The indices can range from -1 to 1, clip to 0-1\n",
    "    #x[..., 11:15] = np.clip(x[..., 11:15], -1, 1)\n",
    "    #x[..., 11:15] = (x[..., 11:15] + 1) / 2\n",
    "    if np.sum(np.isnan(x)) > 0:\n",
    "        to_remove.append(i)\n",
    "    else:\n",
    "        x = np.clip(x, 0, 1)\n",
    "        x = to_int16(x)\n",
    "        data_x[i] = x\n",
    "        try:\n",
    "            data_y[i] = np.array(y)\n",
    "        except:\n",
    "            to_remove.append(i)\n",
    "            \n",
    "# Remove any data samples that had missing values\n",
    "if len(to_remove) > 0:\n",
    "    print(f\"Removing {to_remove}\")\n",
    "    data_x = np.delete(data_x, to_remove, 0)\n",
    "    data_y = np.delete(data_y, to_remove, 0)\n",
    "            \n",
    "print(f\"Finished loading: {data_x.shape} of {data_x.dtype} type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "dataframe = dataframe.drop(0, 0)\n",
    "dataframe.reset_index(inplace = True, drop = True)\n",
    "if len(to_remove) > 0:\n",
    "    dataframe = dataframe.drop(to_remove, 0)\n",
    "    dataframe.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(f\"Writing {source} data\")\n",
    "hkl.dump(data_x, f\"../tile_data/{source}/{source}_x.hkl\", mode='w', compression='gzip')\n",
    "hkl.dump(data_y, f\"../tile_data/{source}/{source}_y.hkl\", mode='w', compression='gzip')\n",
    "dataframe.to_csv(f\"../tile_data/{source}/{source}_plot_ids.csv\", index = False)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
