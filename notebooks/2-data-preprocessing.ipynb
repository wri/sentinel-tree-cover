{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, preprocess, and save train and test data\n",
    "\n",
    "This notebook preprocesses and collates the training and testing data for model creation.\n",
    "\n",
    "# John Brandt\n",
    "# July 11, 2021\n",
    "\n",
    "- Fuse Sentinel 1/2 data\n",
    "- Reconstruct 2D-array from CEO output CSV by plot\n",
    "- Match sentinel data to CEO labels\n",
    "- Stack data_x, data_y, length\n",
    "- Save arrays for data_x, data_y, length\n",
    "\n",
    "\n",
    "# Package imports and source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from scipy.ndimage import median_filter\n",
    "import hickle as hkl\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "%run ../src/preprocessing/slope.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_images(plot_id):\n",
    "    '''Takes a plot ID and subsets the input pd.DataFrame to that plot ID\n",
    "       returns a (14, 14) array-like list with binary labels\n",
    "       \n",
    "        Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    rows = []\n",
    "    lats = reversed(sorted(subs['LAT'].unique()))\n",
    "    for i, val in enumerate(lats):\n",
    "        subs_lat = subs[subs['LAT'] == val]\n",
    "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
    "        rows.append(list(subs_lat['TREE']))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'test'\n",
    "sentinel_1 = True\n",
    "s2_path = \"../data/{}-s2/\".format(source)\n",
    "s1_path = \"../data/{}-s1/\".format(source)\n",
    "csv_path = \"../data/{}-csv/\".format(source)\n",
    "output_path = \"../data/{}-processed/\".format(source)\n",
    "dem_path = \"../data/{}-dem/\".format(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n"
     ]
    }
   ],
   "source": [
    "# Load and edit bad plot ids if needed\n",
    "verified_lu_change = np.load(\"bad_plot_ids.npy\")\n",
    "len(verified_lu_change)\n",
    "\n",
    "to_add = [141238348]\n",
    "to_add = [x for x in to_add if x not in verified_lu_change]\n",
    "verified_lu_change = np.concatenate([verified_lu_change, \n",
    "                     np.array(to_add).flatten()])\n",
    "\n",
    "to_remove = []\n",
    "\n",
    "verified_lu_change = [x for x in verified_lu_change if x not in to_remove]\n",
    "np.save(\"bad_plot_ids.npy\", np.array(verified_lu_change))\n",
    "print(len(verified_lu_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_test_plots =[10048, 10052, 10084, 20026, 20047, 20079, 20091, 100111, 100120, 100191, 100209, 100213, 100216, \n",
    "200101, 139190217, 139270445, 150027, 150051, 150057, 200187, 1500180, 136776649, 136776650,139190100,\n",
    "139190109, 139190113, 139190268, 139190330, 139190396, 139190452, 139190506, 139190534, 139190803,\n",
    "139190811, 139190892, 139190900, 139190903, 139190954, 139191025, 139191125, 139191502, 139191557,139191574,\n",
    "       139252935, 139264527, 139264598, 139270017, 139270025, 139270222, 139270102, 139270307, 139270436, \n",
    "       139270494, 139270542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ceo-oceana_middleast_test-02.csv', 'ceo-tml_asia_testplots-01.csv', 'tml-test-03.csv', 'tml-test-04.csv', 'tml-test-05.csv', 'tml-test-06.csv', 'tml-test-07.csv', 'tml-test-08.csv', 'tml-test-09.csv', 'tml-test-10.csv', 'tml-test-11.csv', 'tml-test-12.csv', 'tml-test-13.csv', 'tml-test-14.csv', 'tml-test-2022-15.csv']\n",
      "ceo-oceana_middleast_test-02.csv 250.0\n",
      "ceo-tml_asia_testplots-01.csv 249.0\n",
      "tml-test-03.csv 115.0\n",
      "tml-test-04.csv 81.0\n",
      "tml-test-05.csv 205.0\n",
      "tml-test-06.csv 161.0\n",
      "tml-test-07.csv 190.0\n",
      "tml-test-08.csv 118.0\n",
      "tml-test-09.csv 179.0\n",
      "tml-test-10.csv 127.0\n",
      "tml-test-11.csv 204.0\n",
      "tml-test-12.csv 213.0\n",
      "tml-test-13.csv 151.0\n",
      "tml-test-14.csv 78.0\n",
      "tml-test-2022-15.csv 209.0\n",
      "2530\n",
      "1505\n",
      "There are 1505 plots\n"
     ]
    }
   ],
   "source": [
    "# For either train or test data, loop through each plot and determine whether there is\n",
    "# labelled Y data for it -- returning one dataframe for the entire data set\n",
    "import re \n",
    "\n",
    "cols_to_keep = ['PLOT_ID', 'SAMPLE_ID', 'LON', 'LAT', 'FLAGGED', 'ANALYSES', 'USER_ID',\n",
    "       'COLLECTION_TIME', 'ANALYSIS_DURATION', 'TREE', 'plotid', 'sampleid']\n",
    "csvs = [x for x in sorted(os.listdir(csv_path)) if \".csv\" in x]\n",
    "#csvs = [x for x in csvs if 'uuid'in x]\n",
    "csvs = [x for x in csvs if \".csv\" in x]\n",
    "#csvs = [x for x in csvs if \"chaco\" in x]\n",
    "#csvs = [x for x in csvs if \"senegal\" not in x]\n",
    "\n",
    "print(csvs)\n",
    "\n",
    "dfs = []\n",
    "for i in csvs:\n",
    "    df = pd.read_csv(csv_path + i, encoding = \"ISO-8859-1\")\n",
    "    print(i, len(df) / 196)\n",
    "    df.columns = [re.sub(r'\\W+', '', x) for x in df.columns]\n",
    "    df.rename(columns={'Ã¯plotid':'plotid'}, inplace=True)\n",
    "    df.columns = [x.upper() for x in df.columns]\n",
    "    df.columns = ['PLOT_ID' if x == 'PLOTID' else x for x in df.columns]\n",
    "    df.columns = ['SAMPLE_ID' if x == 'SAMPLEID' else x for x in df.columns]\n",
    "    df = df.rename(columns={df.columns[0]: 'PLOT_ID'})\n",
    "    #df = df[df['LAT'] > -24]\n",
    "    #df = df[df['LAT'] < 24]\n",
    "    df = df.reset_index()\n",
    "    #print(i, len(df) / 196)\n",
    "    if len(df) > 0:\n",
    "    \n",
    "    # If there are no unique IDs already, go ahead and assign them\n",
    "\n",
    "        if abs(df['PLOT_ID'][0]) == 1:\n",
    "            print(df['PLOT_ID'][0])\n",
    "            print(f\"No unique ID for {i}\")\n",
    "            for index, row in df.iterrows():\n",
    "                row['PLOT_ID'] = abs(row['PLOT_ID'])\n",
    "                df['PLOT_ID'][index] = str(i[-6:-4]).zfill(2) + '00' + str(row['PLOT_ID'])\n",
    "\n",
    "        for column in df.columns:\n",
    "            if column not in cols_to_keep:\n",
    "                df = df.drop(column, axis = 1)\n",
    "\n",
    "        df['country'] = i.split(\".\")[0]\n",
    "        df.to_csv(csv_path + i, index = False)\n",
    "        dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index = True, sort = True)\n",
    "print(len(df) // 196)\n",
    "df = df[~pd.isna(df['TREE'])]\n",
    "print(len(df) // 196)\n",
    "\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "plot_ids_loaded = plot_ids\n",
    "\n",
    "print(f\"There are {len(plot_ids)} plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tml-india-train-plots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int16(array: np.array) -> np.array:\n",
    "    '''Converts a float32 array to int16, reducing storage costs by three-fold'''\n",
    "    assert np.min(array) >= 0, np.min(array)\n",
    "    assert np.max(array) <= 1, np.max(array)\n",
    "    \n",
    "    array = np.clip(array, 0, 1)\n",
    "    array = np.trunc(array * 65535)\n",
    "    assert np.min(array >= 0)\n",
    "    assert np.max(array <= 65535)\n",
    "    \n",
    "    return array.astype(np.uint16)\n",
    "\n",
    "def process_dem(dem):\n",
    "    dem =  median_filter(dem, size = 5)\n",
    "    dem = calcSlope(dem.reshape((1, 32+2, 32+2)),\n",
    "                      np.full((32+2, 32+2), 10),\n",
    "                      np.full((32+2, 32+2), 10), \n",
    "                      zScale = 1, minSlope = 0.02)\n",
    "    dem = dem / 90\n",
    "    dem = dem.reshape((32+2, 32+2, 1))\n",
    "    dem = dem[1:-1, 1:-1]\n",
    "    dem = median_filter(dem, 5)[2:-2, 2:-2]\n",
    "    return dem\n",
    "\n",
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "%run ../src/preprocessing/indices.py\n",
    "\n",
    "def to_float32(array: np.array) -> np.array:\n",
    "    \"\"\"Converts an int_x array to float32\"\"\"\n",
    "    if not isinstance(array.flat[0], np.floating):\n",
    "        assert np.max(array) > 1\n",
    "        array = np.float32(array) / 65535.\n",
    "    assert np.max(array) <= 1\n",
    "    assert array.dtype == np.float32\n",
    "    return array\n",
    "\n",
    "count = 0\n",
    "dataframe = pd.DataFrame({'plot_id': [''], 'lat': [0.325], 'long': [0.325],\n",
    "                          'y': [0]})\n",
    "\n",
    "# Identify shape of data to load\n",
    "plot_ids_to_load = []\n",
    "for i in range(len(plot_ids)):\n",
    "    s1_i = f'{s1_path}{str(plot_ids[i])}.hkl'\n",
    "    s2_i = f'{s2_path}{str(plot_ids[i])}.hkl'\n",
    "    dem_i = f'{dem_path}{str(plot_ids[i])}.npy'\n",
    "    s1_new_i = f'../data/{source}-s1/{str(plot_ids[i])}.npy'\n",
    "    s1_exists = (os.path.exists(s1_i))\n",
    "    \n",
    "    if os.path.isfile(s2_i) and s1_exists:\n",
    "        if plot_ids[i] not in bad_test_plots:#verified_lu_change:\n",
    "            plot_ids_to_load.append(plot_ids[i])\n",
    "\n",
    "print(f\"There are {len(plot_ids_to_load)} plots\")\n",
    "plot_ids_to_load = [x for x in plot_ids_to_load if x not in  [139077414,\n",
    "                                                              139187051,\n",
    "                                                              139187043,\n",
    "                                                             139187133, 139187134]]\n",
    "data_x = np.zeros((len(plot_ids_to_load), 12, 28, 28, 14)).astype(np.uint16)\n",
    "data_y = np.zeros((len(plot_ids_to_load), 14, 14))\n",
    "            \n",
    "# Iterate over each plot\n",
    "to_remove = []\n",
    "\n",
    "for i in range(len(plot_ids_to_load)):\n",
    "    print(plot_ids_to_load[i])\n",
    "    s1_i = f'{s1_path}{str(plot_ids_to_load[i])}.hkl'\n",
    "    s2_i = f'{s2_path}{str(plot_ids_to_load[i])}.hkl'\n",
    "    dem_i = f'{dem_path}{str(plot_ids_to_load[i])}.npy'\n",
    "\n",
    "    x = to_float32(hkl.load(s2_i))\n",
    "    s1 = hkl.load(s1_i)\n",
    "    s1 = np.reshape(s1, (12, 16, 2, 16, 2, 2))\n",
    "    s1 = np.mean(s1, axis = (2, 4))\n",
    "    s1 = resize(s1, (12, 32, 32, 2), order = 1)\n",
    "    s1 = s1[:, 2:-2, 2:-2, :]\n",
    "    \n",
    "    dem = np.load(dem_i)\n",
    "    dem = process_dem(dem)\n",
    "    dem = np.tile(dem.reshape((1, 28, 28)), (x.shape[0], 1, 1))\n",
    "    x[..., 10] = dem\n",
    "    x = np.concatenate([x, s1], axis = -1)\n",
    "\n",
    "    count += 1\n",
    "    y = reconstruct_images(plot_ids_to_load[i])\n",
    "    long = np.mean(df[df['PLOT_ID'] == plot_ids_to_load[i]]['LON'])\n",
    "    lat = np.mean(df[df['PLOT_ID'] == plot_ids_to_load[i]]['LAT'])\n",
    "    dataframe = dataframe.append({'plot_id': str(plot_ids_to_load[i]),\n",
    "                                  'lat': lat, 'long': long,\n",
    "                                 'y': np.sum(np.array(y))}, \n",
    "                                 ignore_index = True)\n",
    "    dataframe.append([plot_ids_to_load[i], lat, long])\n",
    "\n",
    "    if np.sum(np.isnan(x)) > 0:\n",
    "        to_remove.append(i)\n",
    "    else:\n",
    "        x = np.clip(x, 0, 1)\n",
    "        x = to_int16(x)\n",
    "        data_x[i] = x\n",
    "        try:\n",
    "            data_y[i] = np.array(y)\n",
    "        except:\n",
    "            to_remove.append(i)\n",
    "            \n",
    "# Remove any data samples that had missing values\n",
    "if len(to_remove) > 0:\n",
    "    print(f\"Removing {to_remove}\")\n",
    "    data_x = np.delete(data_x, to_remove, 0)\n",
    "    data_y = np.delete(data_y, to_remove, 0)\n",
    "            \n",
    "print(f\"Finished loading: {data_x.shape} of {data_x.dtype} type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "dataframe = dataframe.drop(0, 0)\n",
    "dataframe.reset_index(inplace = True, drop = True)\n",
    "if len(to_remove) > 0:\n",
    "    dataframe = dataframe.drop(to_remove, 0)\n",
    "    dataframe.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(f\"Writing {source} data\")\n",
    "hkl.dump(data_x, f\"../data/{source}/{source}_x.hkl\", mode='w', compression='gzip')\n",
    "hkl.dump(data_y, f\"../data/{source}/{source}_y.hkl\", mode='w', compression='gzip')\n",
    "dataframe.to_csv(f\"../data/{source}/{source}_plot_ids.csv\", index = False)\n",
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
