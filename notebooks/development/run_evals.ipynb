{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495e8d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.keras.layers import Conv2D, Lambda, Dense, Multiply, Add\n",
    "from tensorflow.initializers import glorot_normal, lecun_normal\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "from tensorflow.python.util import deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14910827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/Documents/GitHub/sentinel-tree-cover/src/layers/convgru.py:27: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../../src/layers/zoneout.py\n",
    "%run ../../src/layers/adabound.py\n",
    "%run ../../src/layers/convgru.py\n",
    "%run ../../src/layers/dropblock.py\n",
    "%run ../../src/layers/extra_layers.py\n",
    "%run ../../src/preprocessing/indices.py\n",
    "%run ../../src/preprocessing/slope.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7769d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cse_block(prevlayer, prefix):\n",
    "    '''Channel excitation and spatial squeeze layer. \n",
    "       Calculates the mean of the spatial dimensions and then learns\n",
    "       two dense layers, one with relu, and one with sigmoid, to rerank the\n",
    "       input channels\n",
    "       \n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the cse_block\n",
    "    '''\n",
    "    mean = Lambda(lambda xin: K.mean(xin, axis=[1, 2]))(prevlayer)\n",
    "    lin1 = Dense(K.int_shape(prevlayer)[3] // 2, name=prefix + 'cse_lin1', activation='relu')(mean)\n",
    "    lin2 = Dense(K.int_shape(prevlayer)[3], name=prefix + 'cse_lin2', activation='sigmoid')(lin1)\n",
    "    x = Multiply()([prevlayer, lin2])\n",
    "    return x\n",
    "\n",
    "\n",
    "def sse_block(prevlayer, prefix):\n",
    "    '''Spatial excitation and channel squeeze layer.\n",
    "       Calculates a 1x1 convolution with sigmoid activation to create a \n",
    "       spatial map that is multiplied by the input layer\n",
    "\n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the sse_block\n",
    "    '''\n",
    "    conv = Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "def csse_block(x, prefix):\n",
    "    '''Implementation of Concurrent Spatial and Channel \n",
    "       ‘Squeeze & Excitation’ in Fully Convolutional Networks\n",
    "    \n",
    "        Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): added output of cse and sse block\n",
    "          \n",
    "         References:\n",
    "          https://arxiv.org/abs/1803.02579\n",
    "    '''\n",
    "    #cse = cse_block(x, prefix)\n",
    "    sse = sse_block(x, prefix)\n",
    "    #x = Add(name=prefix + \"_csse_mul\")([cse, sse])\n",
    "\n",
    "    return sse\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        print(\"ZERO PADDING\")\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "    \n",
    "class ReflectionPadding5D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding5D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        print(\"ZERO PADDING\")\n",
    "        return tf.pad(x, [[0,0], [0, 0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3446bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_block(inp, length, size, flt, scope, train, normalize = True):\n",
    "    '''Bidirectional convolutional GRU block with \n",
    "       zoneout and CSSE blocks in each time step\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): (B, T, H, W, C) layer\n",
    "          length (tf.Variable): (B, T) layer denoting number of\n",
    "                                steps per sample\n",
    "          size (int): kernel size of convolution\n",
    "          flt (int): number of convolution filters\n",
    "          scope (str): tensorflow variable scope\n",
    "          train (tf.Bool): flag to differentiate between train/test ops\n",
    "          normalize (bool): whether to compute layer normalization\n",
    "\n",
    "         Returns:\n",
    "          gru (tf.Variable): (B, H, W, flt*2) bi-gru output\n",
    "          steps (tf.Variable): (B, T, H, W, flt*2) output of each step\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        print(f\"GRU input shape {inp.shape}, zoneout: {0.1}\")\n",
    "        \"\"\"\n",
    "        cell_fw = ConvLSTMCell(shape = size, filters = flt,\n",
    "                               kernel = [3, 3], forget_bias=1.0, \n",
    "                               activation=tf.tanh, normalize=True, \n",
    "                               peephole=False, data_format='channels_last', reuse=None)\n",
    "        cell_bw = ConvLSTMCell(shape = size, filters = flt,\n",
    "                               kernel = [3, 3], forget_bias=1.0, \n",
    "                               activation=tf.tanh, normalize=True, \n",
    "                               peephole=False, data_format='channels_last', reuse=None)\n",
    "        \"\"\"\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        zoneout = 0.8\n",
    "        cell_fw = ZoneoutWrapper(\n",
    "           cell_fw, zoneout_drop_prob = zoneout, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = zoneout, is_training = train)\n",
    "        print(inp.shape)\n",
    "        steps, out = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        print(f\"Zoneout: {zoneout}\")\n",
    "        gru = tf.concat(out, axis = -1)\n",
    "        steps = tf.concat(steps, axis = -1)\n",
    "        print(f\"Down block output shape {gru.shape}\")\n",
    "    return gru, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983ff25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_swish_gn(inp, \n",
    "                 is_training, \n",
    "                 kernel_size,\n",
    "                 scope,\n",
    "                 filters, \n",
    "                 keep_rate,\n",
    "                 stride = (1, 1),\n",
    "                 activation = True,\n",
    "                 use_bias = False,\n",
    "                 norm = True,\n",
    "                 dropblock = True,\n",
    "                 csse = True,\n",
    "                 weight_decay = None,\n",
    "                 block_size = 5,\n",
    "                 padding = \"SAME\"):\n",
    "    '''2D convolution, batch renorm, relu block, 3x3 drop block. \n",
    "       Use_bias must be set to False for batch normalization to work. \n",
    "       He normal initialization is used with batch normalization.\n",
    "       RELU is better applied after the batch norm.\n",
    "       DropBlock performs best when applied last, according to original paper.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          kernel_size (int): size of convolution\n",
    "          scope (str): tensorflow variable scope\n",
    "          filters (int): number of filters for convolution\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "          activation (bool): whether to apply RELU\n",
    "          use_bias (str): whether to use bias. Should always be false\n",
    "\n",
    "         Returns:\n",
    "          bn (tf.Variable): output of Conv2D -> Batch Norm -> RELU\n",
    "        \n",
    "         References:\n",
    "          http://papers.nips.cc/paper/8271-dropblock-a-regularization-\n",
    "              method-for-convolutional-networks.pdf\n",
    "          https://arxiv.org/abs/1702.03275\n",
    "          \n",
    "    '''\n",
    "    \n",
    "    bn_flag = \"Group Norm\" if norm else \"\"\n",
    "    activation_flag = \"RELU\" if activation else \"Linear\"\n",
    "    csse_flag = \"CSSE\" if csse else \"No CSSE\"\n",
    "    bias_flag = \"Bias\" if use_bias else \"NoBias\"\n",
    "    drop_flag = \"DropBlock\" if dropblock else \"NoDrop\"\n",
    "        \n",
    "    \n",
    "    print(\"{} {} Conv 2D {} {} {} {} {}\".format(scope, kernel_size,\n",
    "                                                   bn_flag, activation_flag,\n",
    "                                                   csse_flag, bias_flag, drop_flag))\n",
    "    \n",
    "    with tf.variable_scope(scope + \"_conv\"):\n",
    "        conv = Conv2D(filters = filters, kernel_size = (kernel_size, kernel_size),  strides = stride,\n",
    "                      activation = None, padding = 'valid', use_bias = use_bias,\n",
    "                      #kernel_regularizer = weight_decay,\n",
    "                      kernel_initializer = tf.keras.initializers.he_normal())(inp)\n",
    "        #conv = partial_conv(inp, filters, kernel=kernel_size, stride=1, \n",
    "        #                    use_bias=False, padding=padding, scope = scope)\n",
    "    if activation:\n",
    "        conv = tf.nn.swish(conv)\n",
    "    #\n",
    "    if norm:\n",
    "        conv = group_norm(x = conv, scope = scope, G = 8)\n",
    "    if csse:\n",
    "        conv = csse_block(conv, \"csse_\" + scope)\n",
    "    if dropblock: \n",
    "        with tf.variable_scope(scope + \"_drop\"):\n",
    "            drop_block = DropBlock2D(keep_prob=keep_rate, block_size= block_size)\n",
    "            conv = drop_block(conv, is_training)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c69caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 28\n",
    "\n",
    "n_bands = 17\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 13, INPUT_SIZE, INPUT_SIZE, n_bands))\n",
    "length = tf.placeholder_with_default(np.full((1,), 12), shape = (None,))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, INPUT_SIZE - 14, INPUT_SIZE - 14))#, 1))\n",
    "keep_rate = tf.placeholder_with_default(1.0, ()) # For DropBlock\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training') # For BN, DropBlock\n",
    "alpha = tf.placeholder(tf.float32, shape = ()) # For loss scheduling\n",
    "ft_lr = tf.placeholder_with_default(0.001, shape = ()) # For loss scheduling\n",
    "loss_weight = tf.placeholder_with_default(1.0, shape = ())\n",
    "beta_ = tf.placeholder_with_default(0.0, shape = ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51a2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU input shape (?, 12, 28, 28, 17), zoneout: 0.1\n",
      "(?, 12, 28, 28, 17)\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "(3, 3, 33, 32)\n",
      "(3, 3, 33, 32)\n",
      "Zoneout: 0.8\n",
      "Down block output shape (?, 28, 28, 32)\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "ZERO PADDING\n",
      "conv_median 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Median conv: (?, 28, 28, 32)\n",
      "ZERO PADDING\n",
      "conv_concat 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Concat: (?, 28, 28, 32)\n",
      "conv1 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Conv1: (?, 12, 12, 64)\n",
      "conv2 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Encoded (?, 4, 4, 128)\n",
      "ZERO PADDING\n",
      "up2 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "ZERO PADDING\n",
      "up2_out 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "ZERO PADDING\n",
      "up3 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "out 3 Conv 2D Group Norm RELU CSSE NoBias NoDrop\n",
      "The output is (?, 8, 8, 64), with a receptive field of 1\n",
      "The output, sigmoid is (?, 14, 14, 1), with a receptive field of 1\n"
     ]
    }
   ],
   "source": [
    "initial_flt = 32\n",
    "mid_flt = 32 * 2\n",
    "high_flt = 32 * 2 * 2\n",
    "\n",
    "gru_input = inp[:, :12, ...]\n",
    "gru, steps = gru_block(inp = gru_input, length = length,\n",
    "                            size = [28, 28],\n",
    "                            flt = initial_flt // 2,\n",
    "                            scope = 'down_16',\n",
    "                            train = is_training)\n",
    "with tf.variable_scope(\"gru_drop\"):\n",
    "    drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "    gru = drop_block(gru, is_training)\n",
    "    \n",
    "# Median conv\n",
    "median_input = inp[:, -1, ...]\n",
    "median_input = ReflectionPadding2D((1, 1,))(median_input)\n",
    "median_conv = conv_swish_gn(inp = median_input, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_median', filters = initial_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(f\"Median conv: {median_conv.shape}\")\n",
    "\n",
    "concat = tf.concat([gru, median_conv], axis = -1)\n",
    "concat = ReflectionPadding2D((1, 1,))(concat)\n",
    "concat = conv_swish_gn(inp = concat, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_concat', filters = initial_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, padding = \"VALID\")\n",
    "print(f\"Concat: {concat.shape}\")\n",
    "\n",
    "# MaxPool-conv-swish-GroupNorm-csse\n",
    "pool1 = MaxPool2D()(concat)\n",
    "conv1 = conv_swish_gn(inp = pool1, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv1', filters = mid_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(f\"Conv1: {conv1.shape}\")\n",
    "\n",
    "# MaxPool-conv-swish-csse-DropBlock\n",
    "pool2 = MaxPool2D()(conv1)\n",
    "conv2 = conv_swish_gn(inp = pool2, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv2', filters = high_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, block_size = 4, padding = \"VALID\")\n",
    "print(\"Encoded\", conv2.shape)\n",
    "\n",
    "# Decoder 4 - 8, upsample-conv-swish-csse-concat-conv-swish\n",
    "up2 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(conv2)\n",
    "up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2', filters = mid_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "conv1_crop = Cropping2D(2)(conv1)\n",
    "\n",
    "up2 = tf.concat([up2, conv1_crop], -1)\n",
    "up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2_out', filters = mid_flt, \n",
    "                    keep_rate =  keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "# Decoder 8 - 14 upsample-conv-swish-csse-concat-conv-swish\n",
    "up3 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(up2)\n",
    "up3 = ReflectionPadding2D((1, 1,))(up3)\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up3', filters = initial_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "gru_crop = Cropping2D(6)(concat)\n",
    "up3 = tf.concat([up3, gru_crop], -1)\n",
    "\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'out', filters = initial_flt, \n",
    "                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = False, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "init = tf.constant_initializer([-np.log(0.7/0.3)]) # For focal loss\n",
    "print(f\"The output is {up2.shape}, with a receptive field of {1}\")\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1),\n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            bias_initializer = init,\n",
    "           )(up3) # For focal loss\n",
    "print(f\"The output, sigmoid is {fm.shape}, with a receptive field of {1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112eefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import math\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "def calc_mask(seg):\n",
    "\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "    loss_importance = np.array([x for x in range(0, 197, 1)])\n",
    "    loss_importance = loss_importance / 196\n",
    "    loss_importance = np.expm1(loss_importance)\n",
    "    loss_importance[:30] = 0.\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    res[np.logical_and(res < 2, res > 0)] = 0.5\n",
    "    res[np.logical_or(res >= 2, res <= 0)] = 1.\n",
    "    return res\n",
    "\n",
    "def calc_mask_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    bce_batch = np.array([calc_mask(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "    return bce_batch\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight, mask = True, smooth = 0.03):\n",
    "    '''Calculates the weighted binary cross entropy loss between y_true and\n",
    "       y_pred with optional masking and smoothing for regularization\n",
    "       \n",
    "       For smoothing, we want to weight false positives as less important than\n",
    "       false negatives, so we smooth false negatives 2x as much. \n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          weight (float):\n",
    "          mask (arr):\n",
    "          smooth (float):\n",
    "\n",
    "         Returns:\n",
    "          loss (float):\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    y_true = K.clip(y_true, smooth, 1. - smooth)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true,\n",
    "        logit_y_pred,\n",
    "        weight,\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "    #Utility function for calc_dist_map_batch that calculates the loss\n",
    "    #   importance per pixel based on the surface distance function\n",
    "    \n",
    "     #    Parameters:\n",
    "    #      seg (arr):\n",
    "     #     \n",
    "    #     Returns:\n",
    "    #      res (arr):\n",
    "    #\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "\n",
    "    mults = np.ones_like(seg)\n",
    "    ones = np.ones_like(seg)\n",
    "    for x in range(1, res.shape[0] -1 ):\n",
    "        for y in range(1, res.shape[0] - 1):\n",
    "            if seg[x, y] == 1:\n",
    "                l = seg[x - 1, y]\n",
    "                r = seg[x + 1, y]\n",
    "                u = seg[x, y + 1]\n",
    "                d = seg[x, y - 1]\n",
    "                lu = seg[x - 1, y + 1]\n",
    "                ru = seg[x + 1, y + 1]\n",
    "                rd = seg[x + 1, y - 1]\n",
    "                ld = seg[x -1, y - 1]\n",
    "                \n",
    "                sums = (l + r + u + d)\n",
    "                sums2 = (l + r + u + d + lu + ru +rd + ld)\n",
    "                if sums >= 2:\n",
    "                    mults[x, y] = 2\n",
    "                if sums2 <= 1:\n",
    "                    ones[x - 1, y] = 0.5\n",
    "                    ones[x + 1, y] = 0.5\n",
    "                    ones[x, y + 1] = 0.5\n",
    "                    ones[x, y - 1] = 0.5\n",
    "                    ones[x - 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y - 1] = 0.5\n",
    "                    ones[x -1, y - 1] = 0.5\n",
    "\n",
    "    if posmask.any():\n",
    "        \n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "        # When % = 1, 0 -> 1.75\n",
    "        # When % = 100, 0 -> 0\n",
    "        res = np.round(res, 0)\n",
    "        res[np.where(np.isclose(res, -.41421356, rtol = 1e-2))] = -1\n",
    "        res[np.where(res == -1)] = -1 * mults[np.where(res == -1)]\n",
    "        res[np.where(res == 0)] = -1  * mults[np.where(res == 0)]\n",
    "        # When % = 1, 1 -> 0\n",
    "        # When % = 100, 1 -> 1.75\n",
    "        res[np.where(res == 1)] = 1 * ones[np.where(res == 1)]\n",
    "        res[np.where(res == 1)] *= 0.67\n",
    "        #res[np.where(np.isclose(res, 1.41421356, rtol = 1e-2))] = loss_importance[sums]\n",
    "        \n",
    "    res[np.where(res < -3)] = -3\n",
    "    res[np.where(res > 3)] = 3\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "        res *= -1\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "\n",
    "def surface_loss(y_true, y_pred):\n",
    "    '''Calculates the mean surface loss for the input batch\n",
    "       by multiplying the distance map by y_pred\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "        \n",
    "         References:\n",
    "          https://arxiv.org/abs/1812.07032\n",
    "    '''\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    y_true_dist_map = tf.stack(y_true_dist_map, axis = 0)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    loss = tf.reduce_mean(multipled, axis = (1, 2, 3))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_surf(y_true, y_pred, alpha, weight, beta):\n",
    "\n",
    "    bce = weighted_bce_loss(y_true = y_true, \n",
    "                             y_pred = y_pred, \n",
    "                             weight = weight,\n",
    "                             smooth = 0.03)\n",
    "\n",
    "    bce = tf.reduce_mean(bce, axis = (1, 2, 3))\n",
    "    surface = surface_loss(y_true, y_pred)\n",
    "\n",
    "    surface = tf.reduce_mean(surface)\n",
    "\n",
    "\n",
    "    bce = tf.reduce_mean(bce)\n",
    "    bce = (1 - alpha) * bce\n",
    "    surface_portion = alpha * surface\n",
    "    \n",
    "    #result = bce + lovasz\n",
    "    result = bce + surface_portion\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df0e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../src/layers/adabound.py\n",
    "def grad_norm(gradients):\n",
    "        norm = tf.norm(\n",
    "            tf.stack([\n",
    "                tf.norm(grad) for grad in gradients if grad is not None\n",
    "            ])\n",
    "        )\n",
    "        return norm\n",
    "    \n",
    "\n",
    "optimizer = AdaBoundOptimizer(1e-3, ft_lr)\n",
    "train_loss = lovasz_surf(tf.reshape(labels, (-1, INPUT_SIZE - 14, INPUT_SIZE - 14, 1)), \n",
    "                         fm, weight = loss_weight, \n",
    "                         alpha = alpha, beta = beta_)\n",
    "l2_loss = tf.losses.get_regularization_loss()\n",
    "if len(tf.losses.get_regularization_losses()) > 0:\n",
    "    print(\"Adding L2 loss\")\n",
    "    train_loss = train_loss + l2_loss\n",
    "\n",
    "test_loss = lovasz_surf(tf.reshape(labels, (-1, INPUT_SIZE - 14, INPUT_SIZE - 14, 1)),\n",
    "                        fm, weight = loss_weight, \n",
    "                        alpha = alpha, beta = beta_)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = optimizer.minimize(train_loss)   \n",
    "\n",
    "trainable_params = tf.trainable_variables()\n",
    "gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "gradient_norm = grad_norm(gradients)\n",
    "scale = 0.05 / (gradient_norm + 1e-12)\n",
    "e_ws = []\n",
    "for (grad, param) in gradients:\n",
    "    e_w = grad * scale\n",
    "    param.assign_add(e_w)\n",
    "    e_ws.append(e_w)\n",
    "\n",
    "sam_gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "for (param, e_w) in zip(trainable_params, e_ws):\n",
    "    param.assign_sub(e_w)\n",
    "train_step = optimizer.apply_gradients(sam_gradients)\n",
    "\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "saver = tf.train.Saver(max_to_keep = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde50bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../models/small-temporal/model\n"
     ]
    }
   ],
   "source": [
    "path = \"../../models/small-temporal/\"\n",
    "saver.restore(sess, tf.train.latest_checkpoint(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "157a660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(x, min_db):\n",
    "    x = 10 * np.log10(x + 1/65535)\n",
    "    x[x < -min_db] = -min_db\n",
    "    x = x + min_db\n",
    "    x = x / min_db\n",
    "    x = np.clip(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n",
    "\n",
    "\n",
    "def evi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the enhanced vegetation index\n",
    "    2.5 x (08 - 04) / (08 + 6 * 04 - 7.5 * 02 + 1)\n",
    "    '''\n",
    "\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = x[..., 2]\n",
    "    NIR = x[..., 3]\n",
    "    evis = 2.5 * ( (NIR-RED) / (NIR + (6*RED) - (7.5*BLUE) + 1))\n",
    "    evis = np.clip(evis, -1.5, 1.5)\n",
    "    return evis\n",
    "\n",
    "\n",
    "def msavi2(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the modified soil-adjusted vegetation index 2\n",
    "    (2 * NIR + 1 - sqrt((2*NIR + 1)^2 - 8*(NIR-RED)) / 2\n",
    "    '''\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = np.clip(x[..., 2], 0, 1)\n",
    "    NIR = np.clip(x[..., 3], 0, 1)\n",
    "\n",
    "    msavis = (2 * NIR + 1 - np.sqrt( (2*NIR+1)**2 - 8*(NIR-RED) )) / 2\n",
    "    return msavis\n",
    "\n",
    "\n",
    "def bi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    B11 = np.clip(x[..., 8], 0, 1)\n",
    "    B4 = np.clip(x[..., 2], 0, 1)\n",
    "    B8 = np.clip(x[..., 3], 0, 1)\n",
    "    B2 = np.clip(x[..., 0], 0, 1)\n",
    "    bis = ((B11 + B4) - (B8 + B2)) / ((B11 + B4) + (B8 + B2))\n",
    "    return bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "69834433",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_all = [0.006576638437476157, 0.0162050812542916, 0.010040436408026246, 0.013351644159609368, 0.01965362020294499, 0.014229037918669413, 0.015289539940489814, 0.011993591210803388, 0.008239871824216068, 0.006546120393682765, 0.0, 0.0, 0.0, -0.1409399364817101, -0.4973397113668104, -0.09731556326714398, -0.7193834232943873]\n",
    "max_all = [0.2691233691920348, 0.3740291447318227, 0.5171435111009385, 0.6027466239414053, 0.5650263218127718, 0.5747005416952773, 0.5933928435187305, 0.6034943160143434, 0.7472037842374304, 0.7000076295109483, 0.509269855802243, 0.948334642387533, 0.6729257769285485, 0.8177635298774327, 0.35768999002433816, 0.7545951919107605, 0.7602693339366691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0a40352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 12, 28, 28, 13)\n",
      "There are 0 outliers\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import hickle as hkl\n",
    "test_x = hkl.load(\"../../data/test/test_x.hkl\")\n",
    "test_y = hkl.load(\"../../data/test/test_y.hkl\")\n",
    "test_data = pd.read_csv(\"../../data/test/test_plot_ids.csv\")\n",
    "\n",
    "test_x = np.delete(test_x, 11, -1)\n",
    "print(test_x.shape)\n",
    "\n",
    "if not isinstance(test_x.flat[0], np.floating):\n",
    "    assert np.max(test_x) > 1\n",
    "    test_x = test_x / 65535.\n",
    "    \n",
    "test_x[..., -1] = convert_to_db(test_x[..., -1], 22)\n",
    "test_x[..., -2] = convert_to_db(test_x[..., -2], 22)\n",
    "\n",
    "indices = np.empty((test_x.shape[0], 12, 28, 28, 4))\n",
    "indices[..., 0] = evi(test_x)\n",
    "indices[..., 1] = bi(test_x)\n",
    "indices[..., 2] = msavi2(test_x)\n",
    "indices[..., 3] = grndvi(test_x)\n",
    "\n",
    "test_x = np.concatenate([test_x, indices], axis = -1)\n",
    "med = np.median(test_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "test_x = np.concatenate([test_x, med], axis = 1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.min(val) < -1.66]\n",
    "above_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.max(val) > 1.66]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "\n",
    "print(f\"There are {len(outliers)} outliers\")\n",
    "print([x for x in test_data['plot_id'].iloc[outliers]])\n",
    "\n",
    "test_x = np.delete(test_x, outliers, 0)\n",
    "test_y = np.delete(test_y, outliers, 0)\n",
    "test_data = test_data.drop(outliers, 0)\n",
    "test_data = test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "610b9b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data scaling\n"
     ]
    }
   ],
   "source": [
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[..., band] = np.clip(test_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[..., band] - midrange) / (rng / 2)\n",
    "    test_x[..., band] = standardized\n",
    "print(\"Finished data scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "606261bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list):\n",
    "          nrows (int):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(18, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9, cbar = False)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8eee4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 292\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fb742cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7192118226600985\n",
      "[292, 293, 294, 295, 296, 297, 298, 299]\n",
      "292 9.731321416809351 38.750904399999996\n",
      "293 8.6053405928307 38.01012753999999\n",
      "294 -32.16701769948428 28.557814829999995\n",
      "295 -30.77435720949694 26.661426070000008\n",
      "296 -27.72235654952877 29.980106400000004\n",
      "297 -32.34480414948275 18.51288063\n",
      "298 -29.203910269512626 25.50581417\n",
      "299 13.138894969746664 -9.310698178999996\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ids = [x for x in range(len(test_x))]\n",
    "print(start/len(test_ids))\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = test_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    print(i, test_data.iloc[i]['lat'], test_data.iloc[i]['long'])\n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    true = test_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "\n",
    "start = start + 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1040136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[141018567, 141018709]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_data.iloc[[231, 295]]['plot_id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
