{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting lambda and d for the whittaker smoother\n",
    "\n",
    "The goal is to identify the smoothing parameters for the whittaker smoother that best reconstruct bands with manually created time gaps.\n",
    "\n",
    "To do so, we will select the training data samples for which there is no gap larger than 30 days.\n",
    "\n",
    "We will psuedo-generate random gaps in the imagery, apply the whittaker smoother with different lambda, d, and linear vs. median gap filling, and plot the reconstruction error on the imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Identify training data samples that have gaps no larger than 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../src/downloading/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(\"../../data/train-dates\") if '.npy in x']\n",
    "\n",
    "clean_data = []\n",
    "for file in files:\n",
    "    x = np.load('../../data/train-dates/' + file)\n",
    "    if len(x) > 2:\n",
    "        diffs = np.max(np.diff(x))\n",
    "        if diffs < 21:\n",
    "            clean_data.append(file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(clean_data)} files,\"\n",
    "      f\" with {len(clean_data) * 48*48} px having a 20 day gap or less\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_gap = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "dates = []\n",
    "for file in clean_data:\n",
    "    data.append(np.load(\"../../data/train-raw/\" + file))\n",
    "    dates.append(np.load(\"../../data/train-dates/\" + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_72 = np.empty((len(clean_data), 72, 48, 48, 10))\n",
    "missing_72 = np.empty((len(clean_data), 72, 48, 48, 10))\n",
    "indices = np.empty((len(clean_data), 2))\n",
    "\n",
    "for item in range(len(data)):\n",
    "    x, _ = calculate_and_save_best_images(data[item], np.array(dates[item]))\n",
    "    clean_72[item] = x\n",
    "    start = int(len(dates[item]) * 0.2)\n",
    "    #start = random.sample(set(np.arange(2, (int(len(dates[item]) * 0.6)))), 1)[0]\n",
    "    end = start + int(random_gap * len(dates[item]))\n",
    "    indices[item, 0] = dates[item][start]\n",
    "    indices[item, 1] = dates[item][end]  \n",
    "    data[item] = np.delete(data[item], np.arange(start, end), 0)\n",
    "    dates[item] = np.delete(dates[item], np.arange(start, end))    \n",
    "    x, _ = calculate_and_save_best_images(data[item], np.array(dates[item]))\n",
    "    missing_72[item] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"../../data/train-raw/138872337.npy\")\n",
    "dates = np.load(\"../../data/train-dates/138872337.npy\")\n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.scatterplot(dates, x[:, 22, 22, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x, _ = calculate_and_save_best_images(x, dates)\n",
    "#sm = Smoother(lmbd = 800, size = 72, d = 2, nbands = 10, dim = 48)\n",
    "#x = sm.interpolate_array(x)\n",
    "l = sns.scatterplot([x for x in range(0, 360, 5)], x[:, 22, 22, 0])\n",
    "#l.set(ylim = (1800, 8500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 24\n",
    "sns.scatterplot([x for x in range(72)], clean_72[n, :, 22, 22, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot([x for x in range(72)], missing_72[n, :, 22, 22, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot([x for x in range(72)], interpolated_72[n, :, 22, 22, 0])\n",
    "g = g.set(ylim=(np.min(missing_72[n, :, 22, 22, 0]), np.max(missing_72[n, :, 22, 22, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the initial error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.empty((len(clean_72), 48, 48, 10))\n",
    "for sample in range(len(clean_72)):\n",
    "    start, end = indices[sample]\n",
    "    start = int(start // 5)\n",
    "    end = int(end // 5)\n",
    "    clean = clean_72[sample, start:end, ...]\n",
    "    missing = missing_72[sample, start:end, ...]\n",
    "    errors[sample] = np.mean(abs(clean - missing), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear, 50%\n",
    "np.mean(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply whittaker smoother to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import scipy\n",
    "from scipy.sparse.linalg import splu\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "class Smoother:\n",
    "\n",
    "    def __init__(self, lmbd, size, d = 2, nbands = 14, dim = 128):\n",
    "        self.lmbd = lmbd\n",
    "        self.size = size\n",
    "        self.nbands = nbands\n",
    "        self.dim = dim\n",
    "        diagonals = np.zeros(2*d+1)\n",
    "        diagonals[d] = 1.\n",
    "        for i in range(d):\n",
    "            diff = diagonals[:-1] - diagonals[1:]\n",
    "            diagonals = diff\n",
    "        offsets = np.arange(d+1)\n",
    "        shape = (self.size-d, self.size)\n",
    "        E = sparse.eye(self.size, format = 'csc')\n",
    "        D = scipy.sparse.diags(diagonals, offsets, shape)\n",
    "        D = D.conj().T.dot(D) * self.lmbd\n",
    "        coefmat = E + D\n",
    "        self.splu_coef = splu(coefmat)\n",
    "\n",
    "    def smooth(self, y: np.ndarray) -> np.ndarray:\n",
    "        ''' \n",
    "        Apply whittaker smoothing to a 1-dimensional array, returning a 1-dimensional array\n",
    "        '''\n",
    "        return self.splu_coef.solve(np.array(y))\n",
    "\n",
    "\n",
    "    def interpolate_array(self, x) -> np.ndarray:\n",
    "        x = np.reshape(x, (self.size, self.dim*self.dim*self.nbands))\n",
    "        x = self.smooth(x)\n",
    "        x = np.reshape(x, (self.size, self.dim, self.dim, self.nbands))        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbd = 200\n",
    "\n",
    "interpolated_72 = np.copy(missing_72)\n",
    "sm = Smoother(lmbd = lmbd, size = 72, d = 2, nbands = 10, dim = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.empty((len(clean_72), 48, 48, 10))\n",
    "errors_all = np.empty((len(clean_72)))\n",
    "for sample in range(len(clean_72)):\n",
    "    start, end = indices[sample]\n",
    "    start = int(start // 5)\n",
    "    end = int(end // 5)\n",
    "    clean = clean_72[sample, start:end, ...]\n",
    "    out = sm.interpolate_array(missing_72[sample])\n",
    "    interpolated_72[sample] = out\n",
    "    missing = interpolated_72[sample, start:end, ...]\n",
    "    errors[sample] = np.mean(abs(clean - missing), axis = 0)\n",
    "    errors_all[sample] = np.mean(abs(clean_72[sample] - interpolated_72[sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmbd 100, median\n",
    "np.mean(errors, axis = (0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lmbd 200, linear, 20%, d = 1\n",
    "print(np.mean(errors))\n",
    "\n",
    "print(np.mean(errors_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lmbd 200, linear, 20%\n",
    "print(np.mean(errors))\n",
    "\n",
    "print(np.mean(errors_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lmbd 200, linear, 30%\n",
    "print(np.mean(errors))\n",
    "\n",
    "print(np.mean(errors_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lmbd 400, linear, 50%\n",
    "print(np.mean(errors))\n",
    "\n",
    "print(np.mean(errors_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lmbd 200, linear, 50%\n",
    "print(np.mean(errors))\n",
    "\n",
    "print(np.mean(errors_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lmbd 800, linear, 50%\n",
    "print(np.mean(errors))\n",
    "\n",
    "print(np.mean(errors_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lmbd 800, median, 50%\n",
    "print(np.mean(errors))\n",
    "\n",
    "print(np.mean(errors_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
