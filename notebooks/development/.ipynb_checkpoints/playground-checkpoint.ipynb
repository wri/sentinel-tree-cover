{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pyproj import Proj\n",
    "%run ../../src/downloading/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "files = [x for x in os.listdir(\"../../data/train-dates/\") if '.npy' in x]\n",
    "\n",
    "\n",
    "def select_dates(dates):\n",
    "    \"\"\"For imagery that was downloaded prior to capping the number \n",
    "       of monthly images to be 3, it is necessary to enforce that cap\n",
    "       on the training / testing data.\n",
    "       \n",
    "       This function identifies the indices of the imagery to deletet\n",
    "       such that there is a maximum of three images per month.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    before = len(dates)\n",
    "    selected_indices = np.arange(len(dates))\n",
    "    begin = [-60, 0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n",
    "    end = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 390]\n",
    "    indices_to_remove = []\n",
    "    for x, y in zip(begin, end):\n",
    "        indices_month = np.argwhere(np.logical_and(dates >= x, dates < y)).flatten()\n",
    "        if len(indices_month) > 3:\n",
    "            to_delete = np.empty((0,))\n",
    "            if begin == -60:\n",
    "                to_delete = indices_month[:-3]\n",
    "            elif begin == 334:\n",
    "                to_delete = indices_month[3:]\n",
    "            elif len(indices_month) == 4:\n",
    "                to_delete = indices_month[1]\n",
    "            elif len(indices_month) == 5:\n",
    "                to_delete = np.array([indices_month[1],\n",
    "                                      indices_month[3]])\n",
    "            elif len(indices_month) == 6:\n",
    "                to_delete = np.array([indices_month[1],\n",
    "                                      indices_month[3],\n",
    "                                      indices_month[4]])\n",
    "                \n",
    "            to_delete = np.array(to_delete)\n",
    "            if to_delete.size > 0:\n",
    "                indices_to_remove.append(to_delete.flatten())\n",
    "                \n",
    "    if len(indices_to_remove) > 0:\n",
    "        indices_to_remove = np.concatenate(indices_to_remove)\n",
    "        after = before - len(indices_to_remove)\n",
    "        return indices_to_remove\n",
    "    \n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "def subset_contiguous_sunny_dates(dates):\n",
    "    begin = [-60, 0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n",
    "    end = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 390]\n",
    "    n_per_month = []\n",
    "    months_to_adjust = []\n",
    "    indices_to_rm = []\n",
    "    \n",
    "    if len(dates) >= 20:\n",
    "        for x, y in zip(begin, end):\n",
    "            indices_month = np.argwhere(np.logical_and(\n",
    "                dates >= x, dates < y)).flatten()\n",
    "            n_per_month.append(len(indices_month))\n",
    "\n",
    "        for x in range(11):\n",
    "            three_m_sum = np.sum(n_per_month[x:x+3])\n",
    "            if three_m_sum >= 7:\n",
    "                months_to_adjust.append([x, x+1, x+2])\n",
    "\n",
    "        months_to_adjust = [item for sublist in months_to_adjust for item in sublist]\n",
    "        months_to_adjust = list(set(months_to_adjust))\n",
    "\n",
    "\n",
    "        if len(months_to_adjust) > 0:\n",
    "            for month in months_to_adjust:\n",
    "                indices_month = np.argwhere(np.logical_and(\n",
    "                    dates >= begin[month], dates < end[month])).flatten()\n",
    "                if len(indices_month) == 3:\n",
    "                    indices_to_rm.append(indices_month[1])\n",
    "    return indices_to_rm\n",
    "\n",
    "\n",
    "lengths = []\n",
    "lengths_new = []\n",
    "for file in tnrange(10000):\n",
    "    #length = 0\n",
    "    #length_original = 0\n",
    "    dates = np.load(\"../../data/train-dates/\" + files[file])\n",
    "    \n",
    "    init_rm = select_dates(dates)\n",
    "    init_ln = len(dates) - len(init_rm)\n",
    "    lengths.append(init_ln)\n",
    "    \n",
    "    indices_to_rm = subset_contiguous_sunny_dates(dates)\n",
    "    lengths_new.append(init_ln - len(indices_to_rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lengths_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup that takes a bounding box training sample and identifies the name of the quad that it is in\n",
    "# Use GDAL to open the quad and extract the bounding box\n",
    "# For now, compare the data to the sentinel 2 data to see if it matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalwarp -s_srs EPSG:3857 -t_srs EPSG:4326 -r near -of GTiff \\\n",
    "        /Users/john.brandt/Documents/GitHub/restoration-mapper/data/makueni2.tif /Users/john.brandt/Documents/GitHub/restoration-mapper/data/makueni3.tif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gdal.Open('../../data/makueni3.tif')\n",
    "geoTransform = data.GetGeoTransform()\n",
    "minx = geoTransform[0]\n",
    "maxy = geoTransform[3]\n",
    "maxx = minx + geoTransform[1] * data.RasterXSize\n",
    "miny = maxy + geoTransform[5] * data.RasterYSize\n",
    "print(minx, miny, maxx, maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/train-csv/kenya-planet.csv\")\n",
    "for column in ['IMAGERY_TITLE', 'STACKINGPROFILEDG', 'PL_PLOTID', 'IMAGERYYEARDG',\n",
    "              'IMAGERYMONTHPLANET', 'IMAGERYYEARPLANET']:\n",
    "    if column in df.columns:\n",
    "        df = df.drop(column, axis = 1)\n",
    "df = df.dropna(axis = 0)\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_tif(bbox, minx = minx, miny = miny, maxx = maxx, maxy = maxy):\n",
    "    within_x = np.logical_and((bbox[1][0] > minx), (bbox[0][0] < maxx))\n",
    "    within_y = np.logical_and((bbox[0][1] > miny), (bbox[1][1] < maxy))\n",
    "    within = np.logical_and(within_x, within_y)\n",
    "    return within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bbox(plot_id, df):\n",
    "    \"\"\" Calculates the corners of a bounding box from an input\n",
    "        pandas dataframe as output by Collect Earth Online\n",
    "\n",
    "        Parameters:\n",
    "         plot_id (int): plot_id of associated plot\n",
    "         df (pandas.DataFrame): dataframe of associated CEO survey\n",
    "    \n",
    "        Returns:\n",
    "         bounding_box (list): [(min(x), min(y)),\n",
    "                              (max(x), max_y))]\n",
    "    \"\"\"\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    # TOP, LEFT, BOTTOM, RIGHT\n",
    "    # (min x, min y), (max x, max y)\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "\n",
    "def bounding_box(points, expansion = 160):\n",
    "    \"\"\" Calculates the corners of a bounding box with an\n",
    "        input expansion in meters from a given bounding_box\n",
    "        \n",
    "        Subcalls:\n",
    "         calculate_epsg, convertCoords\n",
    "\n",
    "        Parameters:\n",
    "         points (list): output of calc_bbox\n",
    "         expansion (float): number of meters to expand or shrink the\n",
    "                            points edges to be\n",
    "    \n",
    "        Returns:\n",
    "         bl (tuple): x, y of bottom left corner with edges of expansion meters\n",
    "         tr (tuple): x, y of top right corner with edges of expansion meters\n",
    "    \"\"\"\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    inproj = Proj('epsg:4326')\n",
    "    outproj_code = calculate_epsg(bl)\n",
    "    outproj = Proj('epsg:' + str(outproj_code))\n",
    "    \n",
    "    bl_utm =  transform(inproj, outproj, bl[1], bl[0])\n",
    "    tr_utm =  transform(inproj, outproj, tr[1], tr[0])\n",
    "\n",
    "    distance1 = tr_utm[0] - bl_utm[0]\n",
    "    distance2 = tr_utm[1] - bl_utm[1]\n",
    "    expansion1 = (expansion - distance1)/2\n",
    "    expansion2 = (expansion - distance2)/2\n",
    "        \n",
    "    bl_utm = [bl_utm[0] - expansion1, bl_utm[1] - expansion2]\n",
    "    tr_utm = [tr_utm[0] + expansion1, tr_utm[1] + expansion2]\n",
    "    bl =  transform(outproj, inproj, bl_utm[0], bl_utm[1])\n",
    "    tr =  transform(outproj, inproj, tr_utm[0], tr_utm[1])\n",
    "    bl = (bl[1], bl[0])\n",
    "    tr = (tr[1], tr[0])\n",
    "\n",
    "    zone = str(outproj_code)[3:]\n",
    "    zone = zone[1:] if zone[0] == \"0\" else zone\n",
    "    direction = 'N' if tr[1] >= 0 else 'S'\n",
    "    utm_epsg = \"UTM_\" + zone + direction\n",
    "    return (bl, tr)\n",
    "\n",
    "def reconstruct_images(plot_id):\n",
    "    '''Takes a plot ID and subsets the input pd.DataFrame to that plot ID\n",
    "       returns a (14, 14) array-like list with binary labels\n",
    "       \n",
    "        Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    rows = []\n",
    "    lats = reversed(sorted(subs['LAT'].unique()))\n",
    "    for i, val in enumerate(lats):\n",
    "        subs_lat = subs[subs['LAT'] == val]\n",
    "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
    "        rows.append(list(subs_lat['TREE']))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(plot_ids):\n",
    "    bbx = calc_bbox(val, df = df)\n",
    "    bbx = bounding_box(bbx, expansion = 160)\n",
    "    within = within_tif(bbx)\n",
    "    if within:\n",
    "        print(i, val)\n",
    "        ds = gdal.Translate('', '../../data/makueni3.tif', format = 'MEM',\n",
    "                    projWin = [bbx[0][0], bbx[1][1], \n",
    "                               bbx[1][0], bbx[0][1]])\n",
    "        planet = np.array(ds.ReadAsArray())\n",
    "        planet = np.swapaxes(planet, 0, 2)\n",
    "        planet = np.swapaxes(planet, 0, 1)\n",
    "        planet = planet[..., :-1]\n",
    "        planet = np.float32(planet)\n",
    "        planet = resize(planet, (32, 32, planet.shape[-1]), order = 0)\n",
    "        np.save(f\"../../data/test-planet/{str(val)}.npy\", planet)\n",
    "        \n",
    "        bgr = planet[..., :3]\n",
    "        print(np.max(planet))\n",
    "        bgr = bgr / 1600\n",
    "        red = np.copy(bgr[..., 2])\n",
    "        blue = np.copy(bgr[..., 0])\n",
    "        bgr[..., 0] = red\n",
    "        bgr[..., 2] = blue\n",
    "        \n",
    "        \n",
    "        x = np.load(f\"../../data/test-s2/{plot_ids[i]}.npy\")\n",
    "        x = x[..., :3]\n",
    "        blue = np.copy(x[..., 0])\n",
    "        red = np.copy(x[..., 2])\n",
    "        x[..., 0] = red\n",
    "        x[..., 2] = blue\n",
    "\n",
    "        y = reconstruct_images(plot_ids[i])\n",
    "        y = np.array(y)*255\n",
    "        images = [bgr, x[12] * 6, y]\n",
    "        plt.figure(figsize=(15,10))\n",
    "        columns = 3\n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "            plt.imshow(image)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = np.empty((len(plot_ids), 14, 14))\n",
    "data_x = np.empty((len(plot_ids), 24, 16, 16, 17))\n",
    "data_planet = np.empty((len(plot_ids), 32, 32, 4))\n",
    "for i, val in enumerate(plot_ids):\n",
    "    y = reconstruct_images(val)\n",
    "    x = np.load(f\"../../data/train-s2/{str(val)}.npy\")\n",
    "    x_s1 = np.load(f\"../../data/train-s1/{str(val)}.npy\")\n",
    "    x = np.concatenate([x, x_s1], axis = -1)\n",
    "    planet = np.load(f\"../../data/train-planet/{str(val)}.npy\")\n",
    "    data_y[i] = y\n",
    "    data_x[i] = x\n",
    "    data_planet[i] = planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/train_y.npy\", data_y)\n",
    "np.save(\"data/train_x.npy\", data_x)\n",
    "np.save(\"data/train_planet.npy\", data_planet)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
