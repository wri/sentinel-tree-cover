{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import hickle as hkl\n",
    "plt.figure(figsize=(15,13))\n",
    "\n",
    "#1650 / 1161\n",
    "# 1666/1058\n",
    "# 1633, 1082\n",
    "\n",
    "x = str(2174)\n",
    "y = str(638)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "artifact = hkl.load(f\"../../project-monitoring/tiles/{x}/{y}/raw/s2_20/{x}X{y}Y.hkl\")\n",
    "sns.heatmap(artifact[1,..., -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(artifact[..., 3:], axis = (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,13))\n",
    "\n",
    "#1650 / 1161\n",
    "# 1666/1058\n",
    "# 1633, 1082\n",
    "\n",
    "x = str(2174)\n",
    "y = str(639)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "good = hkl.load(f\"../../project-monitoring/tiles/{x}/{y}/raw/s2_10/{x}X{y}Y.hkl\")\n",
    "sns.heatmap(good[0,..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "days_per_month = np.array(days_per_month)\n",
    "days_per_month = np.reshape(days_per_month, (6, 2))\n",
    "days_per_month = np.sum(days_per_month, axis = 1)\n",
    "days_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "\n",
    "kernel_size = 3\n",
    "blur = cv.GaussianBlur(artifact,(kernel_size, kernel_size),0)\n",
    "dst = cv.Canny(blur.astype(np.uint8), 140, 200, None, 3)\n",
    "    \n",
    "# Copy edges to the images that will display the results in BGR\n",
    "cdst = cv.cvtColor(dst, cv.COLOR_GRAY2BGR)\n",
    "cdstP = np.copy(cdst)\n",
    "\n",
    "line_img = np.copy(artifact)\n",
    "\n",
    "\n",
    "lines = cv.HoughLinesP(dst, 1, np.pi / 2, 60, None, 120, 20)\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv.line(line_img,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "        \n",
    "lines = cv.HoughLinesP(dst, 1, np.pi, 60, None, 120, 20)\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv.line(line_img,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,13))\n",
    "sns.heatmap(line_img, vmax = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fspecial_gauss(size, sigma):\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g\n",
    "arr = fspecial_gauss(140, 70)\n",
    "def load_mosaic_predictions(out_folder: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads the .npy subtile files in an output folder and mosaics the overlapping predictions\n",
    "    to return a single .npy file of tree cover for the 6x6 km tile\n",
    "    Additionally, applies post-processing threshold rules and implements no-data flag of 255\n",
    "    \"\"\"\n",
    "    x_tiles = [int(x) for x in os.listdir(out_folder) if '.DS' not in x]\n",
    "    max_x = np.max(x_tiles) + 140\n",
    "    for x_tile in x_tiles:\n",
    "        y_tiles = [int(y[:-4]) for y in os.listdir(out_folder + str(x_tile) + \"/\") if '.DS' not in y]\n",
    "        max_y = np.max(y_tiles) + 140\n",
    "    predictions = np.full((max_x, max_y, len(x_tiles) * len(y_tiles)), np.nan, dtype = np.float32)\n",
    "    mults = np.full((max_x, max_y, len(x_tiles) * len(y_tiles)), 0, dtype = np.float32)\n",
    "    i = 0\n",
    "    for x_tile in x_tiles:\n",
    "        y_tiles = [int(y[:-4]) for y in os.listdir(out_folder + str(x_tile) + \"/\") if '.DS' not in y]\n",
    "        for y_tile in y_tiles:\n",
    "            output_file = out_folder + str(x_tile) + \"/\" + str(y_tile) + \".npy\"\n",
    "            if os.path.exists(output_file):\n",
    "                prediction = np.load(output_file)\n",
    "                if np.sum(prediction) > 0:\n",
    "                    prediction = (prediction * 100).T.astype(np.float32)\n",
    "                    predictions[x_tile: x_tile+140, y_tile:y_tile + 140, i] = prediction\n",
    "                    mults[x_tile: x_tile+140, y_tile:y_tile + 140, i] = fspecial_gauss(140, 20)\n",
    "                i += 1\n",
    "    predictions = predictions.astype(np.float32)\n",
    "    mults = mults / np.sum(mults, axis = -1)[..., np.newaxis]\n",
    "    predictions[predictions == 255] = np.nan\n",
    "    predictions = np.nansum(predictions * mults, axis = -1)\n",
    "    predictions[np.isnan(predictions)] = 255.\n",
    "    predictions = predictions.astype(np.uint8)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = load_mosaic_predictions(f\"../project-monitoring/tiles/{x}/{y}/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,13))\n",
    "sns.heatmap(smooth.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O for fix_artifacts\n",
    "# download folder\n",
    "# download list of tiles\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "def download_folder(s3_folder, local_dir, apikey, apisecret, bucket):\n",
    "    \"\"\"\n",
    "    Checks to see if a file/key pair exists locally or on s3 or neither\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    s3 = boto3.resource('s3', aws_access_key_id=apikey,\n",
    "         aws_secret_access_key= apisecret)\n",
    "    bucket = s3.Bucket(bucket)\n",
    "\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        print(obj)\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        bucket.download_file(obj.key, target)\n",
    "        \n",
    "\n",
    "def download_file(s3_file, local_file, apikey, apisecret, bucket):\n",
    "    \"\"\"\n",
    "    Checks to see if a file/key pair exists locally or on s3 or neither\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    s3 = boto3.resource('s3', aws_access_key_id=apikey,\n",
    "         aws_secret_access_key= apisecret)\n",
    "    bucket = s3.Bucket(bucket)\n",
    "\n",
    "    for obj in bucket.objects.filter(Prefix=s3_file):\n",
    "        target = obj.key if local_file is None \\\n",
    "            else os.path.join(local_file, os.path.relpath(obj.key, s3_file))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        \n",
    "        file_name = s3_file.split(\"/\")[-1]\n",
    "        print(f\"Downloading {s3_file} to {local_file + file_name}\")\n",
    "        bucket.download_file(obj.key, target[:-1] + file_name)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#download_file(bucket = \"tof-output\",\n",
    "#               local_file = \"../project-monitoring/\",\n",
    "#               s3_file = \"2020/databases/redo-ghana.csv\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../redo-ghana.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml_path = \"../../config.yaml\"\n",
    "with open(yaml_path, 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY= key['key']\n",
    "    AWSKEY = key['awskey']\n",
    "    AWSSECRET = key['awssecret']\n",
    "print(f\"Successfully loaded key from {yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in data.iterrows():\n",
    "    x = str(int(row['X_tile']))\n",
    "    y = str(int(row['Y_tile']))\n",
    "    local_path = f\"../../project-monitoring/tof-output/{str(x)}/{str(y)}/\"\n",
    "    s3_path = f\"2020/tiles/{str(x)}/{str(y)}/{str(x)}X{str(y)}Y_POST.tif\"\n",
    "    download_file(bucket = \"tof-output\",\n",
    "               local_file = local_path,\n",
    "               apikey = AWSKEY,\n",
    "               apisecret = AWSSECRET,\n",
    "               s3_file = s3_path)\n",
    "    print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yaml_path = \"../../config.yaml\"\n",
    "with open(yaml_path, 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY= key['key']\n",
    "    AWSKEY = key['awskey']\n",
    "    AWSSECRET = key['awssecret']\n",
    "print(f\"Successfully loaded key from {yaml_path}\")\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"reprocess.csv\")\n",
    "data.head(5)\n",
    "\n",
    "bucket = \"tof-output\"\n",
    "s3 = boto3.client('s3', aws_access_key_id=AWSKEY,\n",
    "         aws_secret_access_key= AWSSECRET)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    x = str(int(row['X_tile']))\n",
    "    y = str(int(row['Y_tile']))\n",
    "    local_path = f\"../../project-monitoring/tof-output/{str(x)}/{str(y)}/{str(x)}X{str(y)}Y_v1.tif\"\n",
    "    s3_path = f\"2020/tiles/{str(x)}/{str(y)}/{str(x)}X{str(y)}Y_v1.tif\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        s3.delete_object(Bucket = \"tof-output\", Key = s3_path)\n",
    "    except:\n",
    "        print(f\"No file at: {s3_path}\")\n",
    "        continue\n",
    "    try:\n",
    "        os.remove(local_path)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
