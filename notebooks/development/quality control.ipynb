{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import rasterio\n",
    "import os\n",
    "\n",
    "x = str(115)\n",
    "y = str(1329)\n",
    "\n",
    "data = pd.read_csv(\"../../src/processing_area_june_28.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "%run ../../src/downloading/io.py\n",
    "import glob\n",
    "\n",
    "yaml_path = \"../../config.yaml\"\n",
    "with open(yaml_path, 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY= key['key']\n",
    "    AWSKEY = key['awskey']\n",
    "    AWSSECRET = key['awssecret']\n",
    "print(f\"Successfully loaded key from {yaml_path}\")\n",
    "uploader = FileUploader(awskey = AWSKEY, awssecret = AWSSECRET, overwrite = True)\n",
    "\n",
    "path_to_process = f\"../../project-monitoring/tiles/{str(x)}/{str(y)}/\"\n",
    "s3_path_to_process = f'2020/processed/{str(x)}/{str(y)}/'\n",
    "\n",
    "download_folder(bucket = \"tof-output\",\n",
    "                   apikey = AWSKEY,\n",
    "                   apisecret = AWSSECRET,\n",
    "                   local_dir = path_to_process,\n",
    "                   s3_folder = s3_path_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def fspecial_gauss(size, sigma):\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g\n",
    "\n",
    "def load_mosaic_predictions(out_folder: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Loads the .npy subtile files in an output folder and mosaics the overlapping predictions\n",
    "    to return a single .npy file of tree cover for the 6x6 km tile\n",
    "    Additionally, applies post-processing threshold rules and implements no-data flag of 255\n",
    "    \n",
    "        Parameters:\n",
    "         out_folder (os.Path): location of the prediction .npy files \n",
    "    \n",
    "        Returns:\n",
    "         predictions (np.ndarray): 6 x 6 km tree cover data as a uint8 from 0-100 w/ 255 no-data flag\n",
    "    \"\"\"\n",
    "    test = np.load(out_folder + \"0/0.npy\")\n",
    "    SIZE = test.shape[0]\n",
    "    print(SIZE)\n",
    "    x_tiles = [int(x) for x in os.listdir(out_folder) if '.DS' not in x]\n",
    "    max_x = np.max(x_tiles) + SIZE\n",
    "    for x_tile in x_tiles:\n",
    "        y_tiles = [int(y[:-4]) for y in os.listdir(out_folder + str(x_tile) + \"/\") if '.DS' not in y]\n",
    "        max_y = np.max(y_tiles) + SIZE\n",
    "    predictions = np.full((max_x, max_y, len(x_tiles) * len(y_tiles)), np.nan, dtype = np.float32)\n",
    "    mults = np.full((max_x, max_y, len(x_tiles) * len(y_tiles)), 0, dtype = np.float32)\n",
    "    i = 0\n",
    "    for x_tile in x_tiles:\n",
    "        y_tiles = [int(y[:-4]) for y in os.listdir(out_folder + str(x_tile) + \"/\") if '.DS' not in y]\n",
    "        for y_tile in y_tiles:\n",
    "            output_file = out_folder + str(x_tile) + \"/\" + str(y_tile) + \".npy\"\n",
    "            if os.path.exists(output_file):\n",
    "                prediction = np.load(output_file)\n",
    "                if np.sum(prediction) < SIZE*SIZE*255:\n",
    "                    prediction = (prediction * 100).T.astype(np.float32)\n",
    "                    predictions[x_tile: x_tile+SIZE, y_tile:y_tile + SIZE, i] = prediction\n",
    "                    mults[x_tile: x_tile+SIZE, y_tile:y_tile + SIZE, i] = fspecial_gauss(SIZE, 35)\n",
    "                i += 1\n",
    "\n",
    "    predictions = predictions.astype(np.float32)\n",
    "    \n",
    "    predictions_range = np.nanmax(predictions, axis=-1) - np.nanmin(predictions, axis=-1)\n",
    "    mean_certain_pred = np.nanmean(predictions[predictions_range < 50])\n",
    "    mean_uncertain_pred = np.nanmean(predictions[predictions_range > 50])\n",
    "    \n",
    "    overpredict = True if (mean_uncertain_pred - mean_certain_pred) > 0 else False\n",
    "    underpredict = True if not overpredict else False\n",
    "    \n",
    "    if SIZE == 168:\n",
    "        for i in range(predictions.shape[-1]):\n",
    "            if overpredict:\n",
    "                problem_tile = True if np.nanmean(predictions[..., i]) > mean_certain_pred else False\n",
    "            if underpredict:\n",
    "                problem_tile = True if np.nanmean(predictions[..., i]) < mean_certain_pred else False\n",
    "            range_i = np.copy(predictions_range)\n",
    "            range_i[np.isnan(predictions[..., i])] = np.nan\n",
    "            range_i = range_i[~np.isnan(range_i)]\n",
    "            if range_i.shape[0] > 0:\n",
    "                range_i = np.reshape(range_i, (168 // 56, 56, 168 // 56, 56))\n",
    "                range_i = np.mean(range_i, axis = (1, 3))\n",
    "                print(np.max(range_i))\n",
    "                n_outliers = np.sum(range_i > 50)\n",
    "                if n_outliers >= 2 and problem_tile:\n",
    "                    predictions[..., i] = np.nan\n",
    "                    mults[..., i] = 0.\n",
    "    \n",
    "    mults = mults / np.sum(mults, axis = -1)[..., np.newaxis]\n",
    "    predictions[predictions > 100] = np.nan\n",
    "    out = np.copy(predictions)\n",
    "    out = np.sum(np.isnan(out), axis = (2))\n",
    "    n_preds = predictions.shape[-1]\n",
    "\n",
    "\n",
    "    predictions = np.nansum(predictions * mults, axis = -1)\n",
    "    predictions[out == n_preds] = np.nan\n",
    "    predictions[np.isnan(predictions)] = 255.\n",
    "    predictions[predictions <= .25*100] = 0.        \n",
    "    predictions = np.around(predictions / 20, 0) * 20\n",
    "    predictions[predictions > 100] = 255.\n",
    "    predictions = predictions.astype(np.uint8)\n",
    "    \n",
    "    original_preds = np.copy(predictions)\n",
    "    for x_i in range(0, predictions.shape[0] - 3):\n",
    "        for y_i in range(0, predictions.shape[1] - 3):\n",
    "            window = original_preds[x_i:x_i+3, y_i:y_i+3]\n",
    "            if np.max(window) < 35:\n",
    "                sum_under_35 = np.sum(np.logical_and(window > 10, window < 35))\n",
    "                if np.logical_and(sum_under_35 > 6, sum_under_35 < 10):\n",
    "                    window = 0.\n",
    "\n",
    "            # This removes or mitigates some of the \"noisiness\" of individual trees\n",
    "            # Which could have odd shapes depending on where they sit within or between\n",
    "            # Sentinel pixels \n",
    "            if np.max(window) >= 25 and np.argmax(window) == 4:\n",
    "                window_binary = window >= 25\n",
    "                if np.sum(window_binary) < 4:\n",
    "                    if np.sum(window_binary[1]) < 3 and np.sum(window_binary[:, 1]) < 3:\n",
    "                        window[0, :] = 0\n",
    "                        window[2, :] = 0\n",
    "                        window[:, 0] = 0\n",
    "                        window[:, 2] = 0\n",
    "                    \n",
    "    predictions = original_preds \n",
    "\n",
    "    \n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = 51\n",
    "predictions = np.around(predictions / 20) * 20\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = load_mosaic_predictions(f\"../../project-monitoring/tiles/{x}/{y}/processed/\")\n",
    "smooth = smooth.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(smooth.T, vmax = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_bbox(initial_bbx: list, expansion: int = 10) -> list:\n",
    "    \"\"\"Makes a (min_x, min_y, max_x, max_y) bounding box that\n",
    "       is 2 * expansion 300 x 300 meter ESA LULC pixels\n",
    "\n",
    "       Parameters:\n",
    "            initial_bbx (list): [min_x, min_y, max_x, max_y]\n",
    "            expansion (int): 1/2 number of 300m pixels to expand\n",
    "\n",
    "       Returns:\n",
    "            bbx (list): expanded [min_x, min_y, max_x, max_y]\n",
    "    \"\"\"\n",
    "    multiplier = 1/360 # Sentinel-2 pixel size in decimal degrees\n",
    "    bbx = copy.deepcopy(initial_bbx)\n",
    "    bbx[0] -= expansion * multiplier\n",
    "    bbx[1] -= expansion * multiplier\n",
    "    bbx[2] += expansion * multiplier\n",
    "    bbx[3] += expansion * multiplier\n",
    "    return bbx\n",
    "\n",
    "data = data[data['Y_tile'] == int(y)]\n",
    "data = data[data['X_tile'] == int(x)]\n",
    "data = data.reset_index(drop = True)\n",
    "x = str(int(x))\n",
    "y = str(int(y))\n",
    "x = x[:-2] if \".0\" in x else x\n",
    "y = y[:-2] if \".0\" in y else y\n",
    "\n",
    "initial_bbx = [data['X'][0], data['Y'][0], data['X'][0], data['Y'][0]]\n",
    "bbx = make_bbox(initial_bbx, expansion = 300/30)\n",
    "\n",
    "file = write_tif(smooth, bbx, x, y, f\"../../project-monitoring/tiles/{x}/{y}/\")\n",
    "key = f'2020/tiles_nobin/{x}/{y}/{str(x)}X{str(y)}Y_POST.tif'\n",
    "uploader.upload(bucket = 'tof-output', key = key, file = file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEw stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "#data = pd.read_csv(\"reprocess.csv\")\n",
    "#data.head(5)\n",
    "\n",
    "bucket = \"tof-output\"\n",
    "s3 = boto3.client('s3', aws_access_key_id=AWSKEY,\n",
    "         aws_secret_access_key= AWSSECRET)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    x = str(int(row['X_tile']))\n",
    "    y = str(int(row['Y_tile']))\n",
    "    local_path = f\"../../project-monitoring/tof-output/{str(x)}/{str(y)}/{str(x)}X{str(y)}Y_POST.tif\"\n",
    "    s3_path = f\"2020/tiles/{str(x)}/{str(y)}/{str(x)}X{str(y)}Y_POST.tif\"\n",
    "    \n",
    "    print(f\"Deleting {x}/{y}\")\n",
    "    try:\n",
    "        #s3.delete_object(Bucket = \"tof-output\", Key = s3_path)\n",
    "    except:\n",
    "        print(f\"No file at: {s3_path}\")\n",
    "        continue\n",
    "    try:\n",
    "       # os.remove(local_path)\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
