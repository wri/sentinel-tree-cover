{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection: Remote Sensing Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index | Features | Full Name | IDB # | Used Sent Hub Variables |\n",
    "|-|-|-|-|-|\n",
    "| 0 | blue | Band 2 (10m) | n/a |  |\n",
    "| 1 | green | Band 3 (10m) | n/a |  |\n",
    "| 2 | red | Band 4 (10m) | n/a |  |\n",
    "| 3 | nir | Band 8 (10m) | n/a |  |\n",
    "| 4 | red_edge1 | Band 5 (20m) | n/a |  |\n",
    "| 5 | red_edge2 | Band 6 (20m) | n/a |  |\n",
    "| 6 | red_edge3 | Band 7 (20m) | n/a |  |\n",
    "| 7 | narrow_nir | Band 8a? (20m) | n/a |  |\n",
    "| 8 | swir1 | Band 11 (20m) | n/a |  |\n",
    "| 9 | swir2 | Band 12 (20m) | n/a |  |\n",
    "| 10 | ndvi | Normalized Difference NIR/Red Normalized Difference Vegetation Index, Calibrated NDVI - CDVI | #67 | N |\n",
    "| 11 | atsavi | Adjusted transformed soil-adjusted VI | #1 | N |\n",
    "| 12 | arvi | Atmospherically Resistant Vegetation Index | #5 | Y |\n",
    "| 13 | arvi2 | Atmospherically Resistant Vegetation Index 2 | #6 | N |\n",
    "| 14 | bwdrvi | Blue-wide dynamic range vegetation index | #7 | N |\n",
    "| 15 | ccci | Canopy Chlorophyll Content Index | #9 | N |\n",
    "| 16 | chl_green | Chlorophyll Green | #12 | N |\n",
    "| 17 | ci_green | Chlorophyll Index Green | #13 | N |\n",
    "| 18 | ci_rededge | Chlorophyll IndexRedEdge | #14 | N |\n",
    "| 19 | chl_rededge | Chlorophyll Red-Edge | #15 | N |\n",
    "| 20 | cvi | Chlorophyll vegetation index | #16 | N |\n",
    "| 21 | ci | Coloration Index | #17 | N |\n",
    "| 22 | ctvi | Corrected Transformed Vegetation Index | #18 | N |\n",
    "| 23 | gdvi | Difference NIR/Green Green Difference Vegetation Index | #24 | N |\n",
    "| 24 | evi | Enhanced Vegetation Index | #25 | N |\n",
    "| 25 | gemi | Global Environment Monitoring Index | #26 | N (from IDB) |\n",
    "| 26 | gli | Green leaf index | #27 | N |\n",
    "| 27 | gndvi | Green Normalized Difference Vegetation Index | #28 | N |\n",
    "| 28 | gosavi | Green Optimized Soil Adjusted Vegetation Index | #29 | N |\n",
    "| 29 | gsavi | Green Soil Adjusted Vegetation Index | #30 | N (from IDB) |\n",
    "| 30 | gbndvi | Green-Blue NDVI | #31 | N |\n",
    "| 31 | grndvi | Green-Red NDVI | #32 | N |\n",
    "| 32 | hue | Hue | #33 | N |\n",
    "| 33 | ivi | Ideal vegetation index | #34 | Y |\n",
    "| 34 | ipvi | Infrared percentage vegetation index | #35 | N |\n",
    "| 35 | intensity | Intensity | #36 | N  |\n",
    "| 36 | lwci | Leaf Water Content Index | #38 | Y |\n",
    "| 37 | msavi2 | Modified Soil Adjusted Vegetation Index (referred to as msavi) | #46 | N |\n",
    "| 38 | normg | Norm G | #50 | N |\n",
    "| 39 | normnir | Norm NIR | #51 | N |\n",
    "| 40 | normr | Norm R | #52 | N |\n",
    "| 41 | ndmi | Normalized Difference 820/1600 Normalized Difference Moisture Index | #61 | N |\n",
    "| 42 | ngrdi | Normalized Difference Green/Red Normalized green red difference index, Visible Atmospherically Resistant Indices Green (VIgreen) | #62 | N |\n",
    "| 43 | ndvi_ad | Normalized Difference MIR/NIR Normalized Difference Vegetation Index (in case of strong atmospheric disturbances) | #63 | N |\n",
    "| 44 | bndvi | Normalized Difference NIR/Blue Blue-normalized difference vegetation index | #64 | N |\n",
    "| 45 | mndvi | Normalized Difference NIR/MIR Modified Normalized Difference Vegetation Index | #66 | N |\n",
    "| 46 | nbr | Normalized Difference NIR/SWIR Normalized Burn Ratio | #68 | N |\n",
    "| 47 | ri | Normalized Difference Red/Green Redness Index | #69 | N |\n",
    "| 48 | ndvi690_710 | Normalized Difference Vegetation Index 690-710 | #70 | N |\n",
    "| 49 | pndvi | Pan NDVI | #72 | N |\n",
    "| 50 | pvi | Perpendicular Vegetation Index | #73 | Y |\n",
    "| 51 | rbndvi | Red-Blue NDVI | #81 | N |\n",
    "| 52 | rsr | Reduced Simple Ratio | #85 | Y |\n",
    "| 53 | rdi | Simple Ratio MIR/NIR Ratio Drought Index | #110 | N |\n",
    "| 54 | srnir | Simple Ratio NIR/700-715 | #111 | N |\n",
    "| 55 | grvi | Simple Ratio NIR/G Green Ratio Vegetation Index | #112 | N |\n",
    "| 56 | dvi | Simple Ratio NIR/RED Difference Vegetation Index, Vegetation Index Number (VIN) | #113 | N |\n",
    "| 57 | slavi | Specific Leaf Area Vegetation Index | #129 | N |\n",
    "| 58 | gvi | Tasselled Cap - vegetation | #133 | N |\n",
    "| 59 | wet | Tasselled Cap - wetness | #134 | N |\n",
    "| 60 | tsavi | Transformed Soil Adjusted Vegetation Index | #135 | Y |\n",
    "| 61 | tvi | Transformed Vegetation Index | #136 | N |\n",
    "| 62 | vari_rededge | Visible Atmospherically Resistant Indices RedEdge | #138 | N |\n",
    "| 63 | wdvi | Weighted Difference Vegetation Index | #139 | Y |\n",
    "| 64 | bsi | Bare Soil Index | n/a | n/a |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hickle as hkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and trim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = hkl.load('data/train/train_x.hkl')\n",
    "train_y = hkl.load('data/train/train_y.hkl')\n",
    "test_x = hkl.load('data/test/test_x.hkl') \n",
    "test_y = hkl.load('data/test/test_y.hkl') \n",
    "\n",
    "# utilize only yearly median time step \n",
    "train_x = train_x[:, -1,...]\n",
    "test_x = test_x[:, -1, ...]\n",
    "\n",
    "# utilize only bands, removing RS indices and trim pixels to match labels\n",
    "train_x = train_x[:, 5:-5, 5:-5, :10]\n",
    "test_x = test_x[:, 5:-5, 5:-5, :10]\n",
    "\n",
    "train_x.shape, test_x.shape\n",
    "\n",
    "#print the max, min, np.percentile(75) - np.percentile(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RS Indices\n",
    "assumptions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_indices(arr):\n",
    "    \n",
    "    '''\n",
    "    Takes in an array of 10 and 20m sentinel-2 bands as input and \n",
    "    calculates 55 remote sensing indices. Returns indices \n",
    "    as a combined ndarray.\n",
    "    '''\n",
    "    \n",
    "    # define bands\n",
    "    blue = arr[...,0]\n",
    "    green = arr[...,1] \n",
    "    red = arr[...,2]\n",
    "    nir = arr[...,3] \n",
    "    red_edge1 = arr[...,4] \n",
    "    red_edge2 = arr[...,5]\n",
    "    red_edge3 = arr[...,6] \n",
    "    narrow_nir = arr[...,7] \n",
    "    swir1 = arr[...,8]\n",
    "    swir2 = arr[...,9]\n",
    "    \n",
    "    # calculate RS indices\n",
    "    ndvi = (nir-red) / (nir+red)  \n",
    "    \n",
    "    atsavi = 1.22*((nir-1.22*red-0.03) / (1.22*nir+red-1.22*0.03+0.08*(1+1.22**2)))\n",
    "\n",
    "    arvi = (nir-red-0.069*(red-blue)) / (nir+red-0.069*(red-blue)) \n",
    "     \n",
    "    arvi2 = (-0.18+1.17)*ndvi\n",
    "     \n",
    "    bwdrvi = (0.1*nir-blue) / (0.1*nir+blue)\n",
    "    \n",
    "    ccci = ((nir-red_edge1) / (nir+red_edge1)) / ((nir-red_edge1) / (nir+red_edge1)) \n",
    "     \n",
    "    chl_green = (red_edge3/green)**-1 \n",
    "    \n",
    "    ci_green = (nir/green)*-1 \n",
    "    \n",
    "    ci_rededge = (nir/red_edge1)*-1 \n",
    "    \n",
    "    chl_rededge = (red_edge3/red_edge1)**-1 \n",
    "     \n",
    "    cvi = nir*(red/green**2) \n",
    "    \n",
    "    ci = (red-blue) / red \n",
    "    \n",
    "    ctvi = ((ndvi+0.5) / np.abs((ndvi)+0.5))*np.sqrt(np.abs(ndvi+0.5))\n",
    "     \n",
    "    gdvi = nir-green \n",
    "    \n",
    "    evi = 2.5*((nir-red) / ((nir+6*red-7.5*blue)+1)) \n",
    "    \n",
    "    def global_env_mon_index(nir, red):\n",
    "        n = (2*(nir**2-red**2)+1.5*nir+0.5*red) / (nir+red+0.5)\n",
    "        gemi = (n*(1-0.25*n)-((red-0.125) / (1-red))) \n",
    "        return gemi\n",
    "        \n",
    "    gemi = global_env_mon_index(nir, red) \n",
    "    \n",
    "    gli = (2*green-red-blue) / (2*green+red+blue) \n",
    "    \n",
    "    gndvi = (nir-green) / (nir+green) \n",
    "    \n",
    "    gosavi = (nir-green) / (nir+green+0.16) \n",
    "    \n",
    "    gsavi = ((nir-green) / (nir+green+0.5))*(1+0.5) \n",
    "    \n",
    "    gbndvi = (nir-(green+blue)) / (nir+(green+blue)) \n",
    "    \n",
    "    grndvi = (nir-(green+red)) / (nir+(green+red)) \n",
    "    \n",
    "    hue = np.arctan(((2*red-green-blue) / 30.5)*(green-blue)) \n",
    "    \n",
    "    ivi = (nir-0.809) / (0.393*red) \n",
    "    \n",
    "    ipvi = ((nir / nir+red)/2)*(ndvi+1) \n",
    "    \n",
    "    intensity = (1/30.5)*(red+green+blue) \n",
    "    \n",
    "    lwci = np.log(1.0-(nir-0.101)) / (-np.log(1.0-(nir-0.101)))\n",
    "        \n",
    "    msavi2 = (2*nir+1 - np.sqrt(np.abs((2*nir+1)**2-8*(nir-red)))) / 2 \n",
    "        \n",
    "    normg = green / (nir+red+green) \n",
    "    \n",
    "    normnir = nir / (nir+red+green)\n",
    "    \n",
    "    normr = red / (nir+red+green)\n",
    "    \n",
    "    ndmi = (nir-swir1) / (nir+swir1) \n",
    "    \n",
    "    ngrdi = (green-red) / (green+red)\n",
    "    \n",
    "    ndvi_ad = (swir2-nir) / (swir2+nir)  \n",
    "    \n",
    "    bndvi = (nir-blue) / (nir+blue) \n",
    "        \n",
    "    mndvi = (nir-swir2) / (nir+swir2) \n",
    "\n",
    "    nbr = (nir-swir2) / (nir+swir2) \n",
    "    \n",
    "    ri = (red-green) / (red+green) \n",
    "    \n",
    "    ndvi690_710 = (nir-red_edge1) / (nir+red_edge1) \n",
    "    \n",
    "    pndvi = (nir-(green+red+blue)) / (nir+(green+red+blue)) \n",
    "    \n",
    "    pvi = (1 / np.sqrt(0.149**2+1)) * (nir-0.374-0.735) \n",
    "    \n",
    "    rbndvi = (nir-(red+blue)) / (nir+(red+blue)) \n",
    "    \n",
    "    rsr = (nir / red)*0.640-(swir2 / 0.640)-0.259 \n",
    "        \n",
    "    rdi = (swir2 / nir) \n",
    "    \n",
    "    srnir = (nir / red_edge1)\n",
    "    \n",
    "    grvi = (nir / green) \n",
    "    \n",
    "    dvi = (nir / red) \n",
    "    \n",
    "    slavi = (nir / (red_edge1+swir2))\n",
    "        \n",
    "    gvi = (-0.2848*blue-0.2435*green-0.5436*red+0.7243*nir+0.0840*swir1-0.1800*swir2)\n",
    "    \n",
    "    wet = (0.1509*blue+0.1973*green+0.3279*red+0.3406*nir-0.7112*swir1-0.4572*swir2) \n",
    "    \n",
    "    tsavi = (0.421*(nir-0.421*red-0.824)) / (red+0.421*(nir-0.824)+0.114*(1+0.421**2)) \n",
    "    \n",
    "    tvi = np.sqrt(np.abs(ndvi+0.5)) \n",
    "    \n",
    "    vari_rededge = (red_edge1-red) / (red_edge1+red)\n",
    "    \n",
    "    wdvi = (nir-0.752*red) \n",
    "    \n",
    "    bsi = (swir1+red)-(nir+blue) / (swir1+red)+(nir+blue) \n",
    "        \n",
    "    full_list = [ndvi, atsavi, arvi, arvi2, bwdrvi, ccci, chl_green, ci_green, \n",
    "               ci_rededge, chl_rededge, cvi, ci, ctvi, gdvi, evi, gemi, gli, \n",
    "               gndvi, gosavi, gsavi, gbndvi, grndvi, hue, ivi, ipvi, intensity, \n",
    "               lwci, msavi2, normg, normnir, normr, ndmi, ngrdi, ndvi_ad, bndvi, \n",
    "               mndvi, nbr, ri, ndvi690_710, pndvi, pvi, rbndvi, rsr, rdi, srnir, \n",
    "               grvi, dvi, slavi, gvi, wet, tsavi, tvi, vari_rededge, wdvi, bsi]\n",
    "    \n",
    "    gs_5 = [evi, msavi2, ndvi, ndmi, bsi] # RS indices for gridsearch\n",
    "    \n",
    "    rs_indices = np.empty((arr.shape[0], arr.shape[1], arr.shape[2], len(full_list)), dtype=np.float32)\n",
    "    gs_indices = np.empty((arr.shape[0], arr.shape[1], arr.shape[2], len(gs_5)), dtype=np.float32)\n",
    "    \n",
    "    for i, v in enumerate(full_list):\n",
    "        rs_indices[..., i] = v\n",
    "    \n",
    "    for i, v in enumerate(gs_5):\n",
    "        gs_indices[..., i] = v\n",
    "    \n",
    "    return gs_indices, rs_indices\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_indices_train, rs_indices_train = calc_indices(train_x)\n",
    "gs_indices_test, rs_indices_test = calc_indices(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine, scale, reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine RS indices with train/test data\n",
    "train_x_rs = np.empty((5468, 14, 14, 65), dtype=np.float32)\n",
    "test_x_rs = np.empty((1025, 14, 14, 65), dtype=np.float32)\n",
    "\n",
    "train_x_rs[..., :10] = train_x\n",
    "train_x_rs[..., 10:] = rs_indices_train\n",
    "\n",
    "test_x_rs[..., :10] = test_x\n",
    "test_x_rs[..., 10:] = rs_indices_test\n",
    "\n",
    "train_x_rs.shape, test_x_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize train/test data \n",
    "min_all = []\n",
    "max_all = []\n",
    "\n",
    "for band in range(0, train_x_rs.shape[-1]):\n",
    "    \n",
    "    mins = np.percentile(train_x_rs[..., band], 1)\n",
    "    maxs = np.percentile(train_x_rs[..., band], 99)\n",
    "    \n",
    "    if maxs > mins:\n",
    "        \n",
    "        # clip values in each band based on min/max \n",
    "        train_x_rs[..., band] = np.clip(train_x_rs[..., band], mins, maxs)\n",
    "        test_x_rs[..., band] = np.clip(test_x_rs[..., band], mins, maxs)\n",
    "\n",
    "        #calculate standardized data\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized_train = (train_x_rs[..., band] - midrange) / (rng / 2)\n",
    "        standardized_test = (test_x_rs[..., band] - midrange) / (rng / 2)\n",
    "\n",
    "        # update train_x_rs and test_x_rs to standardized data\n",
    "        train_x_rs[..., band] = standardized_train\n",
    "        test_x_rs[..., band] = standardized_test\n",
    "\n",
    "        min_all.append(mins)\n",
    "        max_all.append(maxs)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(f\"The data has been scaled to {np.min(train_x_rs)}, {np.max(train_x_rs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape train/test data\n",
    "train_x = np.reshape(train_x_rs, (train_x_rs.shape[0]*train_x_rs.shape[1]*train_x_rs.shape[2], train_x_rs.shape[-1]))\n",
    "train_y = np.reshape(train_y, (train_y.shape[0]*train_y.shape[1]*train_y.shape[2]))\n",
    "test_x = np.reshape(test_x_rs, (test_x_rs.shape[0]*test_x_rs.shape[1]*test_x_rs.shape[2], test_x_rs.shape[-1]))\n",
    "test_y = np.reshape(test_y, (test_y.shape[0]*test_y.shape[1]*test_y.shape[2]))\n",
    "\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search \n",
    "Use random search over 50 difference combinations to narrow down the set of hyperparameters used in grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rds_params = {'max_depth': list(np.linspace(10, 1000, 10, dtype=int)) + [None],  \n",
    "              'max_features': ['auto',5,10], \n",
    "              'max_leaf_nodes': [5,10,20,None], \n",
    "              'max_samples': [5,10,None], \n",
    "              'min_impurity_decrease': [0.0,0.01,0.05],\n",
    "              'min_samples_leaf': [1,2,3,4], \n",
    "              'min_samples_split': [2,5,10], \n",
    "              'n_estimators': [200,300,400,500,600]} \n",
    "\n",
    "rds = RandomizedSearchCV(estimator=rfr,\n",
    "                        param_distributions=rds_params, \n",
    "                        n_iter=50,\n",
    "                        cv=3, \n",
    "                        n_jobs=-1,\n",
    "                        verbose=10)\n",
    " \n",
    "rds.fit(train_x, train_y)\n",
    "rds_best = rds.best_params_\n",
    "rds_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{'n_estimators': 200,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'max_samples': None,\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_features': 10,\n",
    " 'max_depth': 890}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate and compare with baseline\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    y_pred = model.predict(test_x)\n",
    "    return print(f'MSE: {mean_squared_error(test_y, y_pred)}')\n",
    "\n",
    "evaluate(rds.best_estimator_, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rfr = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "base_rfr.fit(train_x, train_y)\n",
    "evaluate(base_rfr, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ids = np.arange(1, 50)\n",
    "\n",
    "def bootstrap(plot_ids, n = 10000):\n",
    "    \n",
    "    # precision, recall, f1\n",
    "    array = np.empty((3, n))\n",
    "    for sample in range(n):\n",
    "        resample = np.random.sample(plot_ids.shape, reuse = True)\n",
    "        # 1, 5, 4, 1 12\n",
    "        plot_ids = plot_ids[resample]\n",
    "        \n",
    "        p, r, f1 = calculate_metrics(plot_ids)\n",
    "        array[..., sample] = p, r, f1\n",
    "        \n",
    "    \n",
    "    p_lower, r_lower, f1_lower = np.percentile(2.5, array)\n",
    "    p_upper, r_upper, f1_upper = np.percentile(97.5, array)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "Using the results of the Random Search, spot check the combinations that are known to perform well by hyperparameter tuning to a subset of the data (10 Sentinel 2 bands and 5 of the RS indices: evi, msavi2, ndvi, ndmi, bsi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine gs indices with train/test data\n",
    "train_x_gs = np.empty((5468, 14, 14, 15), dtype=np.float32)\n",
    "test_x_gs = np.empty((1025, 14, 14, 15), dtype=np.float32)\n",
    "\n",
    "train_x_gs[..., :10] = train_x\n",
    "train_x_gs[..., 10:] = gs_indices_train\n",
    "\n",
    "test_x_gs[..., :10] = test_x\n",
    "test_x_gs[..., 10:] = gs_indices_test\n",
    "\n",
    "train_x_gs.shape, test_x_gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize train/test data \n",
    "min_all = []\n",
    "max_all = []\n",
    "\n",
    "for band in range(0, train_x_gs.shape[-1]):\n",
    "    \n",
    "    mins = np.percentile(train_x_gs[..., band], 1)\n",
    "    maxs = np.percentile(train_x_gs[..., band], 99)\n",
    "    \n",
    "    if maxs > mins:\n",
    "        \n",
    "        # clip values in each band based on min/max \n",
    "        train_x_gs[..., band] = np.clip(train_x_gs[..., band], mins, maxs)\n",
    "        test_x_gs[..., band] = np.clip(test_x_gs[..., band], mins, maxs)\n",
    "\n",
    "        # calculate standardized data\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized_train = (train_x_gs[..., band] - midrange) / (rng / 2)\n",
    "        standardized_test = (test_x_gs[..., band] - midrange) / (rng / 2)\n",
    "\n",
    "        # update train_x and test_x to standardized data\n",
    "        train_x_gs[..., band] = standardized_train\n",
    "        test_x_gs[..., band] = standardized_test\n",
    "\n",
    "        min_all.append(mins)\n",
    "        max_all.append(maxs)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(f\"The GS data has been scaled to {np.min(train_x_gs)}, {np.max(train_x_gs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape train/test data\n",
    "gs_train_x = np.reshape(train_x_gs, (train_x_gs.shape[0]*train_x_gs.shape[1]*train_x_gs.shape[2], train_x_gs.shape[-1]))\n",
    "gs_train_y = np.reshape(train_y, (train_y.shape[0]*train_y.shape[1]*train_y.shape[2]))\n",
    "gs_test_x = np.reshape(test_x_gs, (test_x_gs.shape[0]*test_x_gs.shape[1]*test_x_gs.shape[2], test_x_gs.shape[-1]))\n",
    "gs_test_y = np.reshape(test_y, (test_y.shape[0]*test_y.shape[1]*test_y.shape[2]))\n",
    "\n",
    "gs_train_x.shape, gs_train_y.shape, gs_test_x.shape, gs_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_params = {'n_estimators': [200, 250], \n",
    "              'max_depth': list(np.linspace(690, 990, 5, dtype=int)), \n",
    "              'min_samples_leaf': [2], \n",
    "              'min_samples_split': [3,5,7],\n",
    "              'max_features': [10],\n",
    "              'min_impurity_decrease': [0.0]}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(rfr, \n",
    "                  grid_params, \n",
    "                  cv = 4, \n",
    "                  n_jobs = 6,\n",
    "                  verbose = 10)\n",
    "\n",
    "gs.fit(gs_train_x, gs_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_best = gs.best_estimator_\n",
    "rfr_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"r2 train: {rfr_best.score(gs_train_x, gs_train_y)}\")\n",
    "print(f\"r2 test: {rfr_best.score(gs_test_x, gs_test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mse train: {mean_squared_error(gs_train_y, rfr_best.predict(gs_train_x))}\")\n",
    "print(f\"mse test: {mean_squared_error(gs_test_y, rfr_best.predict(gs_test_x))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually test RF versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict = {'model': [],\n",
    "                    'hyperparams':[],\n",
    "                    'r2 train' : [],\n",
    "                    'r2 test' : [],\n",
    "                    'mse train' : [],\n",
    "                    'mse test' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_and_append(model: 'sklearn.model',\n",
    "                     model_name: str,\n",
    "                     train_x: np.ndarray,\n",
    "                     train_y: np.ndarray,\n",
    "                     test_x np.ndarray,\n",
    "                     test_y: np.ndarray) -> 'sklearn.model':\n",
    "    \n",
    "    # append name and hyperparameters\n",
    "    performance_dict['model'].append(model_name)\n",
    "    performance_dict['hyperparams'].append(model.get_params())\n",
    "    \n",
    "    # score (R2)\n",
    "    performance_dict['r2 train'].append(round(model.score(train_x, train_y), 3))\n",
    "    performance_dict['r2 test'].append(round(model.score(test_x, test_y), 3))\n",
    "    \n",
    "    # score (MSE)\n",
    "    performance_dict['mse train'].append(round(mean_squared_error(train_y, model.predict(train_x)),3))\n",
    "    performance_dict['mse test'].append(round(mean_squared_error(test_y, model.predict(test_x)),3))\n",
    "\n",
    "    return f\"{model_name} added to dictionary\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(performance_dict)\n",
    "df.to_csv('model_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_df = pd.read_csv('model_performance.csv')\n",
    "manual_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Feature Importance for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply best model to all RS indices\n",
    "rfr = RandomForestRegressor(bootstrap = True, \n",
    "                          ccp_alpha = 0.0, \n",
    "                          criterion = 'mse',\n",
    "                          max_depth: int = 690, \n",
    "                          max_features = 10, \n",
    "                          max_leaf_nodes = None,\n",
    "                          max_samples = None, \n",
    "                          min_impurity_decrease = 0.0,\n",
    "                          min_impurity_split = None, \n",
    "                          min_samples_leaf = 2,\n",
    "                          min_samples_split = 7, \n",
    "                          min_weight_fraction_leaf: float = 0.0,\n",
    "                          n_estimators = 250, \n",
    "                          n_jobs = 6, \n",
    "                          oob_score = False,\n",
    "                          random_state = 42, \n",
    "                          verbose = 0, \n",
    "                          warm_start = False)\n",
    "\n",
    "\n",
    "rfr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"r2 train: {rfr.score(train_x, train_y)}\") \n",
    "print(f\"r2 test: {rfr.score(test_x, test_y)}\")\n",
    "print(f\"mse train: {mean_squared_error(train_y, rfr.predict(train_x))}\") \n",
    "print(f\"mse test: {mean_squared_error(test_y, rfr.predict(test_x))}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most important features\n",
    "fi = rfr.feature_importances_\n",
    "\n",
    "# Sort indices with argsort and reverse to get them in order of decreasing importance\n",
    "fi_indices = np.argsort(fi)[::-1]\n",
    "print(fi_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['green', 'red', 'ivi', 'intensity', 'red_edge1', 'blue', 'swir2', 'bsi',\n",
    "                 'normnir', 'grndvi', 'ci', 'rsr', 'swir1', 'ci_green', 'arvi', 'chl_green', \n",
    "                 'gndvi', 'red_edge2', 'pndvi', 'gli', 'dvi', 'chl_rededge', 'wet', 'ndmi',\n",
    "                 'grvi', 'vari_rededge', 'tvi', 'bwdrvi', 'arvi2', 'slavi', 'bndvi', 'narrow_nir',\n",
    "                  'red_edge3', 'hue', 'gbndvi', 'rbndvi', 'srnir', 'ci_rededge', 'ndvi690_710']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab top 30 RS indices (including 9 bands)\n",
    "data = {'feature_importance' : fi[fi_indices][:39],\n",
    "        'feature_indices' : fi_indices[:39],\n",
    "        'feature_names' : feature_names}\n",
    "\n",
    "fi_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "sns.barplot(fi_df['feature_importance'], fi_df['feature_names'], palette=\"Greens_d\")\n",
    "\n",
    "plt.title('Most Important RS Indices for Detecting Tree Cover')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('RS Index');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "- Red edge: Lin, S.; Li, J.; Liu, Q.; Li, L.; Zhao, J.; Yu, W. Evaluating the Effectiveness of Using Vegetation Indices Based on Red-Edge Reflectance from Sentinel-2 to Estimate Gross Primary Productivity. Remote Sens. 2019, 11, 1303. https://doi.org/10.3390/rs11111303\n",
    "- Sentinel 2 Remote Sensing Indices: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/indexdb/\n",
    "- Index DataBase: https://www.indexdatabase.de/db/ias.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Assumptions\n",
    "- all indices that required specific nm were skipped (except [ndmi](https://www.indexdatabase.de/db/i-single.php?id=56)).\n",
    "- all indices (~2) requiring band 9 and band 10 were skipped because these were not included in training data. \n",
    "- the values for variables (y, a, b, n, ar) were pulled from the index's basic information section on IDB. If not available, they were pulled from the [sentinel hub playground](https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/indexdb/). Overall, _b_ was interpreted as a variable whereas B was interpreted as Blue (band 2) with the exception of the index tsavi, where sentinel hub defines B = 0.421. \n",
    "- bare soil index (BSI) was not listed in IDB, so [this formula](https://giscrack.com/list-of-spectral-indices-for-sentinel-and-landsat/) was used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
