{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "from sentinelhub import DataSource\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import splu\n",
    "\n",
    "\n",
    "from sentinelhub import CustomUrlParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "%run ../src/slope.py\n",
    "%run ../src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = '../data/test_tiled/'\n",
    "EPSG = CRS.WGS84\n",
    "GRID_SIZE_X = 1\n",
    "GRID_SIZE_Y = 1\n",
    "\n",
    "IMAGE_X = 14*GRID_SIZE_X\n",
    "IMAGE_Y = 14*GRID_SIZE_Y\n",
    "\n",
    "TEST_X = 5\n",
    "TEST_Y = 5\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY = key['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup function to reproject coordinates\n",
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def bounding_box(point, x_offset_max = 140, y_offset_max = 140, expansion = 10):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    tl = point\n",
    "    \n",
    "    if 48 <= tl[0] <= 54:\n",
    "        epsg = 32639 if tl[1] > 0 else 32739\n",
    "    if 42 <= tl[0] <= 48:\n",
    "        epsg = 32638 if tl[1] > 0 else 32738\n",
    "    if 36 <= tl[0] <= 42:\n",
    "        epsg = 32637 if tl[1] > 0 else 32737\n",
    "    if 30 <= tl[0] <= 36:\n",
    "        epsg = 32636 if tl[1] > 0 else 32736\n",
    "    if 24 <= tl[0] <= 30:\n",
    "        epsg = 32635 if tl[1] > 0 else 32735\n",
    "    if 18 <= tl[0] <= 24:\n",
    "        epsg = 32634 if tl[1] > 0 else 32734\n",
    "\n",
    "    tl = convertCoords(tl, 4326, epsg)\n",
    "    \n",
    "    br = (tl[0], tl[1])\n",
    "    tl = ((tl[0] + (x_offset_max)), (tl[1] + (y_offset_max )))\n",
    "    distance1 = tl[0] - br[0]\n",
    "    distance2 = tl[1] - br[1]\n",
    "    #EXPANSION = (expansion - np.mean([distance1, distance2]))/2 # should this be 155 or 160?\n",
    "    \n",
    "    br = [a - expansion for a in br]\n",
    "    tl = [a + expansion for a in tl]\n",
    "    \n",
    "    after = [b - a for a,b in zip(br, tl)]\n",
    "    print(after)\n",
    "    #br = (br[0] + 20, br[1] + 20)\n",
    "    #tl = (tl[0] - 20, tl[1] - 20)\n",
    "    br = convertCoords(br, epsg, 4326)\n",
    "    tl = convertCoords(tl, epsg, 4326)\n",
    "    \n",
    "    min_x = tl[0] # original X offset - 10 meters\n",
    "    max_x = br[0] # original X offset + 10*GRID_SIZE meters\n",
    "    \n",
    "    min_y = tl[1] # original Y offset - 10 meters\n",
    "    max_y = br[1] # original Y offset + 10 meters + 140 meters\n",
    "    # (min_x, min_y), (max_x, max_y)\n",
    "    # (bl, tr)\n",
    "    return [(min_x, min_y), (max_x, max_y)]\n",
    " \n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)\n",
    "\n",
    "def identify_clouds(bbox, epsg = EPSG, time = ('2018-01-01', '2018-12-31')):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=72,\n",
    "            height=72,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.4,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        cloud_steps = [i for i, val in enumerate(means) if val > 0.20]\n",
    "        return cloud_steps, means, cloud_probs\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(bbox, epsg = EPSG):\n",
    "    #bbox = modify_bbox(bbox, expansion = 10)\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=74,\n",
    "                         height=74,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, 74, 74)),\n",
    "                  np.full((74, 74), 10), np.full((74, 74), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((74, 74, 1))\n",
    "    dem_image = dem_image[1:73, 1:73, :]\n",
    "    print(dem_image.shape)\n",
    "    return dem_image #/ np.max(dem_image)\n",
    "\n",
    "\n",
    "    \n",
    "def download_tiles(bbox, epsg = EPSG, time = ('2018-01-01', '2018-12-31')):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WmsRequest(\n",
    "                layer='ALL_BANDS_NDVI',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                width=72,\n",
    "                height=72,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.4,\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        return img_bands, image_request\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "\n",
    "def calculate_and_save_best_images(cloud_steps, img_bands, image_request, means):\n",
    "    begining_length = len(img_bands)\n",
    "    clean_steps = np.array([x for x in range(len(img_bands)) if x not in cloud_steps])\n",
    "    clean_means = np.array([val for x, val in enumerate(means) if x not in cloud_steps])\n",
    "    keep_steps = []\n",
    "    month_steps = []\n",
    "    month_date = []\n",
    "    month_hash = []\n",
    "    for date in image_request.get_dates():\n",
    "        month_steps.append(date.month)\n",
    "        month_date.append(date.day)\n",
    "    \n",
    "    months = {}    \n",
    "    for i in range(1, 13):\n",
    "        month_i = [x for x, val in enumerate(month_steps) if val == i]\n",
    "        month_clean_steps = [x for x in month_i if means[x] < 0.25]\n",
    "        month_clean_dates = [val for x, val in enumerate(month_date) if x in month_clean_steps]\n",
    "        month_first_half = [val for x, val in enumerate(month_clean_steps) if month_clean_dates[x] < 15]\n",
    "        month_second_half = [val for x, val in enumerate(month_clean_steps) if month_clean_dates[x] >= 15]\n",
    "        months[i] = {\"first\": month_first_half, \"last\": month_second_half}\n",
    "            \n",
    "    months_steps = {}  \n",
    "    for i in months.keys():\n",
    "        prior = []\n",
    "        nxt = []\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if i < 12:\n",
    "            nxt = months[i + 1][\"first\"]\n",
    "        if i > 1: \n",
    "            prior = months[i - 1][\"last\"]\n",
    "        if nxt:\n",
    "            if prior:\n",
    "                if not first and second:\n",
    "                    months[i][\"first\"] = prior + second\n",
    "                if not first and not second:\n",
    "                    months[i][\"first\"] = prior + nxt\n",
    "                if not second and first:\n",
    "                    months[i][\"last\"] = first + nxt\n",
    "                if not second and not first:\n",
    "                    months[i][\"last\"] = prior + nxt\n",
    "                    \n",
    "    for i in months.keys():\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if not first and second:\n",
    "            months[i]['first'] = months[i]['last']\n",
    "        if not second and first:\n",
    "            months[i]['last'] = months[i]['first']\n",
    "            \n",
    "    for i in months.keys():\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if not first:\n",
    "            months[i]['first'] = months[i - 1]['last']\n",
    "        if not second:\n",
    "            months[i]['last'] = months[i + 1]['first']\n",
    "            \n",
    "    for i in months.keys():\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if not first:\n",
    "            months[i]['first'] = months[i]['last']\n",
    "        if not second:\n",
    "            months[i]['last'] = months[i]['first']\n",
    "            \n",
    "    for i in months.keys():\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if not first:\n",
    "            print(\"ERROR!!\")\n",
    "        if not second:\n",
    "            print(\"ERROR\")\n",
    "    \n",
    "    for i in months.keys():\n",
    "        month_first = months[i]['first']\n",
    "        if len(month_first) > 1:\n",
    "            month_first = np.mean([val for x, val in enumerate(img_bands) if x in month_first], axis = 0)\n",
    "        else:\n",
    "            month_first = img_bands[month_first[0]]\n",
    "        month_last = months[i]['last']\n",
    "        if len(month_last) > 1:\n",
    "            month_last = np.mean([val for x, val in enumerate(img_bands) if x in month_last], axis = 0)\n",
    "        else:\n",
    "            month_last = img_bands[month_last[0]]\n",
    "        keep_steps.append(month_first)\n",
    "        keep_steps.append(month_last)\n",
    "    npify = np.stack(keep_steps)\n",
    "    return(npify)\n",
    "\n",
    "def calc_best(tiles, cloud_probs, request, offset_x, offset_y):\n",
    "    c_probs = cloud_probs[:, offset_x:offset_x+16, offset_y:offset_y+16]\n",
    "    images = np.stack(tiles)[:, offset_x:offset_x+16, offset_y:offset_y+16]\n",
    "    means = np.mean(c_probs, (1, 2))\n",
    "    cloud_steps = [i for i, val in enumerate(means) if val > 0.20]\n",
    "    best = calculate_and_save_best_images(cloud_steps, images, request, means)\n",
    "    return best\n",
    "\n",
    "def speyediff(N, d, format = 'csc'):\n",
    "    shape = (N-d, N)\n",
    "    diagonals = np.zeros(2*d + 1)\n",
    "    diagonals[d] = 1.\n",
    "    for i in range(d):\n",
    "        diff = diagonals[:-1] - diagonals[1:]\n",
    "        diagonals = diff\n",
    "    offsets = np.arange(d+1)\n",
    "    spmat = sparse.diags(diagonals, offsets, shape, format = format)\n",
    "    return spmat\n",
    "\n",
    "def smooth(y, lmbd, d = 2):\n",
    "    m = len(y)\n",
    "    E = sparse.eye(m, format = 'csc')\n",
    "    D = speyediff(m, d, format = 'csc')\n",
    "    coefmat = E + lmbd * D.conj().T.dot(D)\n",
    "    z = splu(coefmat).solve(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = (13.567941, 38.157342)\n",
    "coords = (coords[1], coords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[720.0, 20.0]\n",
      "[1420.0, 20.0]\n",
      "[2120.0, 20.0]\n",
      "[2820.0, 20.0]\n",
      "[3520.0, 20.0]\n",
      "[4220.0, 20.0]\n",
      "[4920.0, 20.0]\n",
      "[5620.0, 20.0]\n",
      "[6320.0, 20.0]\n",
      "[7020.0, 20.0]\n",
      "[7720.0, 20.0]\n",
      "[8420.0, 20.0]\n",
      "[9120.0, 20.0]\n",
      "[9820.0, 20.0]\n",
      "[10520.0, 20.0]\n"
     ]
    }
   ],
   "source": [
    "def calculate_offset_coords(coords, step, number):\n",
    "    offset_coords = []\n",
    "    for i in range(number):\n",
    "        bbx = bounding_box(coords, (i+1)*step, 0, expansion = 10)\n",
    "        coord_x = bbx[0][0]\n",
    "        coord_y = coords[1]\n",
    "        offset_coords.append((coord_x, coord_y))\n",
    "    return offset_coords\n",
    "\n",
    "coords = [coords] + calculate_offset_coords(coords, 700, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [[x, y] for x, y in zip(coords, [x for x in range(0, 15)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_download(coord):\n",
    "    idx = coord[1]\n",
    "    print(\"Starting: {}\".format(idx))\n",
    "    coord = coord[0]\n",
    "    output_folder = \"../data/test_tiled/{}/\".format(str(idx))\n",
    "    if not os.path.exists(os.path.realpath(output_folder)):\n",
    "        os.mkdir(os.path.realpath(output_folder))\n",
    "    tiled_bbx = bounding_box(coord, y_offset_max = 700, x_offset_max = 700, expansion = 10)\n",
    "    dem_bbx = bounding_box(coord, y_offset_max = 700, x_offset_max = 700, expansion = 20)\n",
    "    cloud_steps, means, cloud_probs = identify_clouds(tiled_bbx)\n",
    "    tiles, request = download_tiles(tiled_bbx)\n",
    "    dem = download_dem(dem_bbx)\n",
    "    tiles = np.stack(tiles)\n",
    "    dem = np.tile(dem.reshape((1, 72, 72, 1)), (tiles.shape[0], 1, 1, 1))\n",
    "    tiles = np.concatenate([tiles, dem], axis = -1)\n",
    "    for x_offset, cval in enumerate([x for x in range(0, 70, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 70, 14)]):\n",
    "            x = calc_best(tiles, cloud_probs, request, cval, rval)\n",
    "            if x.shape[1] != 16:\n",
    "                print(\"Image size error on {}\".format(idx))\n",
    "            x = ndvi(x, image_size = 16)\n",
    "            x = evi(x, image_size = 16)\n",
    "            x = savi(x, image_size = 16)\n",
    "            x = remove_blank_steps(x)\n",
    "            x = bi(x)\n",
    "            x = msavi2(x)\n",
    "            x = si(x)\n",
    "            x[:, :, :, 10] /= 90\n",
    "            for row in range(0, 16):\n",
    "                for column in range(0, 16):\n",
    "                    for band in [x for x in range(0, 17) if x != 10]:\n",
    "                        sm = smooth(x[:, row, column, band], 0.25, d = 2)\n",
    "                        x[:, row, column, band] = sm\n",
    "            np.save(output_folder + str(x_offset*5+y_offset+1), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(38.157342, 13.567941), 0],\n",
       " [(38.163903535850544, 13.567941), 1],\n",
       " [(38.17037298150427, 13.567941), 2],\n",
       " [(38.17684243838185, 13.567941), 3],\n",
       " [(38.18331190639576, 13.567941), 4],\n",
       " [(38.189781385458524, 13.567941), 5],\n",
       " [(38.19625087548263, 13.567941), 6],\n",
       " [(38.2027203763806, 13.567941), 7],\n",
       " [(38.20918988806491, 13.567941), 8],\n",
       " [(38.21565941044809, 13.567941), 9],\n",
       " [(38.22212894344261, 13.567941), 10],\n",
       " [(38.22859848696099, 13.567941), 11],\n",
       " [(38.23506804091571, 13.567941), 12],\n",
       " [(38.24153760521929, 13.567941), 13],\n",
       " [(38.2480071797842, 13.567941), 14]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 1\n",
      "Starting: 2\n",
      "Starting: 0\n",
      "Starting: 3\n",
      "Starting: 4\n",
      "[720.0, 720.0]\n",
      "[720.0, 720.0]\n",
      "[720.0, 720.0]\n",
      "[720.0, 720.0]\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "[740.0, 740.0]\n",
      "[740.0, 740.0]\n",
      "[740.0, 740.0]\n",
      "[740.0, 740.0]\n",
      "(72, 72, 1)\n",
      "(72, 72, 1)\n",
      "(72, 72, 1)\n",
      "(72, 72, 1)\n",
      "(72, 72, 1)\n",
      "Starting: 5\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "(72, 72, 1)\n",
      "Starting: 6\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "Starting: 7\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "(72, 72, 1)\n",
      "Starting: 8\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "Starting: 9\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "(72, 72, 1)\n",
      "(72, 72, 1)\n",
      "(72, 72, 1)\n",
      "Starting: 10\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "(72, 72, 1)\n",
      "Starting: 11\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "(72, 72, 1)\n",
      "Starting: 12\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "Starting: 13\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "(72, 72, 1)\n",
      "(72, 72, 1)\n",
      "Starting: 14\n",
      "[720.0, 720.0]\n",
      "[740.0, 740.0]\n",
      "(72, 72, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d92d9255376c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "threads = 5\n",
    "pool = multiprocessing.Pool(threads)\n",
    "zip(*pool.map(worker_download, coords))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
