{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "\n",
    "DATA_LOCATION = '../data/subplot4.csv'\n",
    "OUTPUT_FOLDER = '../data/correct_dem/'\n",
    "EPSG = CRS.WGS84\n",
    "IMAGE_SIZE = 16\n",
    "FRESH_START = True\n",
    "OFFSET = 0\n",
    "\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "        key = (yaml.safe_load(stream))\n",
    "        API_KEY = key['key']\n",
    "        \n",
    "existing = [int(x[:-4]) for x in os.listdir(OUTPUT_FOLDER) if \".DS\" not in x]\n",
    "len(existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/slope.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup function to reproject coordinates\n",
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def bounding_box(points, expansion = 160):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    \n",
    "    if 48 <= bl[0] <= 54:\n",
    "        epsg = 32639 if bl[1] > 0 else 32739\n",
    "    if 42 <= bl[0] <= 48:\n",
    "        epsg = 32638 if bl[1] > 0 else 32738\n",
    "    if 36 <= bl[0] <= 42:\n",
    "        epsg = 32637 if bl[1] > 0 else 32737\n",
    "    if 30 <= bl[0] <= 36:\n",
    "        epsg = 32636 if bl[1] > 0 else 32736\n",
    "    if 24 <= bl[0] <= 30:\n",
    "        epsg = 32635 if bl[1] > 0 else 32735\n",
    "    if 18 <= bl[0] <= 24:\n",
    "        epsg = 32634 if bl[1] > 0 else 32734\n",
    "\n",
    "    bl = convertCoords(bl, 4326, epsg)\n",
    "    tr = convertCoords(tr, 4326, epsg)\n",
    "    init = [b - a for a,b in zip(bl, tr)]\n",
    "    distance1 = tr[0] - bl[0]\n",
    "    distance2 = tr[1] - bl[1]\n",
    "    print(distance1, distance2)\n",
    "    EXPANSION = (expansion - np.mean([distance1, distance2]))/2 # should this be 155 or 160?\n",
    "    \n",
    "    bl = [a - EXPANSION for a in bl]\n",
    "    tr = [a + EXPANSION for a in tr]\n",
    "    \n",
    "    after = [b - a for a,b in zip(bl, tr)]\n",
    "    print(after)\n",
    "    \n",
    "    if max(init) > 130:\n",
    "        print(\"ERROR: Initial field greater than 130m\")\n",
    "    if min(init) < 120:\n",
    "        print(\"ERROR: Initial field less than 130m\")\n",
    "        \n",
    "    if min(after) < (expansion - 4.5):\n",
    "        print(\"ERROR\")\n",
    "    if max(after) > (expansion + 5):\n",
    "        print(\"ERROR\")\n",
    "    diffs = [b - a for b, a in zip(after, init)]\n",
    "    #if min(diffs) and max(diffs) != EXPANSION*2:\n",
    "    #    print(\"ERROR: Field change more or less than 10m\")\n",
    "    bl = convertCoords(bl, epsg, 4326)\n",
    "    tr = convertCoords(tr, epsg, 4326)\n",
    "    return bl, tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "location = calc_bbox(val)\n",
    "location = bounding_box(location)\n",
    "box = BBox(location, crs = EPSG)\n",
    "\n",
    "image_request = WcsRequest(\n",
    "                layer='ALL_BANDS_NDVI',\n",
    "                bbox=box,\n",
    "                time = ('2018-01-01', '2018-12-31'),\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=1,\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "img_bands = image_request.get_data()\n",
    "img_bands[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bbox(plot_id):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    # TOP, LEFT, BOTTOM, RIGHT\n",
    "    # (min x, min y), (max x, max y)\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "\n",
    "df = pd.read_csv(DATA_LOCATION)\n",
    "df = df.drop('IMAGERY_TITLE', axis = 1)\n",
    "df = df.dropna(axis = 0)\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.62836118706036 127.20209785876796\n",
      "[160.2131316642044, 159.78686833567917]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([33.49924719536184, 10.406891894000186],\n",
       " [33.5007131600946, 10.408334722621772])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounding_box(calc_bbox(plot_ids[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)\n",
    "\n",
    "def identify_clouds(bbox, epsg = EPSG, time = ('2018-01-01', '2018-12-31')):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=IMAGE_SIZE,\n",
    "            height=IMAGE_SIZE,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.33,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        cloud_steps = [i for i, val in enumerate(means) if val > 0.25]\n",
    "        return cloud_steps, means\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(val, epsg = EPSG):\n",
    "    location = calc_bbox(val)\n",
    "    bbox = bounding_box(location, expansion = 180)\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=18,\n",
    "                         height=18,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, 18, 18)),\n",
    "                  np.full((18, 18), 10), np.full((18, 18), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((18, 18, 1))\n",
    "    dem_image = dem_image[1:17, 1:17, :]\n",
    "    print(dem_image.shape)\n",
    "    return dem_image #/ np.max(dem_image)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "def download_tiles(bbox, epsg = EPSG, time = ('2018-01-01', '2018-12-31')):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WmsRequest(\n",
    "                layer='ALL_BANDS_NDVI',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                width=IMAGE_SIZE,\n",
    "                height=IMAGE_SIZE,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.33,\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        return img_bands, image_request\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "\n",
    "def calculate_and_save_best_images(cloud_steps, img_bands, image_request, means):\n",
    "    begining_length = len(img_bands)\n",
    "    clean_steps = np.array([x for x in range(len(img_bands)) if x not in cloud_steps])\n",
    "    clean_means = np.array([val for x, val in enumerate(means) if x not in cloud_steps])\n",
    "    keep_steps = []\n",
    "    month_steps = []\n",
    "    month_date = []\n",
    "    month_hash = []\n",
    "    for date in image_request.get_dates():\n",
    "        month_steps.append(date.month)\n",
    "        month_date.append(date.day)\n",
    "    \n",
    "    months = {}    \n",
    "    for i in range(1, 13):\n",
    "        month_i = [x for x, val in enumerate(month_steps) if val == i]\n",
    "        month_clean_steps = [x for x in month_i if means[x] < 0.25]\n",
    "        month_clean_dates = [val for x, val in enumerate(month_date) if x in month_clean_steps]\n",
    "        month_first_half = [val for x, val in enumerate(month_clean_steps) if month_clean_dates[x] < 15]\n",
    "        month_second_half = [val for x, val in enumerate(month_clean_steps) if month_clean_dates[x] >= 15]\n",
    "        months[i] = {\"first\": month_first_half, \"last\": month_second_half}\n",
    "            \n",
    "    months_steps = {}  \n",
    "    for i in months.keys():\n",
    "        prior = []\n",
    "        nxt = []\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if i < 12:\n",
    "            nxt = months[i + 1][\"first\"]\n",
    "        if i > 1: \n",
    "            prior = months[i - 1][\"last\"]\n",
    "        if nxt:\n",
    "            if prior:\n",
    "                if not first and second:\n",
    "                    months[i][\"first\"] = prior + second\n",
    "                if not first and not second:\n",
    "                    months[i][\"first\"] = prior + nxt\n",
    "                if not second and first:\n",
    "                    months[i][\"last\"] = first + nxt\n",
    "                if not second and not first:\n",
    "                    months[i][\"last\"] = prior + nxt\n",
    "                    \n",
    "    for i in months.keys():\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if not first and second:\n",
    "            months[i]['first'] = months[i]['last']\n",
    "        if not second and first:\n",
    "            months[i]['last'] = months[i]['first']\n",
    "            \n",
    "    for i in months.keys():\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if not first:\n",
    "            months[i]['first'] = months[i - 1]['last']\n",
    "        if not second:\n",
    "            months[i]['last'] = months[i + 1]['first']\n",
    "            \n",
    "    for i in months.keys():\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if not first:\n",
    "            months[i]['first'] = months[i]['last']\n",
    "        if not second:\n",
    "            months[i]['last'] = months[i]['first']\n",
    "            \n",
    "    for i in months.keys():\n",
    "        first = months[i][\"first\"]\n",
    "        second = months[i][\"last\"]\n",
    "        if not first:\n",
    "            print(\"ERROR!!\")\n",
    "        if not second:\n",
    "            print(\"ERROR\")\n",
    "    \n",
    "    for i in months.keys():\n",
    "        month_first = months[i]['first']\n",
    "        if len(month_first) > 1:\n",
    "            month_first = np.mean([val for x, val in enumerate(img_bands) if x in month_first], axis = 0)\n",
    "        else:\n",
    "            month_first = img_bands[month_first[0]]\n",
    "        month_last = months[i]['last']\n",
    "        if len(month_last) > 1:\n",
    "            month_last = np.mean([val for x, val in enumerate(img_bands) if x in month_last], axis = 0)\n",
    "        else:\n",
    "            month_last = img_bands[month_last[0]]\n",
    "        keep_steps.append(month_first)\n",
    "        keep_steps.append(month_last)\n",
    "    npify = np.stack(keep_steps)\n",
    "    return(npify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((24, 18, 18, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 24, 16, 16, 15)\n"
     ]
    }
   ],
   "source": [
    "def get_shifts(arr):\n",
    "    true_m = arr[:, 1:17, 1:17, :]\n",
    "    true_l = arr[:, 0:16, 1:17, :]\n",
    "    true_r = arr[:, 2:18, 1:17, :]\n",
    "    true_u = arr[:, 1:17, 0:16, :]\n",
    "    true_d = arr[:, 1:17, 2:18, :]\n",
    "    true_dr = arr[:, 2:18, 0:16, :]\n",
    "    true_dl = arr[:, 0:16, 0:16, :]\n",
    "    true_ur = arr[:, 2:18, 2:18, :]\n",
    "    true_ul = arr[:, 0:16, 2:18, :]\n",
    "    true_shifts = np.stack([true_m, true_l, true_r, true_u, true_d, true_dr, true_dl, true_ur, true_ul])\n",
    "    return true_shifts\n",
    "\n",
    "print(get_shifts(z).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING DOWNLOAD OF 3 plots from ../data/subplot4.csv to ../data/correct_dem/\n",
      "Downloading 135345939\n",
      "129.17797865363536 126.37733734725043\n",
      "[161.40032065316336, 158.59967934666201]\n",
      "129.17797865363536 126.37733734725043\n",
      "[181.40032065316336, 178.59967934666201]\n",
      "(16, 16, 1)\n",
      "(24, 16, 16, 11)\n",
      "Downloading 135346035\n",
      "129.1306355490815 126.8616373129189\n",
      "[161.1344991180813, 158.86550088203512]\n",
      "129.1306355490815 126.8616373129189\n",
      "[181.1344991180813, 178.86550088203512]\n",
      "(16, 16, 1)\n",
      "(24, 16, 16, 11)\n",
      "Downloading 135346090\n",
      "127.75127294682898 127.44748403108679\n",
      "[160.1518944578711, 159.8481055421289]\n",
      "127.75127294682898 127.44748403108679\n",
      "[180.1518944578711, 179.8481055421289]\n",
      "(16, 16, 1)\n",
      "(24, 16, 16, 11)\n"
     ]
    }
   ],
   "source": [
    "from sentinelhub import DataSource\n",
    "from sentinelhub import CustomUrlParam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "to_download = [x for x in plot_ids if x not in existing]\n",
    "#to_download = [plot_ids[0]]\n",
    "errors = []\n",
    "print(\"STARTING DOWNLOAD OF {} plots from {} to {}\".format(len(to_download), DATA_LOCATION, OUTPUT_FOLDER))\n",
    "for i, val in enumerate(plot_ids):\n",
    "    if val not in existing:\n",
    "        print(\"Downloading {}\".format(val))\n",
    "        location = calc_bbox(val)\n",
    "        location = bounding_box(location)\n",
    "        try:\n",
    "            # Initiate hash tables\n",
    "            cloud, means = identify_clouds(location)\n",
    "            dem = download_dem(val)\n",
    "            dem = np.tile(dem.reshape((1, 16, 16, 1)), (tiles.shape[0], 1, 1, 1))\n",
    "            img, image_request = download_tiles(location)\n",
    "            tiles = calculate_and_save_best_images(cloud, img, image_request, means) # 22, 16, 16, 10\n",
    "            tiles = np.concatenate([tiles, dem], axis = -1)\n",
    "            print(tiles.shape)\n",
    "            np.save(OUTPUT_FOLDER + str(val), tiles)\n",
    "\n",
    "        except Exception as e:\n",
    "        #    print(e)\n",
    "            logging.fatal(e, exc_info=True)\n",
    "            errors.append(img)\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_bands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-062949eb3850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 160\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_bands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_bands' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# 160\n",
    "sns.heatmap(img_bands[0][:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
