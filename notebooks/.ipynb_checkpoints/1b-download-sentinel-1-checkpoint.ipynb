{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process sentinel 1 data\n",
    "\n",
    "## John Brandt\n",
    "## April 1, 2020\n",
    "\n",
    "## Package imports, API import, source scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import scipy.sparse as sparse\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "from collections import Counter\n",
    "from osgeo import ogr, osr\n",
    "from random import shuffle\n",
    "from scipy.sparse.linalg import splu\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType\n",
    "from sentinelhub import CRS, BBox, constants, DataSource, CustomUrlParam\n",
    "from skimage.transform import resize\n",
    "\n",
    "import reverse_geocoder as rg\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "import hickle as hkl\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "        key = (yaml.safe_load(stream))\n",
    "        API_KEY = key['key'] \n",
    "        \n",
    "%matplotlib inline\n",
    "%run ../src/downloading/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('2018-12-15', '2020-01-15')\n",
    "YEAR = 2019\n",
    "IMSIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_s1_layer(coords):\n",
    "    coords = (coords[1], coords[0])\n",
    "    results = rg.search(coords)\n",
    "    admin1 = (results[-1]['admin1'])\n",
    "    admin2 = results[-1]['admin2']\n",
    "    country = results[-1]['cc']\n",
    "    continent_name = pc.country_alpha2_to_continent_code(country)\n",
    "    print(admin1, admin2, country, continent_name)\n",
    "    if continent_name in ['AF', 'OC', 'EU']:\n",
    "        layer = \"SENT\"\n",
    "    if continent_name in ['SA']:\n",
    "        if coords[0] > -7.11:\n",
    "            layer = \"SENT\"\n",
    "        else:\n",
    "            layer = \"SENT_DESC\"\n",
    "    if continent_name in ['AS']:\n",
    "        if coords[0] > 23.3:\n",
    "            layer = \"SENT\"\n",
    "        else:\n",
    "            layer = \"SENT_DESC\"\n",
    "    if continent_name in ['NA']:\n",
    "        layer = \"SENT_DESC\"\n",
    "    return layer\n",
    "\n",
    "\n",
    "def calc_bbox(plot_id, df):\n",
    "    \"\"\" Calculates the corners of a bounding box from an input\n",
    "        pandas dataframe as output by Collect Earth Online\n",
    "\n",
    "        Parameters:\n",
    "         plot_id (int): plot_id of associated plot\n",
    "         df (pandas.DataFrame): dataframe of associated CEO survey\n",
    "    \n",
    "        Returns:\n",
    "         bounding_box (list): [(min(x), min(y)),\n",
    "                              (max(x), max_y))]\n",
    "    \"\"\"\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "\n",
    "def bounding_box(points, expansion = 160):\n",
    "    \"\"\" Calculates the corners of a bounding box with an\n",
    "        input expansion in meters from a given bounding_box\n",
    "        \n",
    "        Subcalls:\n",
    "         calculate_epsg, convertCoords\n",
    "\n",
    "        Parameters:\n",
    "         points (list): output of calc_bbox\n",
    "         expansion (float): number of meters to expand or shrink the\n",
    "                            points edges to be\n",
    "    \n",
    "        Returns:\n",
    "         bl (tuple): x, y of bottom left corner with edges of expansion meters\n",
    "         tr (tuple): x, y of top right corner with edges of expansion meters\n",
    "    \"\"\"\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    inproj = Proj('epsg:4326')\n",
    "    outproj_code = calculate_epsg(bl)\n",
    "    outproj = Proj('epsg:' + str(outproj_code))\n",
    "    \n",
    "    bl_utm =  transform(inproj, outproj, bl[1], bl[0])\n",
    "    tr_utm =  transform(inproj, outproj, tr[1], tr[0])\n",
    "\n",
    "    distance1 = tr_utm[0] - bl_utm[0]\n",
    "    distance2 = tr_utm[1] - bl_utm[1]\n",
    "    expansion1 = (expansion - distance1)/2\n",
    "    expansion2 = (expansion - distance2)/2\n",
    "    \n",
    "    bl_utm = [bl_utm[0] - expansion1, bl_utm[1] - expansion2]\n",
    "    tr_utm = [tr_utm[0] + expansion1, tr_utm[1] + expansion2]\n",
    "    \n",
    "    #assert int((tr_utm[0] - bl_utm[0]) == 320), f'size is {(tr_utm[0] - bl_utm[0])}'\n",
    "    #assert int((tr_utm[1] - bl_utm[1]) == 320), f'size is {(tr_utm[1] - bl_utm[1])}'\n",
    "\n",
    "    \n",
    "    zone = str(outproj_code)[3:]\n",
    "    zone = zone[1:] if zone[0] == \"0\" else zone\n",
    "    direction = 'N' if tr[1] >= 0 else 'S'\n",
    "    utm_epsg = \"UTM_\" + zone + direction\n",
    "    return (bl_utm, tr_utm), CRS[utm_epsg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_sentinel_1(bbox, epsg, time = time, \n",
    "                        layer = \"SENT\", year = 2019, image_format = MimeType.TIFF_d16, data = DataSource.SENTINEL1_IW_ASC):\n",
    "    \"\"\" Downloads all 10 and 20 meter L2A bands from sentinel-hub\n",
    "        for input bbox and epsg, within time range\n",
    "        \n",
    "        Parameters:\n",
    "         bbox (list): output of calc_bbox\n",
    "         epsg (float): UTM EPSG associated with bbox \n",
    "         time (tuple): YY-MM-DD - YY-MM-DD bounds for downloading \n",
    "    \n",
    "        Returns:\n",
    "         s1 (arr): (Time, X, Y, 2) array of sentinel 1 data\n",
    "         image_dates (list): number of days since time[0] for each\n",
    "                              image in s1.shape[0]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"The data is {data}\")\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer=layer,\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = image_format,\n",
    "                data_source= data,\n",
    "                maxcc=1.0,\n",
    "                resx='10m', resy='5m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=72),\n",
    "            )\n",
    "        data_filter = None\n",
    "        if len(image_request.download_list) > 50:\n",
    "            data_filter = [x for x in range(len(image_request.download_list)) if x % 2 == 0]\n",
    "        s1 = image_request.get_data()#data_filter = data_filter)\n",
    "        #print(s1)\n",
    "        #print(image_request.get_download_list())\n",
    "        s1 = np.stack(s1)\n",
    "        print(f'The original max value is {np.max(s1)}')\n",
    "        if np.max(s1) >= 1000:\n",
    "            s1 = s1 / 65535.\n",
    "            \n",
    "        \n",
    "        assert np.max(s1) <= 1.\n",
    "        assert s1.shape[1] == 64.\n",
    "        assert s1.shape[2] == 32.\n",
    "        \n",
    "        print(f\"Sentinel 1 used {(2/3)*s1.shape[0] * (s1.shape[1]*s1.shape[2])/(512*512)} PU for \\\n",
    "          {s1.shape[0]} out of {len(image_request.download_list)} images\")\n",
    "\n",
    "        s1 = resize(s1, (s1.shape[0], IMSIZE*2, IMSIZE*2, s1.shape[-1]), order = 0)\n",
    "        #print(f\"Sentinel 1 intermediate shape is {s1.shape}\")\n",
    "        s1 = np.reshape(s1, (s1.shape[0], s1.shape[1]//2, 2, s1.shape[2] // 2, 2, s1.shape[-1]))\n",
    "        s1 = np.mean(s1, (2, 4))\n",
    "        s1 = s1[:, 8:24, 8:24, :]\n",
    "        \n",
    "        assert s1.shape[1] == 16.\n",
    "        assert s1.shape[2] == 16.\n",
    "        \n",
    "        image_dates = []\n",
    "        for date in image_request.get_dates():\n",
    "            if date.year == year - 1:\n",
    "                image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year:\n",
    "                image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year + 1:\n",
    "                image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "        image_dates = np.array(image_dates)\n",
    "        print(np.max(s1))\n",
    "        s1c = np.copy(s1)\n",
    "        s1c[np.where(s1c < 1.)] = 0\n",
    "        n_pix_oob = np.sum(s1c, axis = (1, 2, 3))\n",
    "        print(n_pix_oob)\n",
    "        to_remove = np.argwhere(n_pix_oob > (16*16)/5)\n",
    "        print(f'A total of {len(to_remove)} steps of {s1.shape[0]} were removed.')\n",
    "        s1 = np.delete(s1, to_remove, 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        return s1, image_dates\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_days = np.cumsum([0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30])\n",
    "print(starting_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "super_resolve = True\n",
    "year = 2019\n",
    "\n",
    "DATA_LOCATION = '../data/ghana-test.csv'\n",
    "OUTPUT_FOLDER = '../data/test-smooth-200/'\n",
    "\n",
    "def download_plots(data_location = DATA_LOCATION, output_folder = OUTPUT_FOLDER, image_format = MimeType.TIFF_d16):\n",
    "    \"\"\" Downloads sentinel-1 data for the plot IDs associated\n",
    "        with an input CSV from a collect earth online survey\n",
    "        \n",
    "        Parameters:\n",
    "         data_location (os.path)\n",
    "         output_folder (os.path)\n",
    "        \n",
    "        Subcalls:\n",
    "         calc_bbox, bounding_box\n",
    "         download_sentinel_1,\n",
    "         calculate_and_save_best_images\n",
    "         \n",
    "        Creates:\n",
    "         output_folder/{plot_id}.npy\n",
    "    \n",
    "        Returns:\n",
    "         None\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_location, encoding = \"ISO-8859-1\")\n",
    "    for column in ['IMAGERY_TITLE', 'STACKINGPROFILEDG', 'PL_PLOTID', 'IMAGERYYEARDG',\n",
    "                  'IMAGERYMONTHPLANET', 'IMAGERYYEARPLANET']:\n",
    "        if column in df.columns:\n",
    "            df = df.drop(column, axis = 1)\n",
    "    print(df.columns)\n",
    "    df = df.dropna(axis = 0)\n",
    "    plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "    existing = [int(x[:-4]) for x in os.listdir(output_folder) if \".DS\" not in x]\n",
    "    existing = existing + [136397663, 136792033, 136792071, 136397414, 136792213,\n",
    "                          136792216, 136792229]\n",
    "    to_download = [x for x in plot_ids if x not in existing]\n",
    "    print(\"STARTING DOWNLOAD OF {} plots from {} to {}\".format(len(to_download), data_location, output_folder))\n",
    "    errors = []\n",
    "    for i, val in enumerate(to_download):\n",
    "        print(\"Downloading {}/{}, {}\".format(i+1, len(to_download), val))\n",
    "        location_wgs = calc_bbox(val, df = df)\n",
    "        location, epsg = bounding_box(location_wgs, expansion = IMSIZE*10)\n",
    "        try:\n",
    "            # Identify cloud steps, download DEM, and download L2A series\n",
    "            s1_layer = identify_s1_layer(location_wgs[0])\n",
    "            data_source = DataSource.SENTINEL1_IW_DES if s1_layer == \"SENT_DESC\" else DataSource.SENTINEL1_IW_ASC\n",
    "            print(s1_layer, epsg)\n",
    "            s1, s1_dates = download_sentinel_1(location, layer = s1_layer, epsg = epsg, data = data_source)\n",
    "\n",
    "            if s1.shape[0] == 0:\n",
    "                s1_layer = \"SENT_DESC\" if s1_layer == \"SENT\" else \"SENT\"\n",
    "                data_source = DataSource.SENTINEL1_IW_DES if s1_layer == \"SENT_DESC\" else DataSource.SENTINEL1_IW_ASC\n",
    "                print(f'Switching to {s1_layer}')\n",
    "                s1, s1_dates = download_sentinel_1(location, layer = s1_layer, epsg = epsg, data = data_source)\n",
    "            \n",
    "            s1, _ = calculate_and_save_best_images(s1, s1_dates)\n",
    "\n",
    "            # Retain only iamgery every 15 days\n",
    "            biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "            to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "            s1 = np.delete(s1, to_remove, 0)\n",
    "\n",
    "            np.save(output_folder + str(val), s1)\n",
    "            #return s1, s1_dates\n",
    "            print('\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.fatal(e, exc_info=True)\n",
    "            errors.append(i)\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (os.listdir(\"../data/train-csv/\")):\n",
    "    #if \"australia\" in i:\n",
    "    if \"makueni\" in i:\n",
    "        #if any(x in i for x in [\"africa-west\", \"cameroon\", \"koure\", \"niger\"]):\n",
    "        download_plots(\"../data/train-csv/\" + i, \"../data/train-s1/\", image_format = MimeType.TIFF_d16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
