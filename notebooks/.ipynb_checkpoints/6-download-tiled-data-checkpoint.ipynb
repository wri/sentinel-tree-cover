{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "from sentinelhub import DataSource\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import splu\n",
    "\n",
    "\n",
    "from sentinelhub import CustomUrlParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/slope.py\n",
    "%run ../src/utils-bilinear.py\n",
    "%run ../src/dsen2/utils/DSen2Net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSG = CRS.WGS84\n",
    "GRID_SIZE_X = 1\n",
    "GRID_SIZE_Y = 1\n",
    "\n",
    "IMAGE_X = 14*GRID_SIZE_X\n",
    "IMAGE_Y = 14*GRID_SIZE_Y\n",
    "\n",
    "TEST_X = 5\n",
    "TEST_Y = 5\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY = key['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_arr = np.array([[1, 1, 1, 1, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 2, 3, 2, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 1, 1, 1, 1,],])\n",
    "                  \n",
    "c_arr = c_arr / 3\n",
    "o_arr = 1 - c_arr\n",
    "c_arr = np.tile(c_arr[:, :, np.newaxis], (1, 1, 11))\n",
    "o_arr = np.tile(o_arr[:, :, np.newaxis], (1, 1, 11))\n",
    "c_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('2018-12-15', '2020-01-15')\n",
    "SIZE = 9\n",
    "IMSIZE = (SIZE * 14)+2\n",
    "print(time)\n",
    "\n",
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def bounding_box(point, x_offset_max = 140, y_offset_max = 140, expansion = 10):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    #@valid\n",
    "    tl = point\n",
    "    \n",
    "    if 78 <= tl[0] <= 84:\n",
    "        epsg = 32644 if tl[1] > 0 else 32744\n",
    "    if 72 <= tl[0] <= 78:\n",
    "        epsg = 32643 if tl[1] > 0 else 32743\n",
    "    if 66 <= tl[0] <= 72:\n",
    "        epsg = 32642 if tl[1] > 0 else 32742\n",
    "    if 60 <= tl[0] <= 66:\n",
    "        epsg = 32641 if tl[1] > 0 else 32741\n",
    "    if 54 <= tl[0] <= 60:\n",
    "        epsg = 32640 if tl[1] > 0 else 32740\n",
    "    if 48 <= tl[0] <= 54:\n",
    "        epsg = 32639 if tl[1] > 0 else 32739\n",
    "    if 42 <= tl[0] <= 48:\n",
    "        epsg = 32638 if tl[1] > 0 else 32738\n",
    "    if 36 <= tl[0] <= 42:\n",
    "        epsg = 32637 if tl[1] > 0 else 32737\n",
    "    if 30 <= tl[0] <= 36:\n",
    "        epsg = 32636 if tl[1] > 0 else 32736\n",
    "    if 24 <= tl[0] <= 30:\n",
    "        epsg = 32635 if tl[1] > 0 else 32735\n",
    "    if 18 <= tl[0] <= 24:\n",
    "        epsg = 32634 if tl[1] > 0 else 32734\n",
    "    if 12 <= tl[0] <= 18:\n",
    "        epsg = 32633 if tl[1] > 0 else 32733\n",
    "    if 6 <= tl[0] <= 12:\n",
    "        epsg = 32632 if tl[1] > 0 else 32732\n",
    "    if 0 <= tl[0] <= 6:\n",
    "        epsg = 32631 if tl[1] > 0 else 32731\n",
    "    if -6 <= tl[0] <= 0:\n",
    "        epsg = 32630 if tl[1] > 0 else 32730\n",
    "    if -12 <= tl[0] <= -6:\n",
    "        epsg = 32629 if tl[1] > 0 else 32729\n",
    "    if -18 <= tl[0] <= -12:\n",
    "        epsg = 32628 if tl[1] > 0 else 32728\n",
    "    if -24 <= tl[0] <= -18:\n",
    "        epsg = 32627 if tl[1] > 0 else 32727\n",
    "    if -30 <= tl[0] <= -24:\n",
    "        epsg = 32626 if tl[1] > 0 else 32726\n",
    "    if -36 <= tl[0] <= -30:\n",
    "        epsg = 32625 if tl[1] > 0 else 32725\n",
    "    if -42 <= tl[0] <= -36:\n",
    "        epsg = 32624 if tl[1] > 0 else 32724\n",
    "    if -48 <= tl[0] <= -42:\n",
    "        epsg = 32623 if tl[1] > 0 else 32723\n",
    "    if -54 <= tl[0] <= -48:\n",
    "        epsg = 32622 if tl[1] > 0 else 32722\n",
    "    if -60 <= tl[0] <= -54:\n",
    "        epsg = 32621 if tl[1] > 0 else 32721\n",
    "    if -66 <= tl[0] <= -60:\n",
    "        epsg = 32620 if tl[1] > 0 else 32720\n",
    "    if -72 <= tl[0] <= -66:\n",
    "        epsg = 32619 if tl[1] > 0 else 32719\n",
    "    if -78 <= tl[0] <= -72:\n",
    "        epsg = 32618 if tl[1] > 0 else 32718\n",
    "    if -84 <= tl[0] <= -78:\n",
    "        epsg = 32617 if tl[1] > 0 else 32717\n",
    "    if -90 <= tl[0] <= -84:\n",
    "        epsg = 32616 if tl[1] > 0 else 32716\n",
    "    if -96 <= tl[0] <= -90:\n",
    "        epsg = 32615 if tl[1] > 0 else 32715\n",
    "    if -102 <= tl[0] <= -96:\n",
    "        epsg = 32614 if tl[1] > 0 else 32714\n",
    "    if -108 <= tl[0] <= -102:\n",
    "        epsg = 32613 if tl[1] > 0 else 32713\n",
    "    if -114 <= tl[0] <= -108:\n",
    "        epsg = 32612 if tl[1] > 0 else 32712\n",
    "    if -120 <= tl[0] <= -114:\n",
    "        epsg = 32611 if tl[1] > 0 else 32711\n",
    "    if -126 <= tl[0] <= -120:\n",
    "        epsg = 32610 if tl[1] > 0 else 32710\n",
    "        \n",
    "    tl = convertCoords(tl, 4326, epsg)\n",
    "    \n",
    "    br = (tl[0], tl[1])\n",
    "    tl = ((tl[0] + (x_offset_max)), (tl[1] + (y_offset_max )))\n",
    "    distance1 = tl[0] - br[0]\n",
    "    distance2 = tl[1] - br[1]\n",
    "    \n",
    "    br = [a - expansion for a in br]\n",
    "    tl = [a + expansion for a in tl]\n",
    "    \n",
    "    after = [b - a for a,b in zip(br, tl)]\n",
    "    br = convertCoords(br, epsg, 4326)\n",
    "    tl = convertCoords(tl, epsg, 4326)\n",
    "    \n",
    "    min_x = tl[0] # original X offset - 10 meters\n",
    "    max_x = br[0] # original X offset + 10*GRID_SIZE meters\n",
    "    \n",
    "    min_y = tl[1] # original Y offset - 10 meters\n",
    "    max_y = br[1] # original Y offset + 10 meters + 140 meters\n",
    "    # (min_x, min_y), (max_x, max_y)\n",
    "    # (bl, tr)\n",
    "    return [(min_x, min_y), (max_x, max_y)]\n",
    " \n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)\n",
    "\n",
    "def identify_clouds(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=(SIZE*14)+2,\n",
    "            height=(SIZE*14)+2,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.75,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        cloud_steps = [i for i, val in enumerate(means) if val > 0.30]\n",
    "        return cloud_steps, means, cloud_probs\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(bbox, epsg = EPSG):\n",
    "    #@valid\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_s = (SIZE*14)+4\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=dem_s,\n",
    "                         height=dem_s,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, dem_s, dem_s)),\n",
    "                  np.full((dem_s, dem_s), 10), np.full((dem_s, dem_s), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((dem_s,dem_s, 1))\n",
    "    dem_image = dem_image[1:dem_s-1, 1:dem_s-1, :]\n",
    "    return dem_image #/ np.max(dem_image)\n",
    "\n",
    "from skimage.transform import resize\n",
    "def download_layer(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A20',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        img_20 = np.stack(img_bands)\n",
    "        img_20 = resize(img_20, (img_20.shape[0], IMSIZE, IMSIZE, img_20.shape[-1]), order = 0)\n",
    "        \n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A10',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'BICUBIC',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        img_bands = image_request.get_data()\n",
    "        img_10 = np.stack(img_bands)\n",
    "        img_10 = resize(img_10, (img_10.shape[0], IMSIZE, IMSIZE, img_10.shape[-1]), order = 0)\n",
    "        shadows = img_10[:, :, :, -1]\n",
    "        img_10 = img_10[:, :, :, :-1]\n",
    "        \n",
    "        shadows[np.where(shadows != 3)] = 0\n",
    "        shadows[np.where(shadows == 3)] = 1\n",
    "        print(\"Data shape: {}\".format(shadows.shape))\n",
    "        shadow_sum = np.sum(shadows, axis = (1, 2))\n",
    "        shadow_steps = np.argwhere(shadow_sum > (IMSIZE*IMSIZE) / 4)\n",
    "        \n",
    "        img = np.concatenate([img_10, img_20], axis = -1)\n",
    "        return img, image_request, shadows, shadow_steps\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "\n",
    "def remove_missed_clouds(img):\n",
    "    iqr = np.percentile(img[:, :, :, 3].flatten(), 75) - np.percentile(img[:, :, :, 3].flatten(), 25)\n",
    "    thresh_t = np.percentile(img[:, :, :, 3].flatten(), 75) + iqr*2\n",
    "    thresh_b = np.percentile(img[:, :, :, 3].flatten(), 25) - iqr*2\n",
    "    diffs_fw = np.diff(img, 1, axis = 0)\n",
    "    diffs_fw = np.mean(diffs_fw, axis = (1, 2, 3))\n",
    "    diffs_fw = np.array([0] + list(diffs_fw))\n",
    "    diffs_bw = np.diff(np.flip(img, 0), 1, axis = 0)\n",
    "    diffs_bw = np.flip(np.mean(diffs_bw, axis = (1, 2, 3)))\n",
    "    diffs_bw = np.array(list(diffs_bw) + [0])\n",
    "    diffs = abs(diffs_fw - diffs_bw) * 100 # 3, -3 -> 6, -3, 3 -> 6, -3, -3\n",
    "    #diffs = [int(x) for x in diffs]\n",
    "    outlier_percs = []\n",
    "    for step in range(img.shape[0]):\n",
    "        bottom = len(np.argwhere(img[step, :, :, 3].flatten() > thresh_t))\n",
    "        top = len(np.argwhere(img[step, :, :, 3].flatten() < thresh_b))\n",
    "        p = 100* ((bottom + top) / (IMSIZE*IMSIZE))\n",
    "        outlier_percs.append(p)\n",
    "    to_remove = np.argwhere(np.array(outlier_percs) > 25)\n",
    "    return to_remove\n",
    "        \n",
    "    \n",
    "def calculate_and_save_best_images(img_bands, image_dates):\n",
    "\n",
    "    biweekly_dates = [day for day in range(0, 360, 5)] # ideal imagery dates are every 15 days\n",
    "    \n",
    "    # Identify the dates where there is < 20% cloud cover\n",
    "    #satisfactory_ids = list(np.argwhere(np.array(means) < 4.).reshape(-1, )) \n",
    "    satisfactory_ids = [x for x in range(0, img_bands.shape[0])]\n",
    "    satisfactory_dates = [value for idx, value in enumerate(image_dates) if idx in satisfactory_ids]\n",
    "    \n",
    "    \n",
    "    selected_images = {}\n",
    "    for i in biweekly_dates:\n",
    "        distances = [abs(date - i) for date in satisfactory_dates]\n",
    "        closest = np.min(distances)\n",
    "        closest_id = np.argmin(distances)\n",
    "        # If there is imagery within 8 days, select it\n",
    "        if closest < 8:\n",
    "            date = satisfactory_dates[closest_id]\n",
    "            image_idx = int(np.argwhere(np.array(image_dates) == date)[0])\n",
    "            selected_images[i] = {'image_date': [date], 'image_ratio': [1], 'image_idx': [image_idx]}\n",
    "        # If there is not imagery within 8 days, look for the closest above and below imagery\n",
    "        else:\n",
    "            distances = np.array([(date - i) for date in satisfactory_dates])\n",
    "            # Number of days above and below the selected date of the nearest clean imagery\n",
    "            above = distances[np.where(distances < 0, distances, -np.inf).argmax()]\n",
    "            below = distances[np.where(distances > 0, distances, np.inf).argmin()]\n",
    "            if abs(above) > 200: # If date is the last date, occassionally argmax would set above to - number\n",
    "                above = below\n",
    "            if abs(below) > 200:\n",
    "                below = above\n",
    "            if above != below:\n",
    "                below_ratio = above / (above - below)\n",
    "                above_ratio = 1 - below_ratio\n",
    "            else:\n",
    "                above_ratio = below_ratio = 0.5\n",
    "                \n",
    "            # Extract the image date and imagery index for the above and below values\n",
    "            above_date = i + above\n",
    "            above_image_idx = int(np.argwhere(np.array(image_dates) == above_date)[0])\n",
    "            \n",
    "            below_date = i + below\n",
    "            below_image_idx = int(np.argwhere(np.array(image_dates) == below_date)[0])\n",
    "            \n",
    "            selected_images[i] = {'image_date': [above_date, below_date], 'image_ratio': [above_ratio, below_ratio],\n",
    "                                 'image_idx': [above_image_idx, below_image_idx]}\n",
    "                            \n",
    "    max_distance = 0\n",
    "    \n",
    "    for i in selected_images.keys():\n",
    "        #print(i, selected_images[i])\n",
    "        if len(selected_images[i]['image_date']) == 2:\n",
    "            dist = selected_images[i]['image_date'][1] - selected_images[i]['image_date'][0]\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "    \n",
    "    print(\"Maximum time distance: {}\".format(max_distance))\n",
    "        \n",
    "    keep_steps = []\n",
    "    for i in selected_images.keys():\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "        if len(info['image_idx']) == 2:\n",
    "            step1 = img_bands[info['image_idx'][0]] * 0.5#info['image_ratio'][0]\n",
    "            step2 = img_bands[info['image_idx'][1]] * 0.5 #info['image_ratio'][1]\n",
    "            step = step1 + step2\n",
    "        keep_steps.append(step)\n",
    "        \n",
    "    keep_steps = np.stack(keep_steps)\n",
    "    return keep_steps\n",
    "\n",
    "def calc_best(tiles, cloud_probs, request, offset_x, offset_y):\n",
    "    c_probs = cloud_probs[:, offset_x:offset_x+16, offset_y:offset_y+16]\n",
    "    images = np.stack(tiles)[:, offset_x:offset_x+16, offset_y:offset_y+16]\n",
    "    mins = np.min(c_probs, axis = 0)\n",
    "    c_probs = c_probs - mins\n",
    "    # Calculating the number of pixels in the 16x16 window that are 0.3 above min cloud probability\n",
    "    args = np.array([len(np.argwhere(c_probs[x, :, :].reshape(16*16) > 0.3)) for x in range(c_probs.shape[0])])\n",
    "    print(len([x for x in args if x > 3]))\n",
    "    best = calculate_and_save_best_images(images, request, args)\n",
    "    return best\n",
    "\n",
    "def speyediff(N, d, format = 'csc'):\n",
    "    shape = (N-d, N)\n",
    "    diagonals = np.zeros(2*d + 1)\n",
    "    diagonals[d] = 1.\n",
    "    for i in range(d):\n",
    "        diff = diagonals[:-1] - diagonals[1:]\n",
    "        diagonals = diff\n",
    "    offsets = np.arange(d+1)\n",
    "    spmat = sparse.diags(diagonals, offsets, shape, format = format)\n",
    "    return spmat\n",
    "\n",
    "def smooth(y, lmbd, d = 2):\n",
    "    m = len(y)\n",
    "    E = sparse.eye(m, format = 'csc')\n",
    "    D = speyediff(m, d, format = 'csc')\n",
    "    coefmat = E + lmbd * D.conj().T.dot(D)\n",
    "    z = splu(coefmat).solve(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coords = (13.540810, 38.177220) # tigray\n",
    "#coords = (-1.817109, 37.477563) # makueni-2\n",
    "#coords = (-2.575694, 37.949516) # makueni-3\n",
    "#coords = (-2.561161, 38.096274) # makueni\n",
    "#coords = (9.259359, -0.833750) # ghana\n",
    "#coords = (-1.515869, 29.952997) # rwanda\n",
    "#coords = (13.316919, 2.581680) # niger\n",
    "#coords = (13.18158333, 2.47805556) # niger - koure salima\n",
    "#coords = (10.596, 14.2722) # cameroon\n",
    "#coords = (18.232495, -92.134215) # campeche\n",
    "#coords = (14.231732, -89.418679) # el salvador\n",
    "#coords = (-11.044091, 33.818034) # malawi\n",
    "#coords = (10.385811, -1.764760) # sisala east, ghana\n",
    "#coords = (10.390084, -0.846330) # weest mamprusi, ghana\n",
    "#coords = (7.702058, -0.709011) # brong ahafo, bono east\n",
    "coords = (10.097017, -2.439068)# close to wa, has been done\n",
    "#coords = (7.398111, -1.269223) # cocoa\n",
    "#coords = (44.622690, -124.067024) # oregon\n",
    "#coords = (-20.147326, -40.837780) # Esperito santo, BR\n",
    "#coords = (-22.559943, -44.186629) # Vale do Paraiba, Brazil\n",
    "#coords = (6.622101, -0.704616) # kwahu\n",
    "coords = (6.518909, -0.826008) # kwahu large\n",
    "coords = (coords[1], coords[0])\n",
    "OUTPUT_FOLDER = '../data/kwahu-large/'\n",
    "#13.567962754335872\n",
    "\n",
    "borders = bounding_box(coords, 10*(SIZE*14), 10*(SIZE*14), expansion = 0)\n",
    "print(borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this needs the first coordinate to not be [coords] for different y steps\n",
    "\n",
    "def calculate_offset_coords(coords, x_step, y_step, number):\n",
    "    offset_coords = []\n",
    "    y_coord = bounding_box(coords, x_step, y_step, expansion = 0)\n",
    "    y_coord = y_coord[0][1]\n",
    "    for i in range(number):\n",
    "        bbx = bounding_box(coords, (i+1)*x_step, y_step, expansion = 10)\n",
    "        coord_x = bbx[0][0]\n",
    "        coord_y = y_coord\n",
    "        offset_coords.append((coord_x, coord_y))\n",
    "    coords = [(coords[0], y_coord)]\n",
    "    return coords + offset_coords\n",
    "\n",
    "corner_coordinates = []\n",
    "for row in range(0, 22):\n",
    "    temp = calculate_offset_coords(coords, x_step = (SIZE*140), \n",
    "                                            y_step = row*(SIZE*140), \n",
    "                                            number = 22)\n",
    "    corner_coordinates.append([[x, [y, row]] for x, y in zip(temp, [col for col in range(0, 22)])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDL_PATH = \"../src/dsen2/models/\"\n",
    "\n",
    "input_shape = ((4, None, None), (6, None, None))\n",
    "model = s2model(input_shape, num_layers=6, feature_size=128)\n",
    "predict_file = MDL_PATH+'s2_032_lr_1e-04.hdf5'\n",
    "print('Symbolic Model Created.')\n",
    "\n",
    "model.load_weights(predict_file)\n",
    "\n",
    "def DSen2(d10, d20):\n",
    "    test = [d10, d20]\n",
    "    input_shape = ((4, None, None), (6, None, None))\n",
    "    prediction = _predict(test, input_shape, deep=False)\n",
    "    #prediction *= 5\n",
    "    return prediction\n",
    "\n",
    "def _predict(test, input_shape, model = model, deep=False, run_60=False):\n",
    "    \n",
    "    print(\"Predicting using file: {}\".format(predict_file))\n",
    "    prediction = model.predict(test, verbose=1)\n",
    "    return prediction\n",
    "    return img, shadow_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "starting_days = np.cumsum(days_per_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(sample):\n",
    "    for date in range(24):\n",
    "        for band in range(10):\n",
    "            maxs = np.max(sample[date, :, :, band])\n",
    "            mins = np.min(sample[date, :, :, band])\n",
    "            if maxs == 1.0 or mins == 0.0:\n",
    "                print(\"Found null outlier\")\n",
    "                return True\n",
    "            if maxs == mins:\n",
    "                print(\"Found missing outlier\")\n",
    "                return True\n",
    "            if maxs >= 1.05 or mins <= -1.05:\n",
    "                print(\"Found range outlier\")\n",
    "                return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def tile_images(arr, output_folder):\n",
    "    # Normal\n",
    "    for x_offset, cval in enumerate([x for x in range(0, 126, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 126, 14)]):\n",
    "            base_id = 0\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            np.save(output_folder + str(base_id+x_offset*9+y_offset+1), subs)\n",
    "            \n",
    "    # Upright        \n",
    "    for x_offset, cval in enumerate([x for x in range(7, 126, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(7, 126, 14)]):\n",
    "            base_id = 9*9\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            np.save(output_folder + str(base_id+x_offset*8+y_offset+1), subs)\n",
    "            \n",
    "    # Right\n",
    "    for x_offset, cval in enumerate([x for x in range(7, 119, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 126, 14)]):\n",
    "            base_id = (9*9)+(8*8)\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            np.save(output_folder + str(base_id+x_offset*9+y_offset+1), subs)\n",
    "            \n",
    "    # Up\n",
    "    for x_offset, cval in enumerate([x for x in range(0, 119, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(7, 126, 14)]):\n",
    "            base_id = (9*9)+(8*8)+(9*8)\n",
    "            subs = arr[:, cval:cval+16, rval:rval+16]\n",
    "            np.save(output_folder + str(base_id+x_offset*8+y_offset+1), subs)\n",
    "            \n",
    "            \n",
    "def calculate_proximal_steps(date, satisfactory):\n",
    "    arg_before = None\n",
    "    arg_after = None\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < np.max(satisfactory):\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after and not arg_before:\n",
    "        arg_after = date\n",
    "        arg_before = date\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    #print(arg_before, date, arg_after)\n",
    "    return arg_before, arg_after\n",
    "\n",
    "def worker_download(coord, folder = OUTPUT_FOLDER, year = 2019):\n",
    "    idx_x = coord[1][0]\n",
    "    idx_y = coord[1][1]\n",
    "    print(\"Starting: {} {}\".format(idx_x, idx_y))\n",
    "    coord = coord[0]\n",
    "    output_folder = OUTPUT_FOLDER + \"{}\".format(str(idx_y))\n",
    "    if not os.path.exists(os.path.realpath(output_folder)):\n",
    "        os.makedirs(os.path.realpath(output_folder))\n",
    "    existing = [x for x in os.listdir(os.path.realpath(output_folder))]\n",
    "    print(existing)\n",
    "    print(str(idx_x))\n",
    "    if str(idx_x) + \".npy\" not in existing:\n",
    "        tiled_bbx = bounding_box(coord, y_offset_max = SIZE*140, x_offset_max = SIZE*140, expansion = 10)\n",
    "        print(tiled_bbx)\n",
    "        dem_bbx = bounding_box(coord, y_offset_max = SIZE*140, x_offset_max = SIZE*140, expansion = 20)\n",
    "        cloud_steps, means, cloud_probs = identify_clouds(tiled_bbx)\n",
    "        tiles, request, shadows, shadow_steps = download_layer(tiled_bbx)\n",
    "        print(\"Downloaded imagery\")\n",
    "        \n",
    "        image_dates = []\n",
    "        for date in request.get_dates():\n",
    "            if date.year == year - 1:\n",
    "                image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year:\n",
    "                image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year + 1:\n",
    "                image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "        image_dates = np.array(image_dates)\n",
    "\n",
    "        args = np.array([len(np.argwhere(cloud_probs[x, :, :].reshape((128)*(128)) > 0.5)) for x in range(cloud_probs.shape[0])])\n",
    "        dirty_steps = np.argwhere(args > (128)*(128) / 4)\n",
    "        missing_images = [np.argwhere(tiles[x, :, : :10].flatten() == 0.0) for x in range(tiles.shape[0])]\n",
    "        missing_images = np.array([len(x) for x in missing_images])\n",
    "        missing_images_p = [np.argwhere(tiles[x, :, : :10].flatten() >= 1) for x in range(tiles.shape[0])]\n",
    "        missing_images_p = np.array([len(x) for x in missing_images_p])\n",
    "        missing_images += missing_images_p\n",
    "        missing_images = list(np.argwhere(missing_images >= 100))\n",
    "        to_remove = np.unique(np.array(list(dirty_steps) + list(missing_images) + list(shadow_steps)))\n",
    "\n",
    "        # Remove null steps\n",
    "        print(\"There are {}/{} dirty steps: {} cloud, {} missing, {} shadows\".format(len(to_remove),\n",
    "                                                                                    len(tiles), len(dirty_steps),\n",
    "                                                                                    len(missing_images),\n",
    "                                                                                    len(shadow_steps)))\n",
    "\n",
    "        tiles = np.delete(tiles, to_remove, 0)\n",
    "        cloud_probs = np.delete(cloud_probs, to_remove, 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        shadows = np.delete(shadows, to_remove, 0)\n",
    "        #tiles = remove_blank_steps(tiles)\n",
    "        \n",
    "        to_remove = remove_missed_clouds(tiles)\n",
    "        tiles = np.delete(tiles, to_remove, 0)\n",
    "        cloud_probs = np.delete(cloud_probs, to_remove, 0)\n",
    "        shadows = np.delete(shadows, to_remove, 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        print(\"Removing {} steps based on ratio\".format(len(to_remove)))\n",
    "\n",
    "        dem = download_dem(dem_bbx)\n",
    "        \n",
    "        dem = np.tile(dem[np.newaxis, :, :, :], (tiles.shape[0], 1, 1, 1))\n",
    "        tiles = np.concatenate([tiles, dem], axis = -1)\n",
    "        tiles[:, :, :, 10] /= 90\n",
    "        \n",
    "        prior = np.copy(tiles)\n",
    "        new_shadows = threshold_shadows(tiles[:, :, :, 3])\n",
    "        x, new_probs, mid_probs = remove_cloud_and_shadows(tiles, cloud_probs, new_shadows, image_dates)\n",
    "        #x = tiles\n",
    "        #print(\"Before super: {}\".format(x.shape))\n",
    "\n",
    "        #d10 = x[:, :, :, 0:4]\n",
    "        #d20 = x[:, :, :, 4:10]\n",
    "\n",
    "        #d10 = np.swapaxes(d10, 1, -1)\n",
    "        #d10 = np.swapaxes(d10, 2, 3)\n",
    "        #d20 = np.swapaxes(d20, 1, -1)\n",
    "        #d20 = np.swapaxes(d20, 2, 3)\n",
    "        #superresolved = DSen2(d10, d20)\n",
    "        #superresolved = np.swapaxes(superresolved, 1, -1)\n",
    "        #superresolved = np.swapaxes(superresolved, 1, 2)\n",
    "\n",
    "        # returns band IDXs 3, 4, 5, 7, 8, 9\n",
    "        #x[:, :, :, 4:10] = superresolved\n",
    "        \n",
    "        x, amin = evi(x, True)\n",
    "        # Where evi is OOB, remove (likely cloud cover missed)\n",
    "        #if len(amin) > 0:\n",
    "        #    satisfactory = [x for x in range(x.shape[0]) if x not in amin]\n",
    "        #    for i in amin:\n",
    "        #        before, after = calculate_proximal_steps(i, satisfactory)\n",
    "        #        before = i + before\n",
    "        #        after = i + after\n",
    "        ##        print(\"Interpolating {} with {} and {}\".format(i, before, after))\n",
    "         #       bef = x[before, :, :, :]\n",
    "         #       aft = x[after, :, :, :]\n",
    "         #       x[i, :, :, :] = (bef + aft) / 2\n",
    "        x = bi(x, True)\n",
    "        x = msavi2(x, True)\n",
    "        x = si(x, True)\n",
    "        \n",
    "        # check for and remove null values\n",
    "        missing_pixels = 0\n",
    "       # missing = np.argwhere(np.isnan(np.mean(x, axis = (1, 2, 3))))\n",
    "        #if len(missing) > 0:\n",
    "        #    print(\"Deleting {} steps because of missing imagery\".format(missing))\n",
    "        #    x = np.delete(x, missing, 0)\n",
    "        #    image_dates = np.delete(image_dates, missing)\n",
    "        \n",
    "        for band in range(0, 15):\n",
    "            for time in range(0, x.shape[0]):\n",
    "                x_i = x[time, :, :, band]\n",
    "                missing_pixels += len(np.argwhere(np.isnan(x_i)))\n",
    "                x_i[np.argwhere(np.isnan(x_i))] = np.mean(x_i)\n",
    "                x[time, :, :, band] = x_i\n",
    "        print(\"There are {} missing pixels\".format(missing_pixels))\n",
    "        \n",
    "        \n",
    "        x = calculate_and_save_best_images(x, image_dates)\n",
    "    \n",
    "        for row in range(0, (SIZE*14)+2):\n",
    "            for column in range(0, (SIZE*14)+2):\n",
    "                for band in [x for x in range(0, 15) if x != 10]:\n",
    "                    sm = smooth(x[:, row, column, band], 800, d = 2)\n",
    "                    x[:, row, column, band] = sm\n",
    "        \n",
    "        biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "        to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "        x = np.delete(x, to_remove, 0)\n",
    "        np.save(output_folder + \"/\" + str(idx_x) + \".npy\", x)\n",
    "    \n",
    "        return (prior, x, cloud_probs, new_probs, mid_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_shadows(arr):\n",
    "    arr = np.copy(arr)\n",
    "    iqr = np.percentile(arr.flatten(), 75) - np.percentile(arr.flatten(), 25)\n",
    "    low = np.percentile(arr.flatten(), 25)\n",
    "    #high = np.percentile(arr.flatten(), 75)\n",
    "    thresh_low = low - 1.5*iqr\n",
    "    #thresh_high = high + 2*iqr\n",
    "    #arr[np.where(arr > thresh_high)] = 1.\n",
    "    arr[np.where(arr < thresh_low)] = 1.\n",
    "    arr[np.where(arr < 1)] = 0.\n",
    "    arr = np.reshape(arr, (arr.shape[0], 16, 8, 16, 8))\n",
    "    arr = np.sum(arr, axis = (2, 4))\n",
    "    arr = resize(arr, (arr.shape[0], 128, 128), 0)\n",
    "    fake_shadows = np.zeros((arr.shape[0], arr.shape[1], arr.shape[2]))\n",
    "    for step in range(arr.shape[0]):\n",
    "        if step > 0:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        before = arr[step - 1, x, y]\n",
    "                        if abs(before - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "                            \n",
    "    for step in range(arr.shape[0]):\n",
    "        if step < arr.shape[0] - 1:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        after = arr[step + 1, x, y]\n",
    "                        if abs(after - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "    before = np.sum(arr)\n",
    "    arr[np.where(fake_shadows == 1)] = 0.\n",
    "    after = np.sum(arr)\n",
    "    arr[np.where(arr > 9)] = 1.\n",
    "    arr[np.where(arr < 9)] = 0.\n",
    "    print(\"Removed {} fake shadows, leaving {}\".format(before - after, after))\n",
    "    print(\"The total percent shadow cover is: {}%\".format(after/(arr.shape[0]*arr.shape[1]*arr.shape[2])))\n",
    "    for step in range(arr.shape[0]):\n",
    "        for x in range(1, arr.shape[1] -1):\n",
    "            for y in range(1, arr.shape[2] - 1):\n",
    "                if np.sum(arr[step, x-1:x+2, y-1:y+2]) == 1:\n",
    "                    if arr[step, x, y] != 0:\n",
    "                        print(\"Removing: {} {} {} {}\".format(step, x, y, np.sum(arr[step, x-1:x+2, y-1:y+2])))\n",
    "                        arr[step, x, y] = 0\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "def remove_cloud_and_shadows(tiles, c_probs, shadows, image_dates):\n",
    "    \n",
    "    wsize = 5\n",
    "    c_probs = c_probs - np.min(c_probs, axis = 0)\n",
    "    c_probs[np.where(c_probs > 0.33)] = 1.\n",
    "    c_probs[np.where(c_probs < 0.33)] = 0.\n",
    "    c_probs = np.reshape(c_probs, (c_probs.shape[0], 16, 8, 16, 8))\n",
    "    c_probs = np.sum(c_probs, (2, 4))\n",
    "    #c_probs = np.max(c_probs, (2, 4))\n",
    "    c_probs = resize(c_probs, (c_probs.shape[0], IMSIZE, IMSIZE), 0)\n",
    "    c_probs[np.where(c_probs < 4)] = 0\n",
    "    c_probs[np.where(c_probs >= 4)] = 1\n",
    "    secondary_c_probs = np.copy(c_probs)\n",
    "    c_probs += shadows\n",
    "    c_probs[np.where(c_probs >= 1.)] = 1.\n",
    "    number_interpolated = 0\n",
    "    for cval in range(0, IMSIZE - 4, 1):\n",
    "        for rval in range(0, IMSIZE - 4, 1):\n",
    "            subs = c_probs[:, cval:cval + wsize, rval:rval+wsize]\n",
    "            sums = np.sum(subs, axis = (1, 2))\n",
    "            satisfactory = [x for x in range(c_probs.shape[0]) if sums[x] < 10]\n",
    "            satisfactory = np.array(satisfactory)\n",
    "            for date in range(0, tiles.shape[0]):\n",
    "                if np.sum(subs[date, :, :]) > 10:\n",
    "                    number_interpolated += 1\n",
    "                    before, after = calculate_proximal_steps(date, satisfactory)\n",
    "                    before = date + before\n",
    "                    after = date + after\n",
    "                    bef = tiles[before, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    aft = tiles[after, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    before = image_dates[before]\n",
    "                    after = image_dates[after]\n",
    "                    before_diff = abs(image_dates[date] - before)\n",
    "                    after_diff = abs(image_dates[date] - after)\n",
    "                    bef_wt = 1 - before_diff / (before_diff + after_diff)\n",
    "                    aft_wt = 1 - bef_wt\n",
    "                    candidate = bef_wt*bef + aft_wt*aft\n",
    "                    candidate = candidate*c_arr + tiles[date, cval:cval+wsize, rval:rval+wsize, : ]*o_arr\n",
    "                    tiles[date, cval:cval+wsize, rval:rval+wsize, : ] = candidate \n",
    "    print(\"A total of {} pixels were interpolated\".format(number_interpolated))\n",
    "    return tiles, c_probs, secondary_c_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(0, 3):\n",
    "    for c in range(0, 4):\n",
    "        x2 = worker_download(corner_coordinates[r][c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 14))\n",
    "sns.heatmap(x2[1][27, :, :, 0]) # 22, 27, 29, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "START_Y = 0\n",
    "START_X = 0\n",
    "\n",
    "import multiprocessing\n",
    "for i in corner_coordinates[:6]:\n",
    "    try:\n",
    "        threads = 4\n",
    "        pool = multiprocessing.Pool(threads)\n",
    "        zip(*pool.map(worker_download, i[:8]))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    except Exception as e:\n",
    "        print(\"error\")\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
