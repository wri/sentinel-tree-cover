{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree segmentation with multitemporal Sentinel 1/2 imagery\n",
    "\n",
    "## John Brandt\n",
    "## September 2021\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains the TensorFlow model training and prediction. The notebook uses tensorflow 1.15.1 and additionally relies on Keras.\n",
    "\n",
    "\n",
    "## Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.keras.layers import Conv2D, Lambda, Dense, Multiply, Add\n",
    "from tensorflow.initializers import glorot_normal, lecun_normal\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "from tensorflow.python.util import deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/layers/zoneout.py\n",
    "%run ../src/layers/adabound.py\n",
    "%run ../src/layers/convgru.py\n",
    "%run ../src/layers/dropblock.py\n",
    "%run ../src/layers/extra_layers.py\n",
    "%run ../src/layers/stochastic_weight_averaging.py\n",
    "%run ../src/preprocessing/indices.py\n",
    "%run ../src/preprocessing/slope.py\n",
    "%run ../src/utils/metrics.py\n",
    "%run ../src/utils/lovasz.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONE_OUT_PROB = 0.90\n",
    "ACTIVATION_FUNCTION = 'swish'\n",
    "\n",
    "INITIAL_LR = 1e-3\n",
    "DROPBLOCK_MAXSIZE = 5\n",
    "DECONV = 'upconv'\n",
    "N_CONV_BLOCKS = 1\n",
    "FINAL_ALPHA = 0.33\n",
    "LABEL_SMOOTHING = 0.03\n",
    "\n",
    "L2_REG = 0.\n",
    "BATCH_SIZE = 32\n",
    "MAX_DROPBLOCK = 0.85\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "LABEL_SIZE = 14\n",
    "FRESH_START = True\n",
    "best_val = 0.2\n",
    "\n",
    "START_EPOCH = 1\n",
    "END_EPOCH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layer definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility blocks (Batch norm, cSSE, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_block(prevlayer, prefix):\n",
    "    '''Spatial excitation and channel squeeze layer.\n",
    "       Calculates a 1x1 convolution with sigmoid activation to create a \n",
    "       spatial map that is multiplied by the input layer\n",
    "\n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the sse_block\n",
    "    '''\n",
    "    conv = Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    '''Adapted from https://github.com/mronta/CycleGAN-in-Keras/blob/master/reflection_padding.py\n",
    "    '''\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv GRU Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_block(inp, length, size, flt, scope, train, normalize = True):\n",
    "    '''Bidirectional convolutional GRU block with \n",
    "       zoneout and CSSE blocks in each time step\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): (B, T, H, W, C) layer\n",
    "          length (tf.Variable): (B, T) layer denoting number of\n",
    "                                steps per sample\n",
    "          size (int): kernel size of convolution\n",
    "          flt (int): number of convolution filters\n",
    "          scope (str): tensorflow variable scope\n",
    "          train (tf.Bool): flag to differentiate between train/test ops\n",
    "          normalize (bool): whether to compute layer normalization\n",
    "\n",
    "         Returns:\n",
    "          gru (tf.Variable): (B, H, W, flt*2) bi-gru output\n",
    "          steps (tf.Variable): (B, T, H, W, flt*2) output of each step\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        print(f\"GRU input shape {inp.shape}, zoneout: {ZONE_OUT_PROB}\")\n",
    "\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        \n",
    "        zoneout = ZONE_OUT_PROB\n",
    "        cell_fw = ZoneoutWrapper(\n",
    "           cell_fw, zoneout_drop_prob = zoneout, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = zoneout, is_training = train)\n",
    "        steps, out = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        gru = tf.concat(out, axis = -1)\n",
    "        steps = tf.concat(steps, axis = -1)\n",
    "        print(f\"GRU block output shape {gru.shape}\")\n",
    "    return gru, steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_conv(x, channels, kernel=3, stride=1, use_bias=False, padding='SAME', scope='conv_0'):\n",
    "    \"\"\"Implementation of https://arxiv.org/abs/1804.07723\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        if padding.lower() == 'SAME'.lower() :\n",
    "            with tf.variable_scope('mask'):\n",
    "                _, h, w, _ = x.get_shape().as_list()\n",
    "\n",
    "                slide_window = kernel * kernel\n",
    "                mask = tf.ones(shape=[1, h, w, 1])\n",
    "\n",
    "                update_mask = tf.layers.conv2d(mask, filters=1,\n",
    "                                               kernel_size=kernel,\n",
    "                                               kernel_initializer=tf.constant_initializer(1.0),\n",
    "                                               strides=stride, \n",
    "                                               padding=padding, \n",
    "                                               use_bias=False,\n",
    "                                               trainable=False)\n",
    "\n",
    "                mask_ratio = slide_window / (update_mask + 1e-8)\n",
    "                update_mask = tf.clip_by_value(update_mask, 0.0, 1.0)\n",
    "                mask_ratio = mask_ratio * update_mask\n",
    "\n",
    "            with tf.variable_scope('x'):\n",
    "                x = tf.layers.conv2d(x, filters=channels,\n",
    "                                     kernel_size=kernel, \n",
    "                                     kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                                     strides=stride,\n",
    "                                     padding=padding, \n",
    "                                     use_bias=False)\n",
    "                x = x * mask_ratio\n",
    "\n",
    "                if use_bias:\n",
    "                    bias = tf.get_variable(\"bias\", \n",
    "                                           [channels],\n",
    "                                           initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "                    x = tf.nn.bias_add(x, bias)\n",
    "                    x = x * update_mask\n",
    "\n",
    "        else :\n",
    "            x = tf.layers.conv2d(x, filters=channels,\n",
    "                                 kernel_size=kernel, \n",
    "                                 kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                                 strides=stride,\n",
    "                                 padding=padding,\n",
    "                                 use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "def conv_swish_gn(inp, \n",
    "                 is_training, \n",
    "                 kernel_size,\n",
    "                 scope,\n",
    "                 filters, \n",
    "                 keep_rate,\n",
    "                 stride = (1, 1),\n",
    "                 activation = True,\n",
    "                 use_bias = False,\n",
    "                 norm = True,\n",
    "                 dropblock = True,\n",
    "                 csse = True,\n",
    "                 weight_decay = None,\n",
    "                 block_size = 5,\n",
    "                 padding = \"SAME\",\n",
    "                 partial = True):\n",
    "    '''2D convolution, group normalization, SWISH activation, drop block, SSE. \n",
    "       DropBlock performs best when applied last, according to original paper.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          kernel_size (int): size of convolution\n",
    "          scope (str): tensorflow variable scope\n",
    "          filters (int): number of filters for convolution\n",
    "          keep_rate (float): Keep rate for dropblock\n",
    "          stride (tuple): Conv2D stride parameter\n",
    "          activation (bool): Whether or not to apply Swish activation\n",
    "          use_bias (bool): whether to use bias. Should always be false\n",
    "          norm (bool): whether or not to apply group normalization\n",
    "          dropblock (bool): whether or not to apply dropblock\n",
    "          csse (bool): whether or not to apply SSE block\n",
    "          weight_decay (bool): not currently implemented\n",
    "          block_size (int): Block size for dropblock\n",
    "          padding (str): padding parameter for conv2d\n",
    "          partial (bool): Whether or not to use partial conv or Conv2D\n",
    "\n",
    "         Returns:\n",
    "          conv (tf.Variable): output of the block\n",
    "        \n",
    "         References:\n",
    "          http://papers.nips.cc/paper/8271-dropblock-a-regularization-\n",
    "              method-for-convolutional-networks.pdf\n",
    "          https://arxiv.org/abs/1702.03275\n",
    "          \n",
    "    '''\n",
    "    \n",
    "    gn_flag = \"Group Norm\" if norm else \"\"\n",
    "    activation_flag = \"RELU\" if activation else \"Linear\"\n",
    "    sse_flag = \"SSE\" if csse else \"No SSE\"\n",
    "    bias_flag = \"Bias\" if use_bias else \"NoBias\"\n",
    "    drop_flag = \"DropBlock\" if dropblock else \"NoDrop\"\n",
    "        \n",
    "    print(f\"{Scope} Conv: Kernel: {kernel_size}, {gn_flag}, {activation_flag}, {sse_flag}, {drop_flag}\")\n",
    "\n",
    "    with tf.variable_scope(scope + \"_conv\"):\n",
    "        if not partial:\n",
    "            conv = Conv2D(filters = filters, \n",
    "                          kernel_size = (kernel_size, kernel_size), \n",
    "                          strides = stride,\n",
    "                          activation = None,\n",
    "                          padding = 'valid',\n",
    "                          use_bias = use_bias,\n",
    "                          kernel_initializer = tf.keras.initializers.he_normal()\n",
    "                         )(inp)\n",
    "        if partial:\n",
    "            conv = partial_conv(inp, filters,\n",
    "                                kernel=kernel_size, \n",
    "                                stride=1, \n",
    "                                use_bias=False,\n",
    "                                padding=padding, \n",
    "                                scope = scope)\n",
    "    if activation:\n",
    "        conv = tf.nn.swish(conv)\n",
    "    if norm:\n",
    "        conv = group_norm(x = conv, scope = scope, G = 8)\n",
    "    if csse:\n",
    "        conv = sse_block(conv, \"csse_\" + scope)\n",
    "    if dropblock: \n",
    "        with tf.variable_scope(scope + \"_drop\"):\n",
    "            drop_block = DropBlock2D(keep_prob=keep_rate, block_size= block_size)\n",
    "            conv = drop_block(conv, is_training)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bands = 17\n",
    "\n",
    "reg = tf.contrib.layers.l2_regularizer(L2_REG)\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 13, 28, 28, n_bands))\n",
    "length = tf.placeholder_with_default(np.full((1,), 12), shape = (None,))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 14, 14))#, 1))\n",
    "keep_rate = tf.placeholder_with_default(1.0, ()) # For DropBlock\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training') # For DropBlock\n",
    "alpha = tf.placeholder(tf.float32, shape = ()) # For loss scheduling\n",
    "ft_lr = tf.placeholder_with_default(0.001, shape = ()) # For loss scheduling\n",
    "loss_weight = tf.placeholder_with_default(1.0, shape = ())\n",
    "beta_ = tf.placeholder_with_default(0.0, shape = ()) # For loss scheduling, not currently implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model uses a UNet architecture where the encoder extracts increasingly abstract features and the decoder upsamples the features to the target resolution.\n",
    "\n",
    "The encoder consists of three blocks:\n",
    "\n",
    "- GRU: A bidirectional convolutional GRU with channel squeeze and spatial excitation, and group normalization, extracts 3x3 features from the multitemporal imagery\n",
    "- Conv1: A MaxPool-conv-swish-groupNorm-csse layer takes the output of the GRU (size 28) and reduces to size 12\n",
    "- Conv2: The output of the MaxPool-conv-swish-csse-DropBlock is a 4x4x128 encoded feature map\n",
    "\n",
    "The decoder consists of two blocks:\n",
    "\n",
    "- Upconv1: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Upconv2: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Output sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_flt = 32\n",
    "mid_flt = 32 * 2\n",
    "high_flt = 32 * 2 * 2\n",
    "\n",
    "gru_input = inp[:, :12, ...]\n",
    "gru, steps = gru_block(inp = gru_input, length = length,\n",
    "                            size = [28, 28],\n",
    "                            flt = initial_flt // 2,\n",
    "                            scope = 'down_16',\n",
    "                            train = is_training)\n",
    "with tf.variable_scope(\"gru_drop\"):\n",
    "    drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "    gru = drop_block(gru, is_training)\n",
    "    \n",
    "\n",
    "median_input = inp[:, -1, ...]\n",
    "median_conv = conv_swish_gn(inp = median_input, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_median', filters = initial_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(f\"Median conv: {median_conv.shape}\")\n",
    "\n",
    "concat = tf.concat([gru, median_conv], axis = -1)\n",
    "concat = conv_swish_gn(inp = concat, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_concat', filters = initial_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, padding = \"SAME\")\n",
    "print(f\"Concat: {concat.shape}\")\n",
    "\n",
    "    \n",
    "pool1 = MaxPool2D()(concat)\n",
    "conv1 = conv_swish_gn(inp = pool1, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv1', filters = mid_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(f\"Conv1: {conv1.shape}\")\n",
    "\n",
    "\n",
    "pool2 = MaxPool2D()(conv1)\n",
    "conv2 = conv_swish_gn(inp = pool2, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv2', filters = high_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, block_size = 4, padding = \"VALID\")\n",
    "print(\"Encoded\", conv2.shape)\n",
    "\n",
    "# Decoder\n",
    "up2 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(conv2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2', filters = mid_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "conv1_crop = Cropping2D(2)(conv1)\n",
    "\n",
    "up2 = tf.concat([up2, conv1_crop], -1)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2_out', filters = mid_flt, \n",
    "                    keep_rate =  keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "up3 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(up2)\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up3', filters = initial_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "gru_crop = Cropping2D(6)(concat)\n",
    "up3 = tf.concat([up3, gru_crop], -1)\n",
    "\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'out', filters = initial_flt, \n",
    "                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = False, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "\n",
    "# The output bias is initialized as it is in the Focal loss paper\n",
    "init = tf.constant_initializer([-np.log(0.7/0.3)])\n",
    "print(f\"The output is {up2.shape}, with a receptive field of {1}\")\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1),\n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            bias_initializer = init,\n",
    "           )(up3)\n",
    "\n",
    "print(f\"The output, sigmoid is {fm.shape}, with a receptive field of {1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 329929 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(f\"This model has {total_parameters} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import math\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "def calc_mask(seg):\n",
    "\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "    loss_importance = np.array([x for x in range(0, 197, 1)])\n",
    "    loss_importance = loss_importance / 196\n",
    "    loss_importance = np.expm1(loss_importance)\n",
    "    loss_importance[:30] = 0.\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    res[np.logical_and(res < 2, res > 0)] = 0.5\n",
    "    res[np.logical_or(res >= 2, res <= 0)] = 1.\n",
    "    return res\n",
    "\n",
    "def calc_mask_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    bce_batch = np.array([calc_mask(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "    return bce_batch\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight, mask = True, smooth = 0.03):\n",
    "    '''Calculates the weighted binary cross entropy loss between y_true and\n",
    "       y_pred with optional masking and smoothing for regularization\n",
    "       \n",
    "       For smoothing, we want to weight false positives as less important than\n",
    "       false negatives, so we smooth false negatives 2x as much. \n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          weight (float):\n",
    "          mask (arr):\n",
    "          smooth (float):\n",
    "\n",
    "         Returns:\n",
    "          loss (float):\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    y_true = K.clip(y_true, smooth, 1. - smooth)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true,\n",
    "        logit_y_pred,\n",
    "        weight,\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "\n",
    "    mults = np.ones_like(seg)\n",
    "    ones = np.ones_like(seg)\n",
    "    for x in range(1, res.shape[0] -1 ):\n",
    "        for y in range(1, res.shape[0] - 1):\n",
    "            # If > 1 px distance, double the weight of the positive\n",
    "            # If == 1 px, half the weight of the negative\n",
    "            # This is important because the calc_mask fn\n",
    "            # leaves borders with 0 weight otherwise\n",
    "            if seg[x, y] == 1:\n",
    "                l = seg[x - 1, y]\n",
    "                r = seg[x + 1, y]\n",
    "                u = seg[x, y + 1]\n",
    "                d = seg[x, y - 1]\n",
    "                lu = seg[x - 1, y + 1]\n",
    "                ru = seg[x + 1, y + 1]\n",
    "                rd = seg[x + 1, y - 1]\n",
    "                ld = seg[x -1, y - 1]\n",
    "                \n",
    "                sums = (l + r + u + d)\n",
    "                sums2 = (l + r + u + d + lu + ru +rd + ld)\n",
    "                if sums >= 2:\n",
    "                    mults[x, y] = 2\n",
    "                if sums2 <= 1:\n",
    "                    ones[x - 1, y] = 0.5\n",
    "                    ones[x + 1, y] = 0.5\n",
    "                    ones[x, y + 1] = 0.5\n",
    "                    ones[x, y - 1] = 0.5\n",
    "                    ones[x - 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y - 1] = 0.5\n",
    "                    ones[x -1, y - 1] = 0.5\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "        # When % = 1, 0 -> 1.75\n",
    "        # When % = 100, 0 -> 0\n",
    "        res = np.round(res, 0)\n",
    "        res[np.where(np.isclose(res, -.41421356, rtol = 1e-2))] = -1\n",
    "        res[np.where(res == -1)] = -1 * mults[np.where(res == -1)]\n",
    "        res[np.where(res == 0)] = -1  * mults[np.where(res == 0)]\n",
    "        # When % = 1, 1 -> 0\n",
    "        # When % = 100, 1 -> 1.75\n",
    "        res[np.where(res == 1)] = 1 * ones[np.where(res == 1)]\n",
    "        res[np.where(res == 1)] *= 0.67\n",
    "        \n",
    "    # Empirically capping the loss at -3 to 3 is better\n",
    "    res[np.where(res < -3)] = -3\n",
    "    res[np.where(res > 3)] = 3\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "        res *= -1\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "\n",
    "\n",
    "def surface_loss(y_true, y_pred):\n",
    "    '''Calculates the mean surface loss for the input batch\n",
    "       by multiplying the distance map by y_pred\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "        \n",
    "         References:\n",
    "          https://arxiv.org/abs/1812.07032\n",
    "    '''\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    y_true_dist_map = tf.stack(y_true_dist_map, axis = 0)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    loss = tf.reduce_mean(multipled, axis = (1, 2, 3))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_surface_loss(y_true, y_pred, alpha, weight, beta):\n",
    "    \n",
    "    bce = weighted_bce_loss(y_true = y_true, \n",
    "                             y_pred = y_pred, \n",
    "                             weight = weight,\n",
    "                             smooth = 0.03)\n",
    "\n",
    "    bce = tf.reduce_mean(bce, axis = (1, 2, 3))\n",
    "    surface = surface_loss(y_true, y_pred)\n",
    "    surface = tf.reduce_mean(surface)\n",
    "\n",
    "    bce = tf.reduce_mean(bce)\n",
    "    bce = (1 - alpha) * bce\n",
    "    surface_portion = alpha * surface\n",
    "    result = bce + surface_portion\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_norm(gradients):\n",
    "        norm = tf.compat.v1.norm(\n",
    "            tf.stack([\n",
    "                tf.compat.v1.norm(grad) for grad in gradients if grad is not None\n",
    "            ])\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "\n",
    "print(f\"Starting model with: \\n {ZONE_OUT_PROB} zone out \\n {L2_REG} l2 \\n\"\n",
    "      f\"{INITIAL_LR} initial LR \\n {total_parameters} parameters\")  \n",
    "\n",
    "if FRESH_START:\n",
    "    optimizer = AdaBoundOptimizer(INITIAL_LR, ft_lr)\n",
    "    train_loss = bce_surface_loss(tf.reshape(labels, (-1, 14, 14, 1)), \n",
    "                             fm, weight = loss_weight, \n",
    "                             alpha = alpha, beta = beta_)\n",
    "    l2_loss = tf.losses.get_regularization_loss()\n",
    "    if len(tf.losses.get_regularization_losses()) > 0:\n",
    "        train_loss = train_loss + l2_loss\n",
    "        \n",
    "    ft_optimizer = tf.train.MomentumOptimizer(ft_lr, momentum = 0.8, use_nesterov = True)\n",
    "    test_loss = bce_surface_loss(tf.reshape(labels, (-1, 14, 14, 1)),\n",
    "                            fm, weight = loss_weight, \n",
    "                            alpha = alpha, beta = beta_)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(train_loss)   \n",
    "        ft_op = ft_optimizer.minimize(train_loss)\n",
    "\n",
    "    # The following code blocks are for sharpness aware minimization\n",
    "    # Adapted from https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow\n",
    "    # For tensorflow 1.15\n",
    "    trainable_params = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "    gradient_norm = grad_norm(gradients)\n",
    "    scale = 0.05 / (gradient_norm + 1e-12)\n",
    "    e_ws = []\n",
    "    for (grad, param) in gradients:\n",
    "        e_w = grad * scale\n",
    "        param.assign_add(e_w)\n",
    "        e_ws.append(e_w)\n",
    "\n",
    "    sam_gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "    for (param, e_w) in zip(trainable_params, e_ws):\n",
    "        param.assign_sub(e_w)\n",
    "    train_step = optimizer.apply_gradients(sam_gradients)\n",
    "    \n",
    "    # Create a saver to save the model each epoch\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    saver = tf.train.Saver(max_to_keep = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path  = \"models/rmapper/330k-14000-sept-new/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if os.path.isfile(f\"{model_path}metrics.npy\"):\n",
    "    metrics = np.load(f\"{model_path}metrics.npy\")\n",
    "    print(f\"Loading {model_path}metrics.npy\")\n",
    "else:\n",
    "    print(\"Starting anew\")\n",
    "    metrics = np.zeros((6, 300))\n",
    "\n",
    "if not FRESH_START:\n",
    "    path = model_path + \"110-89-9/\"\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of stochastic weight averaging\n",
    "def initialize_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        \n",
    "# SWA BLOCKS\n",
    "model_vars = tf.trainable_variables()\n",
    "swa = StochasticWeightAveraging()\n",
    "swa_op = swa.apply(var_list=model_vars)\n",
    "with tf.variable_scope('BackupVariables'):\n",
    "    # force tensorflow to keep theese new variables on the CPU ! \n",
    "    backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\n",
    "                                   initializer=var.initialized_value())\n",
    "                   for var in model_vars]\n",
    "\n",
    "# operation to assign SWA weights to model\n",
    "swa_to_weights = tf.group(*(tf.assign(var, swa.average(var).read_value()) for var in model_vars))\n",
    "# operation to store model into backup variables\n",
    "save_weight_backups = tf.group(*(tf.assign(bck, var.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "# operation to get back values from backup variables to model\n",
    "restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "\n",
    "initialize_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "*  Load in CSV data from Collect Earth\n",
    "*  Reconstruct the X, Y grid for the Y data per sample\n",
    "*  Calculate remote sensing indices\n",
    "*  Stack X, Y, length data\n",
    "*  Apply median filter to DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "normalize = False\n",
    "train_x = hkl.load(\"data/train/train_x.hkl\")\n",
    "train_y = hkl.load(\"data/train/train_y.hkl\")\n",
    "data = pd.read_csv(\"data/train/train_plot_ids.csv\")\n",
    "\n",
    "if not isinstance(train_x.flat[0], np.floating):\n",
    "    assert np.max(train_x) > 1\n",
    "    train_x = train_x / 65535.\n",
    "\n",
    "# In our training data, index 11 specified the date of the imagery\n",
    "# Which lead to overfitting, so it is removed here\n",
    "train_x = np.delete(train_x, 11, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(x, min_db):\n",
    "    \"\"\"Converts sigma backscatter to decibel\"\"\"\n",
    "    x = 10 * np.log10(x + 1/65535)\n",
    "    x[x < -min_db] = -min_db\n",
    "    x = x + min_db\n",
    "    x = x / min_db\n",
    "    x = np.clip(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n",
    "\n",
    "\n",
    "def evi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the enhanced vegetation index\n",
    "    2.5 x (08 - 04) / (08 + 6 * 04 - 7.5 * 02 + 1)\n",
    "    '''\n",
    "\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = x[..., 2]\n",
    "    NIR = x[..., 3]\n",
    "    evis = 2.5 * ( (NIR-RED) / (NIR + (6*RED) - (7.5*BLUE) + 1))\n",
    "    evis = np.clip(evis, -1.5, 1.5)\n",
    "    return evis\n",
    "\n",
    "\n",
    "def msavi2(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the modified soil-adjusted vegetation index 2\n",
    "    (2 * NIR + 1 - sqrt((2*NIR + 1)^2 - 8*(NIR-RED)) / 2\n",
    "    '''\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = np.clip(x[..., 2], 0, 1)\n",
    "    NIR = np.clip(x[..., 3], 0, 1)\n",
    "\n",
    "    msavis = (2 * NIR + 1 - np.sqrt( (2*NIR+1)**2 - 8*(NIR-RED) )) / 2\n",
    "    return msavis\n",
    "\n",
    "\n",
    "def bi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    B11 = np.clip(x[..., 8], 0, 1)\n",
    "    B4 = np.clip(x[..., 2], 0, 1)\n",
    "    B8 = np.clip(x[..., 3], 0, 1)\n",
    "    B2 = np.clip(x[..., 0], 0, 1)\n",
    "    bis = ((B11 + B4) - (B8 + B2)) / ((B11 + B4) + (B8 + B2))\n",
    "    return bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[..., -1] = convert_to_db(train_x[..., -1], 22)\n",
    "train_x[..., -2] = convert_to_db(train_x[..., -2], 22)\n",
    "\n",
    "indices = np.empty((train_x.shape[0], 12, 28, 28, 4))\n",
    "indices[..., 0] = evi(train_x)\n",
    "indices[..., 1] = bi(train_x)\n",
    "indices[..., 2] = msavi2(train_x)\n",
    "indices[..., 3] = grndvi(train_x)\n",
    "\n",
    "train_x = np.concatenate([train_x, indices], axis = -1)\n",
    "med = np.median(train_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "train_x = np.concatenate([train_x, med], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_all = [0.006576638437476157, 0.0162050812542916, 0.010040436408026246, 0.013351644159609368, 0.01965362020294499, 0.014229037918669413, 0.015289539940489814, 0.011993591210803388, 0.008239871824216068, 0.006546120393682765, 0.0, 0.0, 0.0, -0.1409399364817101, -0.4973397113668104, -0.09731556326714398, -0.7193834232943873]\n",
    "max_all = [0.2691233691920348, 0.3740291447318227, 0.5171435111009385, 0.6027466239414053, 0.5650263218127718, 0.5747005416952773, 0.5933928435187305, 0.6034943160143434, 0.7472037842374304, 0.7000076295109483, 0.509269855802243, 0.948334642387533, 0.6729257769285485, 0.8177635298774327, 0.35768999002433816, 0.7545951919107605, 0.7602693339366691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in tnrange(0, train_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    train_x[..., band] = np.clip(train_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (train_x[..., band] - midrange) / (rng / 2)\n",
    "    train_x[..., band] = standardized\n",
    "\n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(train_x), np.max(train_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "test_x = hkl.load(\"data/test/test_x.hkl\")\n",
    "test_y = hkl.load(\"data/test/test_y.hkl\")\n",
    "test_data = pd.read_csv(\"data/test/test_plot_ids.csv\")\n",
    "\n",
    "test_x = np.delete(test_x, 11, -1)\n",
    "\n",
    "if not isinstance(test_x.flat[0], np.floating):\n",
    "    assert np.max(test_x) > 1\n",
    "    test_x = test_x / 65535.\n",
    "    \n",
    "test_x[..., -1] = convert_to_db(test_x[..., -1], 22)\n",
    "test_x[..., -2] = convert_to_db(test_x[..., -2], 22)\n",
    "\n",
    "indices = np.empty((test_x.shape[0], 12, 28, 28, 4))\n",
    "indices[..., 0] = evi(test_x)\n",
    "indices[..., 1] = bi(test_x)\n",
    "indices[..., 2] = msavi2(test_x)\n",
    "indices[..., 3] = grndvi(test_x)\n",
    "\n",
    "test_x = np.concatenate([test_x, indices], axis = -1)\n",
    "med = np.median(test_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "test_x = np.concatenate([test_x, med], axis = 1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.min(val) < -1.66]\n",
    "above_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.max(val) > 1.66]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "print(\"There are {} outliers: {}\".format(len(outliers), outliers))\n",
    "print([x for x in test_data['plot_id'].iloc[outliers]])\n",
    "\n",
    "test_x = np.delete(test_x, outliers, 0)\n",
    "test_y = np.delete(test_y, outliers, 0)\n",
    "test_data = test_data.drop(outliers, 0)\n",
    "test_data = test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[..., band] = np.clip(test_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[..., band] - midrange) / (rng / 2)\n",
    "    test_x[..., band] = standardized\n",
    "\n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train and test characteristics:\")\n",
    "print(\"Train mean Y {}\".format(np.mean([np.sum(x) for x in test_y])))\n",
    "print(\"Test STD Y {}\".format(np.std([np.sum(x) for x in test_y])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equibatch creation\n",
    "\n",
    "The modelling approach uses equibatch sampling to ensure that there is a near constant standard deviation of the percent tree cover in the output labels for each batch. This helps ensure that the model performs equally well across gradients of tree cover, by mitigating the random possibility that many batches in a row near the end of sampling may be randomly biased towards a tree cover range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [x for x in range(0, len(train_y))]\n",
    "\n",
    "def multiplot(matrices):\n",
    "    '''Plot multiple heatmaps with subplots\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list of arrays):\n",
    "\n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4)\n",
    "    fig.set_size_inches(20, 4)\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        sns.heatmap(data = matrix, ax = axs[i], vmin = 0, vmax = 0.9)\n",
    "        axs[i].set_xlabel(\"\")\n",
    "        axs[i].set_ylabel(\"\")\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_xticks([])\n",
    "\n",
    "        \n",
    "def equibatch(train_ids, p = percents):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          train_ids (list):\n",
    "          p (list):\n",
    "\n",
    "         Returns:\n",
    "          equibatches (list):\n",
    "    '''\n",
    "\n",
    "    percents = [9.0, 17.0, 27.0, 40.0, 63.0, 105.0, 158.0]\n",
    "\n",
    "    train_ids_cp = (train_ids)\n",
    "    np.random.shuffle(train_ids_cp)\n",
    "    ix = train_ids_cp\n",
    "    percs = [np.sum(x) for x in train_y[ix]]\n",
    "    ids0 = [x for x, z in zip(ix, percs) if z <= 2]\n",
    "    ids30 = [x for x, z in zip(ix, percs) if 2 < z <= percents[0]]\n",
    "    ids40 = [x for x, z in zip(ix, percs) if percents[0] < z <= percents[1]]\n",
    "    ids50 = [x for x, z in zip(ix, percs) if percents[1] < z <= percents[2]]\n",
    "    ids60 = [x for x, z in zip(ix, percs) if percents[2] < z <= percents[3]]\n",
    "    ids70 = [x for x, z in zip(ix, percs) if percents[3] < z <= percents[4]]\n",
    "    ids80 = [x for x, z in zip(ix, percs) if percents[4] < z <= percents[5]]\n",
    "    ids90 = [x for x, z in zip(ix, percs) if percents[5] < z <= percents[6]]\n",
    "    ids100 = [x for x, z in zip(ix, percs) if percents[6] < z]\n",
    "    \n",
    "    new_batches = []\n",
    "    maxes = [len(ids0), len(ids30), len(ids40), len(ids50), len(ids60), len(ids70),\n",
    "             len(ids80), len(ids90), len(ids100)]\n",
    "    print(maxes)\n",
    "    cur_ids = [0] * len(maxes)\n",
    "    iter_len = len(train_ids)//(len(maxes))\n",
    "    for i in range(0, iter_len):\n",
    "        for i, val in enumerate(cur_ids):\n",
    "            if val > maxes[i] - 1:\n",
    "                cur_ids[i] = 0\n",
    "        if cur_ids[0] >= (maxes[0] - 2):\n",
    "            cur_ids[0] = 0\n",
    "        to_append = [ids0[cur_ids[0]],\n",
    "                    ids30[cur_ids[1]], ids40[cur_ids[2]],\n",
    "                    ids50[cur_ids[3]], ids60[cur_ids[4]], \n",
    "                    ids70[cur_ids[5]], ids80[cur_ids[6]],\n",
    "                    ids90[cur_ids[7]], ids100[cur_ids[8]]]\n",
    "        \n",
    "        \n",
    "        np.random.shuffle(to_append)\n",
    "        new_batches.append(to_append)\n",
    "        cur_ids = [x + 1 for x in cur_ids]\n",
    "        \n",
    "    new_batches = [item for sublist in new_batches for item in sublist]\n",
    "    return new_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {'all': [0, 1150]}              \n",
    "            \n",
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calculate_metrics(country, al = 0.4, canopy_thresh = 100):\n",
    "    '''Calculates the following metrics for an input country, based on\n",
    "       indexing of the country dictionary:\n",
    "       \n",
    "         - Loss\n",
    "         - F1\n",
    "         - Precision\n",
    "         - Recall\n",
    "         - Dice\n",
    "         - Mean surface distance\n",
    "         - Average error\n",
    "    \n",
    "         Parameters:\n",
    "          country (str):\n",
    "          al (float):\n",
    "          \n",
    "         Returns:\n",
    "          val_loss (float):\n",
    "          best_dice (float):\n",
    "          error (float):\n",
    "    '''\n",
    "    print(canopy_thresh)\n",
    "    start_idx = 0\n",
    "    stop_idx = len(test_x)\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0\n",
    "    relaxed_f1 = 0\n",
    "    preds = []\n",
    "    vls = []\n",
    "    trues = []\n",
    "    test_ids = [x for x in range(len(test_x))]\n",
    "    for test_sample in test_ids[start_idx:stop_idx]:\n",
    "        if np.sum(test_y[test_sample]) < ((canopy_thresh/100) * 197):\n",
    "            x_input = test_x[test_sample].reshape(1, 13, 28, 28, n_bands)\n",
    "            x_median_input = calc_median_input(x_input)\n",
    "            y, vl = sess.run([fm, test_loss], feed_dict={inp: x_input,\n",
    "                                                          length: np.full((1,), 12),\n",
    "                                                          is_training: False,\n",
    "                                                          labels: test_y[test_sample].reshape(1, 14, 14),\n",
    "                                                          loss_weight: 1.0,\n",
    "                                                          alpha: 0.33,\n",
    "                                                          })\n",
    "            preds.append(y.reshape((14, 14)))\n",
    "            vls.append(vl)\n",
    "            trues.append(test_y[test_sample].reshape((14, 14)))\n",
    "    for thresh in range(7, 9):\n",
    "        tps_relaxed = np.empty((len(preds), ))\n",
    "        fps_relaxed = np.empty((len(preds), ))\n",
    "        fns_relaxed = np.empty((len(preds), ))\n",
    "        abs_error = np.empty((len(preds), ))\n",
    "        \n",
    "        for sample in range(len(preds)):\n",
    "            pred = np.copy(preds[sample])\n",
    "            true = trues[sample]\n",
    "        \n",
    "            pred[np.where(pred >= thresh*0.05)] = 1\n",
    "            pred[np.where(pred < thresh*0.05)] = 0\n",
    "            \n",
    "            true_s = np.sum(true[1:-1])\n",
    "            pred_s = np.sum(pred[1:-1])\n",
    "            abs_error[sample] = abs(true_s - pred_s)\n",
    "            tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "            tps_relaxed[sample] = tp_relaxed\n",
    "            fps_relaxed[sample] = fp_relaxed\n",
    "            fns_relaxed[sample] = fn_relaxed                   \n",
    "            \n",
    "        oa_error = np.mean(abs_error)\n",
    "        precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "        recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "        f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "        \n",
    "        if f1_r > best_f1:\n",
    "            best_f1 = f1_r\n",
    "            p = precision_r\n",
    "            r = recall_r\n",
    "            error = oa_error\n",
    "            best_thresh = thresh*0.05\n",
    "\n",
    "    print(f\"{country}: Val loss: {np.around(np.mean(vls), 3)}\"\n",
    "          f\" Thresh: {np.around(best_thresh, 2)}\"\n",
    "          f\" F1: {np.around(best_f1, 3)} R: {np.around(p, 3)} P: {np.around(r, 3)}\"\n",
    "          f\" Error: {np.around(error, 3)}\")\n",
    "    return np.mean(vls), best_f1, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block implements cut mix where random samples are spliced together where the output labels have similar tree cover distributions (within the same kmeans cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "x_med = np.median(train_x, axis = (1, 2, 3))\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(x_med)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "def fftIndgen(n):\n",
    "    a = range(0, n//2+1)\n",
    "    b = range(1, n//2)\n",
    "    b = [x for x in b]\n",
    "    b.reverse()\n",
    "    a = [x for x in a]\n",
    "   \n",
    "    b = [-i for i in b]\n",
    "    return a + b\n",
    "\n",
    "def gaussian_random_field(Pk = lambda k : k**-3.0, size = 100):\n",
    "    def Pk2(kx, ky):\n",
    "        if kx == 0 and ky == 0:\n",
    "            return 0.0\n",
    "        return np.sqrt(Pk(np.sqrt(kx**2 + ky**2)))\n",
    "    noise = np.fft.fft2(np.random.normal(size = (size, size)))\n",
    "    amplitude = np.zeros((size,size))\n",
    "    for i, kx in enumerate(fftIndgen(size)):\n",
    "        for j, ky in enumerate(fftIndgen(size)):            \n",
    "            amplitude[i, j] = Pk2(kx, ky)\n",
    "    return np.fft.ifft2(noise * amplitude).astype(np.float32)\n",
    "\n",
    "def make_aug_masks(n, perc):\n",
    "    masks = np.zeros((n, 24, 24))\n",
    "    for i in range(n):\n",
    "        gas = gaussian_random_field(Pk = lambda k: k**-5, size=24)\n",
    "        percentile = np.clip(np.random.normal(perc, 0.1, 1), 0, 1)\n",
    "        percentile = np.percentile(gas, percentile * 100)\n",
    "        gas = gas <= percentile\n",
    "        masks[i] = gas\n",
    "    return masks\n",
    "\n",
    "\n",
    "def cut_mix(x_batch, y_batch, ids, percent, batch_size, cluster = clusters):\n",
    "    \n",
    "    train_ids = [x for x in range(len(train_x))]\n",
    "    cl_batch = clusters[ids]\n",
    "    \n",
    "    binary_mask = np.random.rand(batch_size)\n",
    "    binary_mask = (binary_mask <= 0.25).astype(np.int)\n",
    "    \n",
    "    masks_x = make_aug_masks(batch_size, .33)\n",
    "    masks_y = masks_x[:, 5:-5, 5:-5]\n",
    "    masks_x = np.broadcast_to(\n",
    "        masks_x[:, np.newaxis, :, :, np.newaxis], (batch_size, 13, 24, 24, 17))\n",
    "    \n",
    "    i = 0\n",
    "    for x, y, cluster, mask in zip(x_batch, y_batch, cl_batch, binary_mask):\n",
    "        if mask == 1:\n",
    "            random_id = np.random.choice(clusters[clusters == cluster])\n",
    "            x_random = train_x[random_id]\n",
    "            y_random = train_y[random_id]\n",
    "\n",
    "            x[masks_x[i] == 1] = x_random[masks_x[i] == 1]\n",
    "            y[masks_y[i] == 1] = y_random[masks_y[i] == 1]\n",
    "            i += 1\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_batch(batch_ids, batch_size):\n",
    "    '''Performs random flips and rotations of the X and Y\n",
    "       data, cut mix, and random splicing of the temporal data\n",
    "    \n",
    "         Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    x = train_x[batch_ids]\n",
    "    samples_to_median = np.random.randint(0, 12, size=(batch_size, 6))\n",
    "    n_samples = np.random.randint(2, 7, size=(batch_size))\n",
    "    for samp in range(batch_size):\n",
    "        samps = samples_to_median[samp, :np.random.randint(2, 6)]\n",
    "        lower_samp = np.min(samps)\n",
    "        upper_samp = np.max(samps)\n",
    "        med_samp = np.median(x[samp, samps], axis = 0)\n",
    "        \n",
    "        x[samp, :lower_samp] = x[samp, lower_samp]\n",
    "        x[samp, upper_samp:] = x[samp, upper_samp]\n",
    "        x[samp, -1, ...] = med_samp\n",
    "        \n",
    "    y = train_y[batch_ids]\n",
    "    x_batch = np.zeros_like(x)\n",
    "    y_batch = np.zeros_like(y)\n",
    "    \n",
    "    flips = np.random.choice(np.array([0, 1, 2, 3]), batch_size, replace = True)\n",
    "    for i in range(x.shape[0]):\n",
    "        current_flip = flips[i]\n",
    "        if current_flip == 0:\n",
    "            x_batch[i] = x[i]\n",
    "            y_batch[i] = y[i]\n",
    "        if current_flip == 1:\n",
    "            x_batch[i] = np.flip(x[i], 1)\n",
    "            y_batch[i] = np.flip(y[i], 0)\n",
    "        if current_flip == 2:\n",
    "            x_batch[i] = np.flip(x[i], [2, 1])\n",
    "            y_batch[i] = np.flip(y[i], [1, 0])\n",
    "        if current_flip == 3:\n",
    "            x_batch[i] = np.flip(x[i], 2)\n",
    "            y_batch[i] = np.flip(y[i], 1)\n",
    "\n",
    "    y_batch = y_batch.reshape((batch_size, 14, 14))\n",
    "    x_batch, y_batch = cut_mix(x_batch, y_batch, batch_ids, 0.5, batch_size)\n",
    "    return x_batch, y_batch\n",
    "\n",
    "x_batch_test, y_batch_test = augment_batch([x for x in range(32)], 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 85\n",
    "f, ((c1r1, c1r2), (c2r1, c2r2)) = plt.subplots(2, 2, sharey=False)\n",
    "f.set_size_inches(15, 12)\n",
    "\n",
    "c1r1.set_title(f\"Train loss - {model_path}\")\n",
    "l1 = sns.scatterplot(y = metrics[0, start:end], x = np.arange(start, end), ax = c1r1)\n",
    "l1.set(ylim=(0.130, .145))\n",
    "\n",
    "c1r2.set_title(\"F1 score\")\n",
    "f =sns.scatterplot(y = metrics[5, start:end], x = np.arange(start, end), ax = c1r2)\n",
    "f.set(ylim=(0.84, .91))\n",
    "\n",
    "c2r1.set_title(\"Test loss\")\n",
    "l = sns.scatterplot(y = metrics[1, start:end], x = np.arange(start, end), ax = c2r1)\n",
    "l.set(ylim=(0.140, .165)) \n",
    "\n",
    "c2r2.set_title(\"Absolute % error\")\n",
    "e = sns.scatterplot(y = metrics[2, start:end] / 2, x = np.arange(start, end), ax = c2r2)\n",
    "e.set(ylim=(2.2, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "best_val = 0.72\n",
    "fine_tune = False\n",
    "countries['all'] = [0, len(test_x)]\n",
    "ft_epochs = 0\n",
    "\n",
    "SWA = True\n",
    "\n",
    "for i in range(1, 140):\n",
    "    al = np.min( [0.01 * (i - 1), 0.33] )\n",
    "    ft_learning_rate = .02\n",
    "    be = 0.0\n",
    "    test_al = al\n",
    "    if fine_tune == True:\n",
    "        op = ft_op\n",
    "        print(f\"FINE TUNING WITH {ft_learning_rate} LR\")\n",
    "    else:\n",
    "        op = train_op\n",
    "        \n",
    "    train_ids = [x for x in range(len(train_y))]\n",
    "    randomize = equibatch(train_ids)\n",
    "    print(f\"starting epoch {i}, alpha: {al}, beta: {be} drop: {np.max(((1. - (i * 0.005)), 0.9))}\"\n",
    "         f\" Learning rate: {ft_learning_rate}\")\n",
    "    \n",
    "    loss = train_loss\n",
    "    BATCH_SIZE = 32\n",
    "    test_ids = [x for x in range(0, len(test_x))]\n",
    "    losses = []\n",
    "    \n",
    "    for k in tqdm.notebook.tnrange(int(len(randomize) // BATCH_SIZE)):\n",
    "        batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "        x_batch, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "        opt, tr = sess.run([train_step, loss],\n",
    "                          feed_dict={inp: x_batch,\n",
    "                                     length: np.full((BATCH_SIZE,), 12),\n",
    "                                     labels: y_batch,\n",
    "                                     is_training: True,\n",
    "                                     loss_weight: 1.0,\n",
    "                                     keep_rate: np.max(((1. - (i * 0.005)), 0.9)),\n",
    "                                     alpha: al,\n",
    "                                     beta_: be,\n",
    "                                     ft_lr: ft_learning_rate,\n",
    "                                     })\n",
    "        losses.append(tr)\n",
    "    \n",
    "    print(f\"Epoch {i}: Loss {np.around(np.mean(losses[:-1]), 3)}\")\n",
    "    if SWA:\n",
    "        sess.run(swa_op)\n",
    "        sess.run(save_weight_backups)\n",
    "        sess.run(swa_to_weights)\n",
    "        \n",
    "    metrics[0, i] = np.mean(losses[:-1])\n",
    "    val_loss, f1, error = calculate_metrics('all', al = test_al, canopy_thresh = 75)\n",
    "    metrics[1, i] = val_loss\n",
    "    metrics[2, i] = error\n",
    "    metrics[5, i] = f1\n",
    "    \n",
    "    if f1 < (best_val - 0.002):\n",
    "        ft_epochs += 1\n",
    "        \n",
    "    if f1 > (best_val - 0.02):\n",
    "        print(f\"Saving model with {f1}\")\n",
    "        np.save(f\"{model_path}metrics.npy\", metrics)\n",
    "        os.mkdir(f\"{model_path}{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/\")\n",
    "        save_path = saver.save(sess, f\"{model_path}/{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/model\")\n",
    "        if f1 > best_val:\n",
    "            best_val = f1\n",
    "    if SWA:\n",
    "        sess.run(restore_weight_backups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list):\n",
    "          nrows (int):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(18, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9, cbar = False)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5789473684210527\n",
      "[array([569]), array([592]), array([595]), array([679]), array([745]), array([760]), array([914]), array([925])]\n",
      "[569] (-7.791302406846306, 35.75990311) 56.0\n",
      "[592] (19.493803419640034, -101.49773039999997) 55.0\n",
      "[595] (14.819488899717035, -88.84684396) 44.0\n",
      "[679] (-10.805307259789279, -39.36969121) 41.0\n",
      "[745] (10.946778349786637, -6.522180084999999) 73.0\n",
      "[760] (9.717757138809617, -72.42657236000002) 53.0\n",
      "[914] (7.842697145845316, 37.06221983) 53.0\n",
      "[925] (19.190617529644737, -70.20175089) 53.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(start/len(test_ids))\n",
    "test_ids = [x for x in range(test_x.shape[0])]\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = test_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    median_input = calc_median_input(x_input)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  #inp_median: median_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    print(i, (list(test_data.iloc[idx, 1])[0], list(test_data.iloc[idx, 2])[0]), diffs[i[0]])\n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    true = test_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "\n",
    "start = start + 8 \n",
    "\n",
    "# 123, 334, 680, 875, 917, 950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14286, 14287, 14288, 14289, 14290, 14291, 14292, 14293]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ids = [x for x in range(train_x.shape[0])]\n",
    "start = len(train_ids) - 100\n",
    "\n",
    "matrix_ids = [train_ids[start], train_ids[start + 1], train_ids[start + 2],\n",
    "             train_ids[start + 3], train_ids[start + 4],\n",
    "             train_ids[start + 5], train_ids[start + 6], train_ids[start + 7]]\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = train_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                    })\n",
    "    y = np.array(y).reshape(14, 14)    \n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "    \n",
    "start += 8\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
