{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree segmentation with multitemporal Sentinel 1/2 imagery\n",
    "\n",
    "## John Brandt\n",
    "## July 13 2021\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains the TensorFlow model training and prediction used to segment trees for [Restoration Mapper](https://restorationmapper.org). The notebook uses tensorflow 1.15.5 and additionally relies on Keras 2.2.4\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Package loading\n",
    "- Utility scripts\n",
    "- Hyperparameter definitions\n",
    "- Custom tensorflow layer functions\n",
    "- Tensorflow graph creation\n",
    "- Data loading\n",
    "- Data preprocessing\n",
    "- Equibatch creation\n",
    "- Loss definition\n",
    "- Tensorflow graph initialization\n",
    "- Training\n",
    "- Model validation\n",
    "- Sanity Checks\n",
    "\n",
    "## Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.keras.layers import Conv2D, Lambda, Dense, Multiply, Add\n",
    "from tensorflow.initializers import glorot_normal, lecun_normal\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "from tensorflow.python.util import deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/Documents/GitHub/sentinel-tree-cover/src/layers/convgru.py:27: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../src/layers/zoneout.py\n",
    "%run ../src/layers/adabound.py\n",
    "%run ../src/layers/convgru.py\n",
    "%run ../src/layers/dropblock.py\n",
    "%run ../src/layers/extra_layers.py\n",
    "%run ../src/layers/stochastic_weight_averaging.py\n",
    "%run ../src/preprocessing/indices.py\n",
    "%run ../src/preprocessing/slope.py\n",
    "%run ../src/models/metrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONE_OUT_PROB = 0.8\n",
    "DROPBLOCK_MAXSIZE = 4\n",
    "FINAL_ALPHA = 0.33\n",
    "LABEL_SMOOTHING = 0.03\n",
    "L2_REG = 5e-4\n",
    "MAX_DROPBLOCK = 0.95\n",
    "FRESH_START = True\n",
    "START_EPOCH = 1\n",
    "END_EPOCH = 100\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layer definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility blocks (Batch norm, cSSE, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cse_block(prevlayer, prefix):\n",
    "    '''Channel excitation and spatial squeeze layer. \n",
    "       Calculates the mean of the spatial dimensions and then learns\n",
    "       two dense layers, one with relu, and one with sigmoid, to rerank the\n",
    "       input channels\n",
    "       \n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the cse_block\n",
    "    '''\n",
    "    mean = Lambda(lambda xin: K.mean(xin, axis=[1, 2]))(prevlayer)\n",
    "    lin1 = Dense(K.int_shape(prevlayer)[3] // 2, name=prefix + 'cse_lin1', activation='relu')(mean)\n",
    "    lin2 = Dense(K.int_shape(prevlayer)[3], name=prefix + 'cse_lin2', activation='sigmoid')(lin1)\n",
    "    x = Multiply()([prevlayer, lin2])\n",
    "    return x\n",
    "\n",
    "\n",
    "def sse_block(prevlayer, prefix):\n",
    "    '''Spatial excitation and channel squeeze layer.\n",
    "       Calculates a 1x1 convolution with sigmoid activation to create a \n",
    "       spatial map that is multiplied by the input layer\n",
    "\n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the sse_block\n",
    "    '''\n",
    "    conv = Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "def csse_block(x, prefix):\n",
    "    '''Implementation of Concurrent Spatial and Channel \n",
    "       ‘Squeeze & Excitation’ in Fully Convolutional Networks\n",
    "    \n",
    "        Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): added output of cse and sse block\n",
    "          \n",
    "         References:\n",
    "          https://arxiv.org/abs/1803.02579\n",
    "    '''\n",
    "    #cse = cse_block(x, prefix)\n",
    "    sse = sse_block(x, prefix)\n",
    "    #x = Add(name=prefix + \"_csse_mul\")([cse, sse])\n",
    "    return sse\n",
    "\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        print(\"ZERO PADDING\")\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv GRU Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_block(inp, length, size, flt, scope, train, normalize = True):\n",
    "    '''Bidirectional convolutional GRU block with \n",
    "       zoneout and CSSE blocks in each time step\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): (B, T, H, W, C) layer\n",
    "          length (tf.Variable): (B, T) layer denoting number of\n",
    "                                steps per sample\n",
    "          size (int): kernel size of convolution\n",
    "          flt (int): number of convolution filters\n",
    "          scope (str): tensorflow variable scope\n",
    "          train (tf.Bool): flag to differentiate between train/test ops\n",
    "          normalize (bool): whether to compute layer normalization\n",
    "\n",
    "         Returns:\n",
    "          gru (tf.Variable): (B, H, W, flt*2) bi-gru output\n",
    "          steps (tf.Variable): (B, T, H, W, flt*2) output of each step\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        print(f\"GRU input shape {inp.shape}, zoneout: {0.1}\")\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        \n",
    "        cell_fw = ZoneoutWrapper(\n",
    "           cell_fw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        print(inp.shape)\n",
    "        steps, out = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        print(f\"Zoneout: {ZONE_OUT_PROB}\")\n",
    "        gru = tf.concat(out, axis = -1)\n",
    "        steps = tf.concat(steps, axis = -1)\n",
    "        print(f\"Down block output shape {gru.shape}\")\n",
    "    return gru, steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_swish_gn(inp, \n",
    "                 is_training, \n",
    "                 kernel_size,\n",
    "                 scope,\n",
    "                 filters, \n",
    "                 keep_rate,\n",
    "                 stride = (1, 1),\n",
    "                 activation = True,\n",
    "                 use_bias = False,\n",
    "                 norm = True,\n",
    "                 dropblock = True,\n",
    "                 csse = True,\n",
    "                 weight_decay = None,\n",
    "                 block_size = 5,\n",
    "                 padding = \"SAME\"):\n",
    "    '''2D convolution, batch renorm, relu block, 3x3 drop block. \n",
    "       Use_bias must be set to False for batch normalization to work. \n",
    "       He normal initialization is used with batch normalization.\n",
    "       RELU is better applied after the batch norm.\n",
    "       DropBlock performs best when applied last, according to original paper.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          kernel_size (int): size of convolution\n",
    "          scope (str): tensorflow variable scope\n",
    "          filters (int): number of filters for convolution\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "          activation (bool): whether to apply RELU\n",
    "          use_bias (str): whether to use bias. Should always be false\n",
    "\n",
    "         Returns:\n",
    "          bn (tf.Variable): output of Conv2D -> Batch Norm -> RELU\n",
    "        \n",
    "         References:\n",
    "          http://papers.nips.cc/paper/8271-dropblock-a-regularization-\n",
    "              method-for-convolutional-networks.pdf\n",
    "          https://arxiv.org/abs/1702.03275\n",
    "          \n",
    "    '''\n",
    "    bn_flag = \"Group Norm\" if norm else \"\"\n",
    "    activation_flag = \"RELU\" if activation else \"Linear\"\n",
    "    csse_flag = \"CSSE\" if csse else \"No CSSE\"\n",
    "    bias_flag = \"Bias\" if use_bias else \"NoBias\"\n",
    "    drop_flag = \"DropBlock\" if dropblock else \"NoDrop\"\n",
    "    print(f\"{scope} {kernel_size} Conv 2D {bn_flag} {activation_flag} {csse_flag} {bias_flag} {drop_flag}\")\n",
    "    \n",
    "    with tf.variable_scope(scope + \"_conv\"):\n",
    "        conv = Conv2D(filters = filters, kernel_size = (kernel_size, kernel_size),  strides = stride,\n",
    "                      activation = None, padding = 'valid', use_bias = use_bias,\n",
    "                      kernel_initializer = tf.keras.initializers.he_normal())(inp)\n",
    "    if activation:\n",
    "        conv = tf.nn.swish(conv)\n",
    "    if norm:\n",
    "        conv = group_norm(x = conv, scope = scope, G = 8)\n",
    "    if csse:\n",
    "        conv = csse_block(conv, \"csse_\" + scope)\n",
    "    if dropblock: \n",
    "        with tf.variable_scope(scope + \"_drop\"):\n",
    "            drop_block = DropBlock2D(keep_prob=keep_rate, block_size= block_size)\n",
    "            conv = drop_block(conv, is_training)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "n_bands = 17\n",
    "reg = tf.contrib.layers.l2_regularizer(0.)\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 13, 28, 28, n_bands))\n",
    "length = tf.placeholder_with_default(np.full((1,), 12), shape = (None,))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 14, 14))#, 1))\n",
    "keep_rate = tf.placeholder_with_default(1.0, ()) # For DropBlock\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training') # For BN, DropBlock\n",
    "alpha = tf.placeholder(tf.float32, shape = ()) # For loss scheduling\n",
    "ft_lr = tf.placeholder_with_default(0.001, shape = ()) # For loss scheduling\n",
    "loss_weight = tf.placeholder_with_default(1.0, shape = ())\n",
    "beta_ = tf.placeholder_with_default(0.0, shape = ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model uses a UNet architecture where the encoder extracts increasingly abstract features and the decoder upsamples the features to the target resolution.\n",
    "\n",
    "The encoder consists of three blocks:\n",
    "\n",
    "- GRU: A bidirectional convolutional GRU with channel squeeze and spatial excitation, and group normalization, extracts 3x3 features from the multitemporal imagery\n",
    "- Conv1: A MaxPool-conv-swish-groupNorm-sse layer takes the output of the GRU (size 28) and reduces to size 12\n",
    "- Conv2: The output of the MaxPool-conv-swish-csse-DropBlock is a 4x4x128 encoded feature map\n",
    "\n",
    "The decoder consists of two blocks:\n",
    "\n",
    "- Upconv1: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Upconv2: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Output sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU input shape (?, 12, 28, 28, 17), zoneout: 0.1\n",
      "(?, 12, 28, 28, 17)\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "(3, 3, 33, 32)\n",
      "(3, 3, 33, 32)\n",
      "Zoneout: 0.8\n",
      "Down block output shape (?, 28, 28, 32)\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "ZERO PADDING\n",
      "conv_median 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Median conv: (?, 28, 28, 32)\n",
      "ZERO PADDING\n",
      "conv_concat 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Concat: (?, 28, 28, 32)\n",
      "conv1 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Conv1: (?, 12, 12, 64)\n",
      "conv2 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "Encoded (?, 4, 4, 128)\n",
      "ZERO PADDING\n",
      "up2 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "ZERO PADDING\n",
      "up2_out 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "ZERO PADDING\n",
      "up3 3 Conv 2D Group Norm RELU CSSE NoBias DropBlock\n",
      "out 3 Conv 2D Group Norm RELU CSSE NoBias NoDrop\n",
      "The output is (?, 8, 8, 64), with a receptive field of 1\n",
      "The output, sigmoid is (?, 14, 14, 1), with a receptive field of 1\n"
     ]
    }
   ],
   "source": [
    "initial_flt = 32\n",
    "mid_flt = 32 * 2\n",
    "high_flt = 32 * 2 * 2\n",
    "\n",
    "gru_input = inp[:, :12, ...]\n",
    "gru, steps = gru_block(inp = gru_input, length = length,\n",
    "                            size = [28, 28],\n",
    "                            flt = initial_flt // 2,\n",
    "                            scope = 'down_16',\n",
    "                            train = is_training)\n",
    "with tf.variable_scope(\"gru_drop\"):\n",
    "    drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "    gru = drop_block(gru, is_training)\n",
    "    \n",
    "# Median conv\n",
    "median_input = inp[:, -1, ...]\n",
    "median_input = ReflectionPadding2D((1, 1,))(median_input)\n",
    "median_conv = conv_swish_gn(inp = median_input, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_median', filters = initial_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(f\"Median conv: {median_conv.shape}\")\n",
    "\n",
    "concat = tf.concat([gru, median_conv], axis = -1)\n",
    "concat = ReflectionPadding2D((1, 1,))(concat)\n",
    "concat = conv_swish_gn(inp = concat, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_concat', filters = initial_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, padding = \"VALID\")\n",
    "print(f\"Concat: {concat.shape}\")\n",
    "\n",
    "# MaxPool-conv-swish-GroupNorm-csse\n",
    "pool1 = MaxPool2D()(concat)\n",
    "conv1 = conv_swish_gn(inp = pool1, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv1', filters = mid_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(f\"Conv1: {conv1.shape}\")\n",
    "\n",
    "# MaxPool-conv-swish-csse-DropBlock\n",
    "pool2 = MaxPool2D()(conv1)\n",
    "conv2 = conv_swish_gn(inp = pool2, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv2', filters = high_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, block_size = 4, padding = \"VALID\")\n",
    "print(\"Encoded\", conv2.shape)\n",
    "\n",
    "# Decoder 4 - 8, upsample-conv-swish-csse-concat-conv-swish\n",
    "up2 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(conv2)\n",
    "up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2', filters = mid_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "conv1_crop = Cropping2D(2)(conv1)\n",
    "\n",
    "up2 = tf.concat([up2, conv1_crop], -1)\n",
    "up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2_out', filters = mid_flt, \n",
    "                    keep_rate =  keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "# Decoder 8 - 14 upsample-conv-swish-csse-concat-conv-swish\n",
    "up3 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(up2)\n",
    "up3 = ReflectionPadding2D((1, 1,))(up3)\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up3', filters = initial_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "gru_crop = Cropping2D(6)(concat)\n",
    "up3 = tf.concat([up3, gru_crop], -1)\n",
    "\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'out', filters = initial_flt, \n",
    "                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = False, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "init = tf.constant_initializer([-np.log(0.7/0.3)]) # For focal loss\n",
    "print(f\"The output is {up2.shape}, with a receptive field of {1}\")\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1),\n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            bias_initializer = init,\n",
    "           )(up3) # For focal loss\n",
    "print(f\"The output, sigmoid is {fm.shape}, with a receptive field of {1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 329929 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(f\"This model has {total_parameters} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import math\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight, mask = True, smooth = LABEL_SMOOTHING):\n",
    "    '''Calculates the weighted binary cross entropy loss between y_true and\n",
    "       y_pred with optional masking and smoothing for regularization\n",
    "       \n",
    "       For smoothing, we want to weight false positives as less important than\n",
    "       false negatives, so we smooth false negatives 2x as much. \n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          weight (float):\n",
    "          mask (arr):\n",
    "          smooth (float):\n",
    "\n",
    "         Returns:\n",
    "          loss (float):\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    y_true = K.clip(y_true, smooth, 1. - smooth)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true,\n",
    "        logit_y_pred,\n",
    "        weight,\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "    \"\"\"\n",
    "    Utility function for calc_dist_map_batch that calculates the loss\n",
    "    importance per pixel based on the surface distance function\n",
    "    \n",
    "     Parameters:\n",
    "       seg (arr):\n",
    "  \n",
    "     Returns:\n",
    "       res (arr):\n",
    "    \"\"\"\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "\n",
    "    mults = np.ones_like(seg)\n",
    "    ones = np.ones_like(seg)\n",
    "    for x in range(1, res.shape[0] -1 ):\n",
    "        for y in range(1, res.shape[0] - 1):\n",
    "            # If > 1 px, double the weight of the positive\n",
    "            # If == 1 px, half the weight of the negative\n",
    "            if seg[x, y] == 1:\n",
    "                l = seg[x - 1, y]\n",
    "                r = seg[x + 1, y]\n",
    "                u = seg[x, y + 1]\n",
    "                d = seg[x, y - 1]\n",
    "                lu = seg[x - 1, y + 1]\n",
    "                ru = seg[x + 1, y + 1]\n",
    "                rd = seg[x + 1, y - 1]\n",
    "                ld = seg[x -1, y - 1]\n",
    "                \n",
    "                sums = (l + r + u + d)\n",
    "                sums2 = (l + r + u + d + lu + ru +rd + ld)\n",
    "                if sums >= 2:\n",
    "                    mults[x, y] = 2\n",
    "                if sums2 <= 1:\n",
    "                    ones[x - 1, y] = 0.5\n",
    "                    ones[x + 1, y] = 0.5\n",
    "                    ones[x, y + 1] = 0.5\n",
    "                    ones[x, y - 1] = 0.5\n",
    "                    ones[x - 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y - 1] = 0.5\n",
    "                    ones[x -1, y - 1] = 0.5\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "        # When % = 1, 0 -> 1.75\n",
    "        # When % = 100, 0 -> 0\n",
    "        res = np.round(res, 0)\n",
    "        res[np.where(np.isclose(res, -.41421356, rtol = 1e-2))] = -1\n",
    "        res[np.where(res == -1)] = -1 * mults[np.where(res == -1)]\n",
    "        res[np.where(res == 0)] = -1  * mults[np.where(res == 0)]\n",
    "        # When % = 1, 1 -> 0\n",
    "        # When % = 100, 1 -> 1.75\n",
    "        res[np.where(res == 1)] = 1 * ones[np.where(res == 1)]\n",
    "        res[np.where(res == 1)] *= 0.67\n",
    "        #res[np.where(np.isclose(res, 1.41421356, rtol = 1e-2))] = loss_importance[sums]\n",
    "        \n",
    "    res[np.where(res < -3)] = -3\n",
    "    res[np.where(res > 3)] = 3\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "        res *= -1\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "\n",
    "\n",
    "def surface_loss(y_true, y_pred):\n",
    "    '''Calculates the mean surface loss for the input batch\n",
    "       by multiplying the distance map by y_pred\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "        \n",
    "         References:\n",
    "          https://arxiv.org/abs/1812.07032\n",
    "    '''\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    y_true_dist_map = tf.stack(y_true_dist_map, axis = 0)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    loss = tf.reduce_mean(multipled, axis = (1, 2, 3))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_surface(y_true, y_pred, alpha, weight, beta):\n",
    "    bce = weighted_bce_loss(y_true = y_true, \n",
    "                             y_pred = y_pred, \n",
    "                             weight = weight,\n",
    "                             smooth = 0.03)\n",
    "\n",
    "    bce = tf.reduce_mean(bce, axis = (1, 2, 3))\n",
    "    surface = surface_loss(y_true, y_pred)\n",
    "    surface = tf.reduce_mean(surface)\n",
    "    \n",
    "    bce = tf.reduce_mean(bce)\n",
    "    bce = (1 - alpha) * bce\n",
    "    surface_portion = alpha * surface\n",
    "\n",
    "    result = bce + surface_portion\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../src/layers/adabound.py\n",
    "def grad_norm(gradients):\n",
    "        norm = tf.norm(\n",
    "            tf.stack([\n",
    "                tf.norm(grad) for grad in gradients if grad is not None\n",
    "            ])\n",
    "        )\n",
    "        return norm\n",
    "    \n",
    "\n",
    "optimizer = AdaBoundOptimizer(1e-3, ft_lr)\n",
    "train_loss = bce_surface(tf.reshape(labels, (-1, 14, 14, 1)), \n",
    "                         fm, weight = loss_weight, \n",
    "                         alpha = alpha, beta = beta_)\n",
    "l2_loss = tf.losses.get_regularization_loss()\n",
    "if len(tf.losses.get_regularization_losses()) > 0:\n",
    "    print(\"Adding L2 loss\")\n",
    "    train_loss = train_loss + l2_loss\n",
    "\n",
    "test_loss = bce_surface(tf.reshape(labels, (-1, 14, 14, 1)),\n",
    "                        fm, weight = loss_weight, \n",
    "                        alpha = alpha, beta = beta_)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = optimizer.minimize(train_loss)   \n",
    "\n",
    "trainable_params = tf.trainable_variables()\n",
    "gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "gradient_norm = grad_norm(gradients)\n",
    "scale = 0.05 / (gradient_norm + 1e-12)\n",
    "e_ws = []\n",
    "for (grad, param) in gradients:\n",
    "    e_w = grad * scale\n",
    "    param.assign_add(e_w)\n",
    "    e_ws.append(e_w)\n",
    "\n",
    "sam_gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "for (param, e_w) in zip(trainable_params, e_ws):\n",
    "    param.assign_sub(e_w)\n",
    "train_step = optimizer.apply_gradients(sam_gradients)\n",
    "\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "saver = tf.train.Saver(max_to_keep = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting anew\n",
      "INFO:tensorflow:Restoring parameters from ../models/small-temporal/model\n"
     ]
    }
   ],
   "source": [
    "model_path  = \"../models/small-temporal/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if os.path.isfile(f\"{model_path}metrics.npy\"):\n",
    "    metrics = np.load(f\"{model_path}metrics.npy\")\n",
    "    print(f\"Loading {model_path}metrics.npy\")\n",
    "else:\n",
    "    print(\"Starting anew\")\n",
    "    metrics = np.zeros((6, 300))\n",
    "\n",
    "path = model_path\n",
    "saver.restore(sess, tf.train.latest_checkpoint(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        \n",
    "        \n",
    "# SWA BLOCKS\n",
    "model_vars = tf.trainable_variables()\n",
    "swa = StochasticWeightAveraging()\n",
    "swa_op = swa.apply(var_list=model_vars)\n",
    "with tf.variable_scope('BackupVariables'):\n",
    "    # force tensorflow to keep theese new variables on the CPU ! \n",
    "    backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\n",
    "                                   initializer=var.initialized_value())\n",
    "                   for var in model_vars]\n",
    "\n",
    "swa_to_weights = tf.group(*(tf.assign(var, swa.average(var).read_value()) for var in model_vars))\n",
    "save_weight_backups = tf.group(*(tf.assign(bck, var.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "\n",
    "initialize_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "*  Load in CSV data from Collect Earth\n",
    "*  Reconstruct the X, Y grid for the Y data per sample\n",
    "*  Calculate indices\n",
    "*  Stack X, Y, length data\n",
    "*  Apply median filter to DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "normalize = False\n",
    "train_x = hkl.load(\"../data/train/train_x.hkl\")\n",
    "train_y = hkl.load(\"../data/train/train_y.hkl\")\n",
    "data = pd.read_csv(\"../data/train/train_plot_ids.csv\")\n",
    "\n",
    "if not isinstance(train_x.flat[0], np.floating):\n",
    "    assert np.max(train_x) > 1\n",
    "    train_x = train_x / 65535.\n",
    "    \n",
    "train_x = np.delete(train_x, 11, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(x, min_db):\n",
    "    x = 10 * np.log10(x + 1/65535)\n",
    "    x[x < -min_db] = -min_db\n",
    "    x = x + min_db\n",
    "    x = x / min_db\n",
    "    x = np.clip(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n",
    "\n",
    "\n",
    "def evi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the enhanced vegetation index\n",
    "    2.5 x (08 - 04) / (08 + 6 * 04 - 7.5 * 02 + 1)\n",
    "    '''\n",
    "\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = x[..., 2]\n",
    "    NIR = x[..., 3]\n",
    "    evis = 2.5 * ( (NIR-RED) / (NIR + (6*RED) - (7.5*BLUE) + 1))\n",
    "    evis = np.clip(evis, -1.5, 1.5)\n",
    "    return evis\n",
    "\n",
    "\n",
    "def msavi2(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the modified soil-adjusted vegetation index 2\n",
    "    (2 * NIR + 1 - sqrt((2*NIR + 1)^2 - 8*(NIR-RED)) / 2\n",
    "    '''\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = np.clip(x[..., 2], 0, 1)\n",
    "    NIR = np.clip(x[..., 3], 0, 1)\n",
    "\n",
    "    msavis = (2 * NIR + 1 - np.sqrt( (2*NIR+1)**2 - 8*(NIR-RED) )) / 2\n",
    "    return msavis\n",
    "\n",
    "\n",
    "def bi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    B11 = np.clip(x[..., 8], 0, 1)\n",
    "    B4 = np.clip(x[..., 2], 0, 1)\n",
    "    B8 = np.clip(x[..., 3], 0, 1)\n",
    "    B2 = np.clip(x[..., 0], 0, 1)\n",
    "    bis = ((B11 + B4) - (B8 + B2)) / ((B11 + B4) + (B8 + B2))\n",
    "    return bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 13, 28, 28, 17)\n"
     ]
    }
   ],
   "source": [
    "train_x[..., -1] = convert_to_db(train_x[..., -1], 22)\n",
    "train_x[..., -2] = convert_to_db(train_x[..., -2], 22)\n",
    "\n",
    "indices = np.empty((train_x.shape[0], 12, 28, 28, 4))\n",
    "indices[..., 0] = evi(train_x)\n",
    "indices[..., 1] = bi(train_x)\n",
    "indices[..., 2] = msavi2(train_x)\n",
    "indices[..., 3] = grndvi(train_x)\n",
    "\n",
    "train_x = np.concatenate([train_x, indices], axis = -1)\n",
    "med = np.median(train_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "train_x = np.concatenate([train_x, med], axis = 1)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data preprocessing\n",
    "\n",
    "*  Identify and remove samples with time steps / channels that have a 0. or 1. value, which indicates missing data\n",
    "*  Identify and remove samples with time steps / channels with no variation, which indicates missing data\n",
    "*  Identify and remove samples with values above or below the allowable values for the band\n",
    "*  Identify and remove samples with null data, or samples with extreme band 0 data (which squash all the \"clean\" samples)\n",
    "*  Smooth per-pixel temporal data with Whittaker smoother, d = 2, lambda = 0.5 to reduce sample noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 0 outlying training data points\n",
      "[]\n",
      "(219, 13, 28, 28, 17)\n",
      "(219, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "below_1 = [i for i, val in enumerate(train_x[..., :10]) if np.min(val) < -2]\n",
    "above_1 = [i for i, val in enumerate(train_x[..., :10]) if np.max(val) > 2]\n",
    "min_vals = [np.min(val) for i, val in enumerate(train_x[..., :10]) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(train_x[..., :10]) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(train_x) if np.sum(np.isnan(val)) > 100]\n",
    "oob_vals = [i for i, val in enumerate(train_x) if np.max(val[..., 0]) > 0.7]\n",
    "\n",
    "outliers = below_1 + above_1 + nans + oob_vals\n",
    "outliers = list(set(outliers))\n",
    "print(f\"Removing {len(outliers)} outlying training data points\")\n",
    "print(sorted(outliers))\n",
    "train_x = np.delete(train_x, outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_all = [0.006576638437476157, 0.0162050812542916, 0.010040436408026246, 0.013351644159609368, 0.01965362020294499, 0.014229037918669413, 0.015289539940489814, 0.011993591210803388, 0.008239871824216068, 0.006546120393682765, 0.0, 0.0, 0.0, -0.1409399364817101, -0.4973397113668104, -0.09731556326714398, -0.7193834232943873]\n",
    "max_all = [0.2691233691920348, 0.3740291447318227, 0.5171435111009385, 0.6027466239414053, 0.5650263218127718, 0.5747005416952773, 0.5933928435187305, 0.6034943160143434, 0.7472037842374304, 0.7000076295109483, 0.509269855802243, 0.948334642387533, 0.6729257769285485, 0.8177635298774327, 0.35768999002433816, 0.7545951919107605, 0.7602693339366691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006576638437476157, 0.0162050812542916, 0.010040436408026246, 0.013351644159609368, 0.01965362020294499, 0.014229037918669413, 0.015289539940489814, 0.011993591210803388, 0.008239871824216068, 0.006546120393682765, 0.0, 0.0, 0.0, -0.1409399364817101, -0.4973397113668104, -0.09731556326714398, -0.7193834232943873]\n",
      "[0.2691233691920348, 0.3740291447318227, 0.5171435111009385, 0.6027466239414053, 0.5650263218127718, 0.5747005416952773, 0.5933928435187305, 0.6034943160143434, 0.7472037842374304, 0.7000076295109483, 0.509269855802243, 0.948334642387533, 0.6729257769285485, 0.8177635298774327, 0.35768999002433816, 0.7545951919107605, 0.7602693339366691]\n"
     ]
    }
   ],
   "source": [
    "for band in range(0, train_x.shape[-1]):\n",
    "    #mins = np.percentile(train_x[:, ..., band], 0.1)\n",
    "    #maxs = np.percentile(train_x[:, ..., band], 99.9)\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    train_x[..., band] = np.clip(train_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (train_x[..., band] - midrange) / (rng / 2)\n",
    "    train_x[..., band] = standardized\n",
    "    #min_all.append(mins)\n",
    "    #max_all.append(maxs)\n",
    "\n",
    "print(min_all)\n",
    "print(max_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 0\n"
     ]
    }
   ],
   "source": [
    "outliers = [139368676, 135847238, 135546165, 136446416, 139379033, 137966730,\n",
    "            139201842, 139146753, 135546165, 135680251, 135697756, 135703958, 135809793,\n",
    " 135809874, 135809913, 135847238, 136089167, 136089205, 136434315,136434751, 136434792, 136434852, 136434903,\n",
    " 136434908, 136446261, 136446353, 136446416, 136446451, 136752959, 137966730, 138872345,\n",
    " 138872603, 138872689, 139025570, 139027591, 139027614, 139046306,\n",
    " 139077793, 139077852, 139146753, 139160490,139669281,139929363,\n",
    " 139161820, 139189356, 139189539, 136318389, 135807724, 135680967, 139207880,\n",
    " 139189689, 139191633, 139201842, 139201886, 139341952, 139342073, 139365739, 139365903,\n",
    " 139368676, 139379033, 139379276, 139419912, 139189774, 139669397, 139940209, 139745924, 139319271, \n",
    " 139940210, 139940211, 139940212, 139940213,139940214,139940215,139940216, 139940217,139940218,139940219,\n",
    " 139940220, 139940221, 139940222, 139940223, 139940224,139940225, 139940226,139940227,139940228, 140474053,\n",
    "           139046981, 139291824, 135698166, 139277262, 139686333, 138900959, 136446306, 140474089, 140474144,\n",
    "           140751023, 140751031, 140751033, 140751032, 140751040, 140751039, 140751082,\n",
    "140751089, 140751111, 140751124, 140751221, 140750979, 140751095, 140751154, 140751239, ]\n",
    "\n",
    "outliers = data[data['plot_id'].isin(outliers)]\n",
    "outliers = list(outliers.index)\n",
    "print(outliers, len(outliers))\n",
    "train_x = np.delete(train_x, outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(975, 12, 28, 28, 13)\n",
      "There are 0 outliers\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import hickle as hkl\n",
    "test_x = hkl.load(\"../data/test/test_x.hkl\")\n",
    "test_y = hkl.load(\"../data/test/test_y.hkl\")\n",
    "test_data = pd.read_csv(\"../data/test/test_plot_ids.csv\")\n",
    "\n",
    "test_x = np.delete(test_x, 11, -1)\n",
    "print(test_x.shape)\n",
    "\n",
    "if not isinstance(test_x.flat[0], np.floating):\n",
    "    assert np.max(test_x) > 1\n",
    "    test_x = test_x / 65535.\n",
    "    \n",
    "test_x[..., -1] = convert_to_db(test_x[..., -1], 22)\n",
    "test_x[..., -2] = convert_to_db(test_x[..., -2], 22)\n",
    "\n",
    "indices = np.empty((test_x.shape[0], 12, 28, 28, 4))\n",
    "indices[..., 0] = evi(test_x)\n",
    "indices[..., 1] = bi(test_x)\n",
    "indices[..., 2] = msavi2(test_x)\n",
    "indices[..., 3] = grndvi(test_x)\n",
    "\n",
    "test_x = np.concatenate([test_x, indices], axis = -1)\n",
    "med = np.median(test_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "test_x = np.concatenate([test_x, med], axis = 1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.min(val) < -1.66]\n",
    "above_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.max(val) > 1.66]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "\n",
    "print(f\"There are {len(outliers)} outliers\")\n",
    "print([x for x in test_data['plot_id'].iloc[outliers]])\n",
    "\n",
    "test_x = np.delete(test_x, outliers, 0)\n",
    "test_y = np.delete(test_y, outliers, 0)\n",
    "test_data = test_data.drop(outliers, 0)\n",
    "test_data = test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[392, 399] 2\n",
      "Removing 2 outlying testing data points\n",
      "[392, 399]\n"
     ]
    }
   ],
   "source": [
    "outliers = [139190811, 139190836]\n",
    "outliers = test_data[test_data['plot_id'].isin(outliers)]\n",
    "outliers = list(outliers.index)\n",
    "print(outliers, len(outliers))\n",
    "\n",
    "print(f\"Removing {len(outliers)} outlying testing data points\")\n",
    "print(sorted(outliers))\n",
    "test_x = np.delete(test_x, outliers, 0)\n",
    "test_y = np.delete(test_y, outliers, 0)\n",
    "test_data = test_data.drop(outliers, 0)\n",
    "test_data.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data scaling\n"
     ]
    }
   ],
   "source": [
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[..., band] = np.clip(test_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[..., band] - midrange) / (rng / 2)\n",
    "    test_x[..., band] = standardized\n",
    "print(\"Finished data scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equibatch creation\n",
    "\n",
    "The modelling approach uses equibatch sampling to ensure that there is a near constant standard deviation of the percent tree cover in the output labels for each batch. This helps ensure that the model performs equally well across gradients of tree cover, by mitigating the random possibility that many batches in a row near the end of sampling may be randomly biased towards a tree cover range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107.0, 155.32999999999998, 166.56, 176.16, 183.02, 191.5, 196.0, 196.0]\n",
      "There are 5 zeros\n"
     ]
    }
   ],
   "source": [
    "sums = np.sum(train_y, axis = (1, 2))\n",
    "percents = [np.percentile(sums, x) for x in range(30, 100, 9)]\n",
    "print(percents)\n",
    "print(f\"There are {len(np.argwhere(sums == 0))} zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "[6, 1, 1, 3, 1, 1, 1, 8, 26]\n"
     ]
    }
   ],
   "source": [
    "train_ids = [x for x in range(0, len(train_y))]\n",
    "\n",
    "def multiplot(matrices):\n",
    "    '''Plot multiple heatmaps with subplots\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list of arrays):\n",
    "\n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4)\n",
    "    fig.set_size_inches(20, 4)\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        sns.heatmap(data = matrix, ax = axs[i], vmin = 0, vmax = 0.9)\n",
    "        axs[i].set_xlabel(\"\")\n",
    "        axs[i].set_ylabel(\"\")\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_xticks([])\n",
    "\n",
    "def equibatch(train_ids, p = percents):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          train_ids (list):\n",
    "          p (list):\n",
    "\n",
    "         Returns:\n",
    "          equibatches (list):\n",
    "    '''\n",
    "    percents = [9.0, 17.0, 27.0, 40.0, 63.0, 105.0, 158.0]\n",
    "    # 0, 5, 10, 14, 20, 32, 55, 80\n",
    "    print(len(train_ids))\n",
    "    train_ids_cp = train_ids\n",
    "    np.random.shuffle(train_ids_cp)\n",
    "    ix = train_ids_cp\n",
    "    print(len(ix))\n",
    "    percs = [np.sum(x) for x in train_y[ix]]\n",
    "    ids0 = [x for x, z in zip(ix, percs) if z <= 2]\n",
    "    ids30 = [x for x, z in zip(ix, percs) if 2 < z <= percents[0]]\n",
    "    ids40 = [x for x, z in zip(ix, percs) if percents[0] < z <= percents[1]]\n",
    "    ids50 = [x for x, z in zip(ix, percs) if percents[1] < z <= percents[2]]\n",
    "    ids60 = [x for x, z in zip(ix, percs) if percents[2] < z <= percents[3]]\n",
    "    ids70 = [x for x, z in zip(ix, percs) if percents[3] < z <= percents[4]]\n",
    "    ids80 = [x for x, z in zip(ix, percs) if percents[4] < z <= percents[5]]\n",
    "    ids90 = [x for x, z in zip(ix, percs) if percents[5] < z <= percents[6]]\n",
    "    ids100 = [x for x, z in zip(ix, percs) if percents[6] < z]\n",
    "    \n",
    "    new_batches = []\n",
    "    maxes = [len(ids0), len(ids30), len(ids40), len(ids50), len(ids60), len(ids70),\n",
    "             len(ids80), len(ids90), len(ids100)]\n",
    "    print(maxes)\n",
    "    cur_ids = [0] * len(maxes)\n",
    "    iter_len = len(train_ids)//(len(maxes))\n",
    "    for i in range(0, iter_len):\n",
    "        for i, val in enumerate(cur_ids):\n",
    "            if val > maxes[i] - 1:\n",
    "                cur_ids[i] = 0\n",
    "        if cur_ids[0] >= (maxes[0] - 2):\n",
    "            cur_ids[0] = 0\n",
    "        to_append = [ids0[cur_ids[0]],\n",
    "                    ids30[cur_ids[1]], ids40[cur_ids[2]],\n",
    "                    ids50[cur_ids[3]], ids60[cur_ids[4]], \n",
    "                    ids70[cur_ids[5]], ids80[cur_ids[6]],\n",
    "                    ids90[cur_ids[7]], ids100[cur_ids[8]]]\n",
    "        \n",
    "        np.random.shuffle(to_append)\n",
    "        new_batches.append(to_append)\n",
    "        cur_ids = [x + 1 for x in cur_ids]\n",
    "        \n",
    "    new_batches = [item for sublist in new_batches for item in sublist]\n",
    "    return new_batches\n",
    "\n",
    "batch = equibatch(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_size_inches(15, 6)\n",
    "sns.distplot(np.sum(train_y, axis = (1, 2)), bins = 50, kde = False, ax = ax1)\n",
    "ax1.set_title('Original distribution')\n",
    "ax2.set_title('Equibatch distribution')\n",
    "sns.distplot(np.sum(train_y[batch], axis = (1, 2)),\n",
    "             bins = 50, kde = False, ax = ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example equibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[4:8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[8:12]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Loss definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 85 is out of bounds for axis 0 with size 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bc40002ee763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_dist_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ground truth Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Boundary loss mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 85 is out of bounds for axis 0 with size 48"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 85 # 14\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_size_inches(14, 5)\n",
    "sns.heatmap(calc_dist_map(train_y[idx]), ax = ax1)\n",
    "ax2.set_title('Ground truth Y')\n",
    "ax1.set_title('Boundary loss mask')\n",
    "sns.heatmap(train_y[idx], ax = ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {'all': [0, 1150]}\n",
    "\n",
    "def dice_loss_tolerance(y_true, y_pred):\n",
    "    numerator_data = np.zeros_like(y_true)\n",
    "    for x in range(y_true.shape[0]):\n",
    "        for y in range(y_true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([y_true.shape[0], y+2])\n",
    "            max_x = np.min([y_true.shape[0], x+2])\n",
    "            if y_true[x, y] == 1:\n",
    "                numerator_data[x, y] = np.max(y_pred[min_x:max_x, min_y:max_y])\n",
    "                \n",
    "    numerator = 2 * np.sum(y_true * numerator_data, axis=-1)\n",
    "    denominator = np.sum(y_true + y_pred, axis=-1)\n",
    "    return (numerator + 1) / (denominator + 1)\n",
    "                    \n",
    "            \n",
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calculate_metrics(country, al = 0.4, canopy_thresh = 100):\n",
    "    '''Calculates the following metrics for an input country, based on\n",
    "       indexing of the country dictionary:\n",
    "       \n",
    "         - Loss\n",
    "         - F1\n",
    "         - Precision\n",
    "         - Recall\n",
    "         - Dice\n",
    "         - Mean surface distance\n",
    "         - Average error\n",
    "    \n",
    "         Parameters:\n",
    "          country (str):\n",
    "          al (float):\n",
    "          \n",
    "         Returns:\n",
    "          val_loss (float):\n",
    "          best_dice (float):\n",
    "          error (float):\n",
    "    '''\n",
    "    print(canopy_thresh)\n",
    "    start_idx = 0\n",
    "    stop_idx = len(test_x)\n",
    "    best_f1 = 0\n",
    "    best_dice = 0\n",
    "    best_thresh = 0\n",
    "    hausdorff = 0\n",
    "    relaxed_f1 = 0\n",
    "    preds = []\n",
    "    vls = []\n",
    "    trues = []\n",
    "    test_ids = [x for x in range(len(test_x))]\n",
    "    for test_sample in test_ids[start_idx:stop_idx]:\n",
    "        if np.sum(test_y[test_sample]) < ((canopy_thresh/100) * 197):\n",
    "            x_input = test_x[test_sample].reshape(1, 13, 28, 28, n_bands)\n",
    "            x_median_input = calc_median_input(x_input)\n",
    "            y, vl = sess.run([fm, test_loss], feed_dict={inp: x_input,\n",
    "                                                          #inp_median: x_median_input,\n",
    "                                                          length: np.full((1,), 12),\n",
    "                                                          is_training: False,\n",
    "                                                          labels: test_y[test_sample].reshape(1, 14, 14),\n",
    "                                                          loss_weight: 1.0,\n",
    "                                                          alpha: 0.33,\n",
    "                                                          })\n",
    "            preds.append(y.reshape((14, 14)))\n",
    "            vls.append(vl)\n",
    "            trues.append(test_y[test_sample].reshape((14, 14)))\n",
    "    dice_losses = []\n",
    "    for thresh in range(7, 9):\n",
    "        tps_relaxed = np.empty((len(preds), ))\n",
    "        fps_relaxed = np.empty((len(preds), ))\n",
    "        fns_relaxed = np.empty((len(preds), ))\n",
    "        abs_error = np.empty((len(preds), ))\n",
    "        \n",
    "        for sample in range(len(preds)):\n",
    "            pred = np.copy(preds[sample])\n",
    "            true = trues[sample]\n",
    "            if thresh == 8:\n",
    "                if np.sum(true + pred) > 0:\n",
    "                    dice_losses.append(0.5)\n",
    "                   # dice_losses.append(dice_loss_tolerance(np.array(true), np.array(pred)))\n",
    "                else:\n",
    "                    dice_losses.append(1.)\n",
    "            pred[np.where(pred >= thresh*0.05)] = 1\n",
    "            pred[np.where(pred < thresh*0.05)] = 0\n",
    "            \n",
    "            true_s = np.sum(true[1:-1])\n",
    "            pred_s = np.sum(pred[1:-1])\n",
    "            abs_error[sample] = abs(true_s - pred_s)\n",
    "            tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "            tps_relaxed[sample] = tp_relaxed\n",
    "            fps_relaxed[sample] = fp_relaxed\n",
    "            fns_relaxed[sample] = fn_relaxed                   \n",
    "            \n",
    "        oa_error = np.mean(abs_error)\n",
    "        precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "        recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "        f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "        \n",
    "        if f1_r > best_f1:\n",
    "            haus = np.zeros((len(preds), ))\n",
    "            for sample in range(len(preds)):\n",
    "                pred = np.copy(preds[sample])\n",
    "                pred[np.where(pred >= thresh*0.05)] = 1\n",
    "                pred[np.where(pred < thresh*0.05)] = 0\n",
    "                true = trues[sample]\n",
    "                #dists = compute_surface_distances(np.array(true).reshape(14, 14, 1).astype(int),\n",
    "                #                                  np.array(pred).reshape(14, 14, 1).astype(int),\n",
    "                #                                  [1, 1, 1])\n",
    "                #if np.sum(true + pred) > 0:\n",
    "                #    haus_i = compute_robust_hausdorff(dists, 50)\n",
    "                #    if not np.isinf(haus_i):\n",
    "                #        haus[sample] = haus_i\n",
    "                #if np.sum(true + pred) == 0:\n",
    "                #    haus[sample] = 0.\n",
    "                    \n",
    "            dices = np.mean(dice_losses)\n",
    "            haus = np.mean(haus)\n",
    "            best_dice = 0.5\n",
    "            best_f1 = f1_r\n",
    "            p = precision_r\n",
    "            r = recall_r\n",
    "            error = oa_error\n",
    "            best_thresh = thresh*0.05\n",
    "            best_haus = 0.5\n",
    "    print(f\"{country}: Val loss: {np.around(np.mean(vls), 3)}\"\n",
    "          f\" Thresh: {np.around(best_thresh, 2)}\"\n",
    "          f\" F1: {np.around(best_f1, 3)} R: {np.around(p, 3)} P: {np.around(r, 3)}\"\n",
    "          f\" D: {np.around(np.mean(best_dice), 3)} H: {np.around(best_haus, 3)}\"\n",
    "          f\" Error: {np.around(error, 3)}\")\n",
    "    return np.mean(vls), best_f1, error, best_haus, np.mean(best_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = 0.33\n",
    "\n",
    "def make_evaluation_csv(data):\n",
    "    test_ids = [x for x in range(len(test_x))]\n",
    "    print(len(test_ids))\n",
    "    sums = []\n",
    "    sum_preds = []\n",
    "    trues = []\n",
    "    preds = []\n",
    "    for test_sample in test_ids:\n",
    "        x_input = test_x[test_sample].reshape(1, 13, 28, 28, n_bands)\n",
    "        #x_median_input = calc_median_input(x_input)\n",
    "        y, vl = sess.run([fm, test_loss], feed_dict={inp: x_input,\n",
    "                                                      #inp_median: x_median_input,\n",
    "                                                      length: np.full((1,), 12),\n",
    "                                                      is_training: False,\n",
    "                                                      labels: test_y[test_sample].reshape(1, 14, 14),\n",
    "                                                      loss_weight: 0.5,\n",
    "                                                      alpha: al,\n",
    "                                                      })\n",
    "        preds.append(y.reshape((14, 14)))\n",
    "        trues.append(test_y[test_sample].reshape((14, 14)))\n",
    "    thresh = 0.3\n",
    "    tps_relaxed = np.empty((len(preds), ))\n",
    "    fps_relaxed = np.empty((len(preds), ))\n",
    "    fns_relaxed = np.empty((len(preds), ))\n",
    "    abs_error = np.empty((len(preds), ))\n",
    "    \n",
    "    tree_cover = []\n",
    "    for sample in range(len(preds)):\n",
    "        pred = np.copy(preds[sample])\n",
    "        true = trues[sample]\n",
    "        if thresh == 8:\n",
    "            if np.sum(true + pred) > 0:\n",
    "                dice_losses.append(0.5)\n",
    "               # dice_losses.append(dice_loss_tolerance(np.array(true), np.array(pred)))\n",
    "            else:\n",
    "                dice_losses.append(1.)\n",
    "        pred[np.where(pred >= thresh)] = 1\n",
    "        pred[np.where(pred < thresh)] = 0\n",
    "\n",
    "        true_s = np.sum(true)\n",
    "        pred_s = np.sum(pred)\n",
    "        \n",
    "        tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "        abs_error[sample] = int((true_s - pred_s) // 1.96)\n",
    "        print(abs_error[sample])\n",
    "        tps_relaxed[sample] = tp_relaxed\n",
    "        fps_relaxed[sample] = fp_relaxed\n",
    "        fns_relaxed[sample] = fn_relaxed       \n",
    "        tree_cover.append(int( (np.sum(true) * 100) // 196))\n",
    "\n",
    "    oa_error = np.mean(abs_error)\n",
    "    precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "    recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "    f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "    data['error'] = abs_error\n",
    "    data['tp'] = tps_relaxed\n",
    "    data['fp'] = fps_relaxed\n",
    "    data['fn'] = fns_relaxed\n",
    "    data['tree_cover'] = tree_cover\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0875d2187330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_med\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_med\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "x_med = np.median(train_x, axis = (1, 2, 3))\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(x_med)\n",
    "clusters = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-87ed7c4bf47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# principal components (?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcut_mix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clusters' is not defined"
     ]
    }
   ],
   "source": [
    "def fftIndgen(n):\n",
    "    a = range(0, n//2+1)\n",
    "    b = range(1, n//2)\n",
    "    b = [x for x in b]\n",
    "    b.reverse()\n",
    "    a = [x for x in a]\n",
    "   \n",
    "    b = [-i for i in b]\n",
    "    return a + b\n",
    "\n",
    "def gaussian_random_field(Pk = lambda k : k**-3.0, size = 100):\n",
    "    def Pk2(kx, ky):\n",
    "        if kx == 0 and ky == 0:\n",
    "            return 0.0\n",
    "        return np.sqrt(Pk(np.sqrt(kx**2 + ky**2)))\n",
    "    noise = np.fft.fft2(np.random.normal(size = (size, size)))\n",
    "    amplitude = np.zeros((size,size))\n",
    "    for i, kx in enumerate(fftIndgen(size)):\n",
    "        for j, ky in enumerate(fftIndgen(size)):            \n",
    "            amplitude[i, j] = Pk2(kx, ky)\n",
    "    return np.fft.ifft2(noise * amplitude).astype(np.float32)\n",
    "\n",
    "def make_aug_masks(n, perc):\n",
    "    masks = np.zeros((n, 24, 24))\n",
    "    for i in range(n):\n",
    "        gas = gaussian_random_field(Pk = lambda k: k**-5, size=24)\n",
    "        percentile = np.clip(np.random.normal(perc, 0.1, 1), 0, 1)\n",
    "        percentile = np.percentile(gas, percentile * 100)\n",
    "        gas = gas <= percentile\n",
    "        masks[i] = gas\n",
    "    return masks\n",
    "\n",
    "\n",
    "# Realistically rather than sampling from the entire dataset,\n",
    "# We would want to match up each pair of samples such that they share the same\n",
    "# principal components (?)\n",
    "\n",
    "def cut_mix(x_batch, y_batch, ids, percent, batch_size, cluster = clusters):\n",
    "    \n",
    "    train_ids = [x for x in range(len(train_x))]\n",
    "    cl_batch = clusters[ids]\n",
    "    \n",
    "    binary_mask = np.random.rand(batch_size)\n",
    "    binary_mask = (binary_mask <= 0.25).astype(np.int)\n",
    "    \n",
    "    masks_x = make_aug_masks(batch_size, .33)\n",
    "    masks_y = masks_x[:, 5:-5, 5:-5]\n",
    "    masks_x = np.broadcast_to(\n",
    "        masks_x[:, np.newaxis, :, :, np.newaxis], (batch_size, 13, 24, 24, 17))\n",
    "    \n",
    "    i = 0\n",
    "    for x, y, cluster, mask in zip(x_batch, y_batch, cl_batch, binary_mask):\n",
    "        if mask == 1:\n",
    "            random_id = np.random.choice(clusters[clusters == cluster])\n",
    "            x_random = train_x[random_id]\n",
    "            y_random = train_y[random_id]\n",
    "\n",
    "            x[masks_x[i] == 1] = x_random[masks_x[i] == 1]\n",
    "            y[masks_y[i] == 1] = y_random[masks_y[i] == 1]\n",
    "            i += 1\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_batch(batch_ids, batch_size):\n",
    "    '''Performs random flips and rotations of the X and Y\n",
    "       data for a total of 4 x augmentation\n",
    "    \n",
    "         Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    x = train_x[batch_ids]\n",
    "    #steps_to_noise = np.random.choice(np.arange(0, 12), 2, replace = False)\n",
    "    #noise = np.random.normal(1, .025, size = (batch_size, 1, 24, 24, n_bands))\n",
    "    #x[:, steps_to_noise, ...] = x[:, steps_to_noise, ...] * noise\n",
    "    \n",
    "    y = train_y[batch_ids]\n",
    "    x_batch = np.zeros_like(x)\n",
    "    y_batch = np.zeros_like(y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    flips = np.random.choice(np.array([0, 1, 2, 3]), batch_size, replace = True)\n",
    "    for i in range(x.shape[0]):\n",
    "        current_flip = flips[i]\n",
    "        if current_flip == 0:\n",
    "            x_batch[i] = x[i]\n",
    "            y_batch[i] = y[i]\n",
    "        if current_flip == 1:\n",
    "            x_batch[i] = np.flip(x[i], 1)\n",
    "            y_batch[i] = np.flip(y[i], 0)\n",
    "        if current_flip == 2:\n",
    "            x_batch[i] = np.flip(x[i], [2, 1])\n",
    "            y_batch[i] = np.flip(y[i], [1, 0])\n",
    "        if current_flip == 3:\n",
    "            x_batch[i] = np.flip(x[i], 2)\n",
    "            y_batch[i] = np.flip(y[i], 1)\n",
    "\n",
    "    y_batch = y_batch.reshape((batch_size, 14, 14))\n",
    "    #x_batch, y_batch = cut_mix(x_batch, y_batch, batch_ids, 0.5, batch_size)\n",
    "    return x_batch, y_batch\n",
    "\n",
    "x_batch_test, y_batch_test = augment_batch([x for x in range(32)], 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_median_input(x_batch):\n",
    "    x_median = np.percentile(x_batch, 25, axis = (1))\n",
    "    return x_median\n",
    "\n",
    "x_batch_med = calc_median_input(x_batch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 201\n",
    "f, ((c1r1, c1r2), (c2r1, c2r2)) = plt.subplots(2, 2, sharey=False)\n",
    "f.set_size_inches(15, 12)\n",
    "\n",
    "c1r1.set_title(f\"Train loss - {model_path}\")\n",
    "l1 = sns.scatterplot(y = metrics[0, start:end], x = np.arange(start, end), ax = c1r1)\n",
    "l1.set(ylim=(0.120, .145))\n",
    "\n",
    "c1r2.set_title(\"F1 score\")\n",
    "f =sns.scatterplot(y = metrics[5, start:end], x = np.arange(start, end), ax = c1r2)\n",
    "f.set(ylim=(0.84, .91))\n",
    "\n",
    "c2r1.set_title(\"Test loss\")\n",
    "l = sns.scatterplot(y = metrics[1, start:end], x = np.arange(start, end), ax = c2r1)\n",
    "l.set(ylim=(0.140, .165)) \n",
    "\n",
    "c2r2.set_title(\"Absolute % error\")\n",
    "e = sns.scatterplot(y = metrics[2, start:end] / 2, x = np.arange(start, end), ax = c2r2)\n",
    "e.set(ylim=(2.2, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_lr(epoch):\n",
    "    path = f'{model_path}78-90-7/'\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(path))\n",
    "    op = train_op\n",
    "    print(\"Using Adabound\")\n",
    "    BATCH_SIZE = 20\n",
    "    test_lrs = [1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 8e-3, 1e-2, 5e-2, 1e-1, 2e-1]\n",
    "    losses = []\n",
    "    train_ids = [x for x in range(len(train_y))]\n",
    "    randomize = equibatch(train_ids)\n",
    "    \n",
    "    for k in tnrange(len(test_lrs)):\n",
    "        loss_i = []\n",
    "        for batch in tnrange(15):\n",
    "            batch_ids = randomize[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            x_batch, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "            x_median_input = calc_median_input(x_batch)\n",
    "            ft_learning_rate = test_lrs[k]\n",
    "            opt, tr = sess.run([op, loss],\n",
    "                              feed_dict={inp: x_batch,\n",
    "                                         #inp_median: x_median_input,\n",
    "                                         length: np.full((BATCH_SIZE, 1), 12),\n",
    "                                         labels: y_batch,\n",
    "                                         is_training: True,\n",
    "                                         clipping_params['rmax']: 5,\n",
    "                                         clipping_params['rmin']: 0,\n",
    "                                         clipping_params['dmax']: 3,\n",
    "                                         loss_weight: 1.45,\n",
    "                                         keep_rate: np.max(((1. - (i * 0.003)), 0.90)),\n",
    "                                         alpha: np.min([epoch * 0.01, 0.33]),\n",
    "                                         beta_: be,\n",
    "                                         ft_lr: ft_learning_rate,\n",
    "                                         })\n",
    "            loss_i.append(tr)\n",
    "        losses.append(np.mean(loss_i))\n",
    "        print(test_lrs[k], np.mean(loss_i))\n",
    "    return losses, test_lrs\n",
    "\n",
    "#losses, test_lrs = find_lr(epoch = 28)\n",
    "#sns.scatterplot(np.log10(test_lrs), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If warm-restart, reinitialize the optimizer\n",
    "#sess.run(tf.variables_initializer(optimizer.variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path  = \"../models/small-temporal/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if os.path.isfile(f\"{model_path}metrics.npy\"):\n",
    "    metrics = np.load(f\"{model_path}metrics.npy\")\n",
    "    print(f\"Loading {model_path}metrics.npy\")\n",
    "else:\n",
    "    print(\"Starting anew\")\n",
    "    metrics = np.zeros((6, 300))\n",
    "\n",
    "path = model_path\n",
    "saver.restore(sess, tf.train.latest_checkpoint(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.delete(train_x, [8, 12, 33,], axis = 0)\n",
    "train_y = np.delete(train_y, [8, 12, 33,], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 102, alpha: 0.33, beta: 0.0 drop: 0.9 Learning rate: 0.0005\n",
      "Epoch 102: Loss 0.20200000703334808\n",
      "75\n",
      "all: Val loss: 0.15199999511241913 Thresh: 0.4 F1: 0.891 R: 0.889 P: 0.893 D: 0.5 H: 0.5 Error: 5.915\n",
      "Saving model with 0.8908448311017468\n",
      "starting epoch 103, alpha: 0.33, beta: 0.0 drop: 0.9 Learning rate: 0.0005\n",
      "Epoch 103: Loss 0.1940000057220459\n",
      "75\n",
      "all: Val loss: 0.1509999930858612 Thresh: 0.4 F1: 0.891 R: 0.891 P: 0.891 D: 0.5 H: 0.5 Error: 5.856\n",
      "Saving model with 0.8913332198195131\n",
      "starting epoch 104, alpha: 0.33, beta: 0.0 drop: 0.9 Learning rate: 0.0005\n",
      "Epoch 104: Loss 0.19099999964237213\n",
      "75\n",
      "all: Val loss: 0.15000000596046448 Thresh: 0.4 F1: 0.892 R: 0.894 P: 0.891 D: 0.5 H: 0.5 Error: 5.789\n",
      "Saving model with 0.8924294633414076\n",
      "starting epoch 105, alpha: 0.33, beta: 0.0 drop: 0.9 Learning rate: 0.0005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-6e93fc80a724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                      \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                      \u001b[0mbeta_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                                      \u001b[0mft_lr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mft_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                                      })\n\u001b[1;32m     44\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val = 0.72\n",
    "fine_tune = False\n",
    "#countries['all'] = [0, len(test_x)]\n",
    "ft_epochs = 0\n",
    "\n",
    "SWA = True\n",
    "\n",
    "for i in range(102, 201):\n",
    "    al = np.min( [0.01 * (i - 1), 0.33] )\n",
    "    ft_learning_rate = .0005\n",
    "    be = 0.0\n",
    "    test_al = al\n",
    "    if fine_tune == True:\n",
    "        op = ft_op\n",
    "        print(f\"FINE TUNING WITH {ft_learning_rate} LR\")\n",
    "    else:\n",
    "        op = train_op\n",
    "        \n",
    "    train_ids = [x for x in range(len(train_y))]\n",
    "    randomize = train_ids\n",
    "    #randomize = equibatch(train_ids)\n",
    "    print(f\"starting epoch {i}, alpha: {al}, beta: {be} drop: {np.max(((1. - (i * 0.005)), 0.9))}\"\n",
    "         f\" Learning rate: {ft_learning_rate}\")\n",
    "    \n",
    "    loss = train_loss\n",
    "    BATCH_SIZE = 32\n",
    "    test_ids = [x for x in range(0, len(test_x))]\n",
    "    losses = []\n",
    "    \n",
    "    for k in range(int(len(randomize) // BATCH_SIZE)):\n",
    "        batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "        x_batch, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "        opt, tr = sess.run([train_step, loss],\n",
    "                          feed_dict={inp: x_batch,\n",
    "                                     length: np.full((BATCH_SIZE,), 12),\n",
    "                                     labels: y_batch,\n",
    "                                     is_training: True,\n",
    "                                     loss_weight: 1.0,\n",
    "                                     keep_rate: np.max(((1. - (i * 0.005)), 0.5)),\n",
    "                                     alpha: al,\n",
    "                                     beta_: be,\n",
    "                                     ft_lr: ft_learning_rate,\n",
    "                                     })\n",
    "        losses.append(tr)\n",
    "    \n",
    "    print(f\"Epoch {i}: Loss {np.around(np.mean(losses[:-1]), 3)}\")\n",
    "    if SWA:\n",
    "        sess.run(swa_op)\n",
    "\n",
    "        # now to evaluate the model with SWA weights :\n",
    "        # save weights\n",
    "        sess.run(save_weight_backups)\n",
    "\n",
    "        # replace weights by SWA ones\n",
    "        sess.run(swa_to_weights)\n",
    "    run_metrics = False\n",
    "    metrics[0, i] = np.mean(losses[:-1])\n",
    "    if (i > 80) and (i % 1) == 0:\n",
    "        run_metrics = True\n",
    "    elif i % 1 == 0:\n",
    "        run_metrics = True\n",
    "    if run_metrics:\n",
    "        val_loss, f1, error, haus, dice = calculate_metrics('all', al = test_al, canopy_thresh = 75)\n",
    "        metrics[1, i] = val_loss\n",
    "        metrics[2, i] = error\n",
    "        metrics[3, i] = haus\n",
    "        metrics[4, i] = dice\n",
    "        metrics[5, i] = f1\n",
    "        if f1 < (best_val - 0.002):\n",
    "            ft_epochs += 1\n",
    "        if f1 > (best_val - 0.02):\n",
    "            print(f\"Saving model with {f1}\")\n",
    "            np.save(f\"{model_path}metrics.npy\", metrics)\n",
    "            os.mkdir(f\"{model_path}/swa/{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/\")\n",
    "            save_path = saver.save(sess, f\"{model_path}/swa/{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/model\")\n",
    "            if f1 > best_val:\n",
    "                best_val = f1\n",
    "    if SWA:\n",
    "        sess.run(restore_weight_backups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: Val loss: 0.14300000667572021 Thresh: 0.35 F1: 0.904 R: 0.928 P: 0.882 D: 0.5 H: 0.5 Error: 5.136\n"
     ]
    }
   ],
   "source": [
    "val_loss, f1, error, haus, dice = calculate_metrics('all', al = 0.33, canopy_thresh = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(973, 14, 28, 28, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_s1 = test_x[..., 11:13]\n",
    "test_s1 = np.delete(test_s1, [1, 3, 5, 7, 9, 11], axis = 1)\n",
    "test_s1 = test_s1.repeat(2, axis = 1)\n",
    "test_s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s1 = test_s1[:, :-1, ...]\n",
    "test_x[..., 11:13] = test_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "all: Val loss: 0.14399999380111694 Thresh: 0.35 F1: 0.902 R: 0.924 P: 0.882 D: 0.5 H: 0.5 Error: 5.182\n"
     ]
    }
   ],
   "source": [
    "val_loss, f1, error, haus, dice = calculate_metrics('all', al = 0.33, canopy_thresh = 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/ipykernel/__main__.py:4: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d3744c2eae4636a5ee1fa3d5459133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=973.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_ids = [x for x in range(len(test_x))]\n",
    "test_out = np.zeros_like(test_y)\n",
    "diffs = []\n",
    "for idx in tnrange(len(test_ids)):\n",
    "    x_input = test_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    median_input = calc_median_input(x_input)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  #inp_median: median_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    test_out[idx] = y\n",
    "    #y[np.where(y > 0.35)] = 1.0\n",
    "    #y[np.where(y < 0.35)] = 0.\n",
    "    #diff = np.sum(y) - np.sum(test_y[idx])\n",
    "    #diffs.append(diff)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list):\n",
    "          nrows (int):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(18, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9, cbar = False)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.848262415903619, 33.91996394000001)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 0\n",
    "test_data.iloc[start]['lat'], test_data.iloc[start]['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "0 -4.848262415903619 33.91996394000001\n",
      "1 -4.196233920916483 34.13992536\n",
      "2 6.584925279869622 31.346829719999995\n",
      "3 7.879326573844607 30.369424660000004\n",
      "4 8.489990293832896 28.22798455\n",
      "5 13.221048009745212 13.79266686\n",
      "6 13.94605977973234 13.40172914\n",
      "7 16.53197182968784 -5.349714262000002\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(start/len(test_ids))\n",
    "#test_ids = [x for x in range(test_x.shape[0])]\n",
    "#test_ids = sorted(test_ids)\n",
    "#test_ids = np.argwhere(abs(np.array(diffs)) > 25)\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = test_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    median_input = calc_median_input(x_input)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  #inp_median: median_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    print(i, test_data.iloc[i]['lat'], test_data.iloc[i]['long'])\n",
    "    #print(i, (list(test_data.iloc[idx, 1])[0], list(test_data.iloc[idx, 2])[0]), diffs[i[0]])\n",
    "    #y, mapshape = aggregate_maxes(test_y[idx], y)\n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    true = test_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "\n",
    "start = start + 8 \n",
    "\n",
    "# 123, 334, 680, 875, 917, 950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e266a079a032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdiffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     y = sess.run([fm], feed_dict={inp: x_input,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tqdm/__init__.py\u001b[0m in \u001b[0;36mtnrange\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     warn(\"Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\",\n\u001b[1;32m     40\u001b[0m          TqdmDeprecationWarning, stacklevel=2)\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mtnrange\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0mOn\u001b[0m \u001b[0mPython3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \"\"\"\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             raise ImportError(\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "train_ids = [x for x in range(len(train_y))]\n",
    "diffs = np.zeros((len(train_ids), ))\n",
    "for idx in tnrange(0, len(train_ids) - 16, 20):\n",
    "    x_input = train_x[idx:idx + 20].reshape(20, 13, 28, 28, n_bands)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  #inp_median: median_input,\n",
    "                                  length: np.full((20,), 12),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(20, 14, 14)\n",
    "    y[y > 0.4] = 1.0\n",
    "    y[y < 0.4] = 0.\n",
    "    diff = np.sum(y, axis = (1, 2)) - np.sum(train_y[idx: idx + 20], axis = (1, 2))\n",
    "    diffs[idx : idx + 20] = diff\n",
    "\n",
    "data['diffs'] = diffs\n",
    "data.to_csv(\"data_diffs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [x for x in range(train_x.shape[0])]\n",
    "start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208, 209, 210, 211, 212, 213, 214, 215]\n",
      "208 141238363 13.280144489744147 -13.965938199999998\n",
      "209 141238364 13.281073619744136 -13.81294345\n",
      "210 141238365 13.266324639744408 -13.8039569\n",
      "211 141238366 13.255626069744606 -13.827759699999998\n",
      "212 141238367 13.25783101974455 -13.82979505\n",
      "213 141238368 12.913657079750733 -14.05445974\n",
      "214 141238369 13.07308384974786 -14.55135335\n",
      "215 141238370 13.072679219747874 -14.523433430000004\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_ids = np.argwhere(np.logical_and(abs(np.array(diffs)) >= 70,\n",
    "#                        abs(np.array(diffs)) < 200))\n",
    "\n",
    "matrix_ids = [train_ids[start], train_ids[start + 1], train_ids[start + 2],\n",
    "             train_ids[start + 3], train_ids[start + 4],\n",
    "             train_ids[start + 5], train_ids[start + 6], train_ids[start + 7]]\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = train_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                    })\n",
    "    y = np.array(y).reshape(14, 14)    \n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(14, 14)\n",
    "    \n",
    "    #print(idx, (list(data.iloc[idx, 1])[0], list(data.iloc[idx, 2])[0]))\n",
    "    print(idx, data.iloc[idx, 0], data.iloc[idx, 1],\n",
    "          data.iloc[i, 2])\n",
    "    trues.append(true)\n",
    "    \n",
    "start += 8\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hkl.dump(train_x, f\"../data/train/train_x.hkl\", mode='w', compression='gzip')\n",
    "hkl.dump(train_y, f\"../data/train/train_y.hkl\", mode='w', compression='gzip')\n",
    "data.to_csv(f\"../data/train/train_plot_ids.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([8, 12, 33], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "141237871, 141237875\n",
    "#[ ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
